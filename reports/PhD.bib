Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Vandeweerd2021a,
author = {Vandeweerd, Nathan},
journal = {International Journal of Learner Corpus Research},
title = {{fsca: French syntactic complexity analyzer}}
}
@article{Cho2018,
abstract = {Despite the prolific research on the effects of task complexity on performance, the applicability of the research findings on other task modes is limited due to its focus on oral language. Modality has recently started to gain interest for its potential for L2 development, and learner variables such as working memory is expected to mediate between task effects and performance. This study investigates the roles of task complexity and modality in task performance. It further examines how working memory is associated with task performance and mediates the effects of task variables on performance. Thirty-nine participants performed four argumentative tasks, which differed in task complexity and modality. Working memory was measured via reading span and operation span tests, and task performance was evaluated in terms of complexity, accuracy, and fluency. The results revealed that task complexity produced increased syntactic complexity but only by the phrasal-level measure. Task complexity led to decreased accuracy, but fluency was not affected by task complexity. Task complexity effects were similar across modalities. As for modality on performance, speaking was more accurate, but less fluent than writing. Interestingly, speaking produced higher syntactic complexity than writing. No significant relationship existed between working memory and any performance measures.},
author = {Cho, Minyoung},
doi = {10.1016/j.system.2017.10.010},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cho/Cho{\_}2018{\_}Task complexity, modality, and working memory in L2 task performance.pdf:pdf},
issn = {0346251X},
journal = {System},
keywords = {Modality,Task complexity,Task performance,Working memory},
pages = {85--98},
publisher = {Elsevier},
title = {{Task complexity, modality, and working memory in L2 task performance}},
url = {https://doi.org/10.1016/j.system.2017.10.010},
volume = {72},
year = {2018}
}
@article{Larsson2019,
abstract = { Subject extraposition (e.g. it is important to remember ) is generally considered to be a formal construction that learners, whose writing is often said to be overly informal, have been found to struggle with. This study investigates to what extent register and text type can be used to explore learners' reportedly “informal” use of this construction. Learner writing is compared to expert writing from several different registers and to native-speaker student writing. The results show that there are important differences across both registers and text types. Furthermore, while the learners' use is most like that of the experts' academic writing, certain similarities to the non-academic registers were also noted. The results additionally suggest that earlier claims about the informal status of learner writing seem mainly to have been influenced by the text types included in the corpora previously investigated. },
author = {Larsson, Tove and Kaatari, Henrik},
doi = {10.1075/ijlcr.17014.lar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Larsson, Kaatari/Larsson, Kaatari{\_}2019{\_}Extraposition in learner and expert writing.pdf:pdf},
issn = {2215-1478},
journal = {International Journal of Learner Corpus Research},
number = {1},
pages = {33--62},
title = {{Extraposition in learner and expert writing}},
volume = {5},
year = {2019}
}
@inproceedings{Parisse2017,
address = {Grenoble},
author = {Parisse, Christophe and Benzitoun, Christophe and Etienne, Carole and Li{\'{e}}geois, Lo{\"{i}}c},
booktitle = {Journ{\'{e}}es de Linguistique de Corpus},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Parisse et al/Parisse et al.{\_}2017{\_}Agr{\'{e}}gation automatis{\'{e}}e de corpus de fran{\c{c}}ais parl{\'{e}}.pdf:pdf},
pages = {27--30},
title = {{Agr{\'{e}}gation automatis{\'{e}}e de corpus de fran{\c{c}}ais parl{\'{e}}}},
year = {2017}
}
@book{Lonsdale2009,
address = {New York},
author = {Lonsdale, Deryle and {Le Bras}, Yvon},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lonsdale, Le Bras/Lonsdale, Le Bras{\_}2009{\_}A Frequency Dictionary of French(2).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lonsdale, Le Bras/Lonsdale, Le Bras{\_}2009{\_}A Frequency Dictionary of French.pdf:pdf},
isbn = {0203883047},
publisher = {Routledge},
title = {{A Frequency Dictionary of French}},
year = {2009}
}
@article{Buysse2018,
abstract = {Clause linkage, or the combination of multiple propositions in one complex syntactic unit, is an important concept to be mastered by anyone acquiring a language. Though its role in both first (L1) and second (L2) language acquisition has been studied before (Diessel {\&} Tomasello, V{\'{e}}ronique, Klein {\&} Perdue), an overarching approach to its development is still lacking. This paper proposes a unified model of clause linkage and its development based on Role and Reference Grammar (Van Valin) and tests this model's applicability to L2 acquisition by analyzing oral L2 English and French productions by Dutch-speaking learners, focusing on the syntactic and the semantic aspect of clause linkage and on their interaction.},
author = {Buysse, Manon and Housen, Alex and Pierrard, Michel},
doi = {10.1111/stul.12067},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Buysse, Housen, Pierrard/Buysse, Housen, Pierrard{\_}2018{\_}A Role and Reference Grammar Account of Clause Linkage Development in Second Language An Application to En.pdf:pdf},
issn = {14679582},
journal = {Studia Linguistica},
number = {2},
pages = {472--508},
title = {{A Role and Reference Grammar Account of Clause Linkage Development in Second Language: An Application to English and French}},
volume = {72},
year = {2018}
}
@manual{VanderLoo2019,
annote = {R package version 0.2.1},
author = {van der Loo, Mark},
title = {{gower: Gower's Distance}},
url = {https://cran.r-project.org/package=gower},
year = {2019}
}
@manual{Muller2019a,
annote = {R package version 2.1.3},
author = {M{\"{u}}ller, Kirill and Wickham, Hadley},
title = {{tibble: Simple Data Frames}},
url = {https://cran.r-project.org/package=tibble},
year = {2019}
}
@book{Dahl2004,
address = {Amsterdam},
author = {Dahl, {\"{O}}sten},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dahl/Dahl{\_}2004{\_}Growth and Maintenance of Linguistic Complexity.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dahl/Dahl{\_}2004{\_}Growth and Maintenance of Linguistic Complexity(2).pdf:pdf},
publisher = {John Benjamins},
title = {{Growth and Maintenance of Linguistic Complexity}},
year = {2004}
}
@incollection{Alderson2010,
author = {Alderson, J Charles},
booktitle = {Communicative proficiency and linguistic development : Intersections between SLA and language testing},
editor = {Bartning, Inge and Martin, Maisa and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Alderson/Alderson{\_}2010{\_}Language testing-informed SLA SLA-informed language testing.pdf:pdf},
pages = {239--248},
publisher = {European Second Language Association},
title = {{Language testing-informed SLA ? SLA-informed language testing ?}},
volume = {1},
year = {2010}
}
@techreport{Bachy2007,
address = {Lou},
author = {Bachy, Sylviane and Francard, Michel and Geron, Genevi{\`{e}}ve and Giroul, Vincent and Hambye, Philippe and Simon, Anne-Catherine and Wilmet, R{\'{e}}gine and Ambye, Philippe H and Imon, Anne Catherine S and Ilmet, R{\'{e}}gine W},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bachy et al/Bachy et al.{\_}2007{\_}Conventions de transcription r{\'{e}}gissant les corpus de la banque de donn{\'{e}}es VALIBEL.PDF:PDF},
institution = {Universit{\'{e}} catholique de Louvain},
pages = {1--18},
title = {{Conventions de transcription r{\'{e}}gissant les corpus de la banque de donn{\'{e}}es VALIBEL}},
year = {2007}
}
@phdthesis{Granget2004,
address = {Paris},
author = {Granget, Cyrille},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granget/Granget{\_}2004{\_}L'acquisition par des apprenants germanophones de la r{\'{e}}f{\'{e}}rence au pass{\'{e}} en fran{\c{c}}ais un cas d'{\'{e}}cole.pdf:pdf},
school = {Universit{\'{e}} de Paris III- Sorbonne Nouvelle},
title = {{L'acquisition par des apprenants germanophones de la r{\'{e}}f{\'{e}}rence au pass{\'{e}} en fran{\c{c}}ais : un cas d'{\'{e}}cole}},
type = {Doctoral Dissertation},
year = {2004}
}
@manual{Tierney2018,
annote = {R package version 0.2-16},
author = {Tierney, Luke},
title = {{codetools: Code Analysis Tools for R}},
url = {https://cran.r-project.org/package=codetools},
year = {2018}
}
@manual{Csardi2019e,
annote = {R package version 1.3.3},
author = {Cs{\'{a}}rdi, G{\'{a}}bor},
title = {{rcmdcheck: Run 'R CMD check' from 'R' and Capture Results}},
url = {https://cran.r-project.org/package=rcmdcheck},
year = {2019}
}
@article{Wray2000,
abstract = {One important component of successful language learning is the mastery of idiomatic forms of expression, including idioms, collocations, and sentence frames (collectively referred to here as formulaic sequences). Three attempts to foreground formulaic sequences in teaching syllabuses are those of Willis (1990), Nattinger and DeCarrico (1992), and Lewis (1993). All three find themselves confronting the question of how the teaching of multi-word strings relates to the learner's accumulation of grammatical and lexical knowledge, and despite their different viewpoints and priorities, all conclude that larger units can, and should, be perceived by the learner and teacher in terms of their component parts. Yet research into the nature of formulaic sequences indicates that their form often precludes, and their function specifically circumvents, such internal inspection, for their value resides in the bypassing of the analytical processes which encode and decode strings. Thus, Willis, Nattinger and DeCarrico, and Lewis are all pursuing native-like linguistic usage by promoting entirely unnative-like processing behaviour. This non-alignment is only tractable if the classroom teaching of languages is fully acknowledged as artificial, even when the methods used appear 'naturalistic'.},
author = {Wray, Allison},
doi = {10.1093/applin/21.4.463},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wray/Wray{\_}2000{\_}Formulaic sequences in second language teaching principle and practice.pdf:pdf},
issn = {0142-6001},
journal = {Applied Linguistics},
keywords = {formulaic language},
mendeley-tags = {formulaic language},
month = {dec},
number = {4},
pages = {463--489},
title = {{Formulaic sequences in second language teaching: principle and practice}},
url = {http://applij.oxfordjournals.org/content/21/4/463.short},
volume = {21},
year = {2000}
}
@article{Lumley2004,
annote = {R package verson 2.2},
author = {Lumley, Thomas},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--19},
title = {{Analysis of Complex Survey Samples}},
volume = {9},
year = {2004}
}
@incollection{Pascale2015,
address = {Rennes},
author = {Pascale, Okamura-Tr{\'{e}}visiol},
booktitle = {Les subordonn{\'{e}}es: Corpus, aquisition et didactique},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Pascale/Pascale{\_}2015{\_}L'aquisition et l'enseignement des relatives en FLE Regardes crois{\'{e}}s.pdf:pdf},
pages = {103--120},
publisher = {Presses Universitaires de Rennes},
title = {{L'aquisition et l'enseignement des relatives en FLE: Regardes crois{\'{e}}s}},
year = {2015}
}
@inproceedings{Ferrari2009,
address = {Lancaster},
author = {Ferrari, Stefania and Nuzzo, Elena},
booktitle = {Task Based Language Teaching Conference},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ferrari, Nuzzo/Ferrari, Nuzzo{\_}2009{\_}Meeting the challenge of diversity with TBLT Connecting speaking and writing in mainstream classrooms.pdf:pdf},
title = {{Meeting the challenge of diversity with TBLT: Connecting speaking and writing in mainstream classrooms}},
year = {2009}
}
@manual{Ratnakumar2016,
annote = {R package version 0.3.1},
author = {Ratnakumar, Sridhar and Mick, Trent and Davis, Trevor},
title = {{rappdirs: Application Directories: Determine Where to Save Data, Caches, and Logs}},
url = {https://cran.r-project.org/package=rappdirs},
year = {2016}
}
@article{Xanthos2010,
abstract = {This study introduces a new metric for assessing the inflectional diversity of morphologically analyzed language transcripts. The proposed metric is based on the intuitive notion of mean size of paradigm (MSP) and makes extensive use of random sampling procedures for normalization purposes. This approach is systematically evaluated on the basis of large sets of Dutch acquisition corpora, including both child speech and child-directed speech. It is shown to be an efficient way of controlling for sample size in the measurement of inflectional diversity, as well as a suitable method for assessing inflectional development in longitudinal data. MSP is compared with ID (inflectional diversity) introduced by Malvern, Richards, Chipere, and Dur{\'{a}}n (2004). {\textcopyright} The Author(s) 2010.},
author = {Xanthos, Aris and Gillis, Steven},
doi = {10.1177/0142723709359236},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Xanthos, Gillis/Xanthos, Gillis{\_}2010{\_}Quantifying the development of inflectional diversity.pdf:pdf},
issn = {01427237},
journal = {First Language},
keywords = {Developmental variables,Inflectional diversity,Longitudinal corpora,Mean size of paradigm,Random sampling},
number = {2},
pages = {175--198},
title = {{Quantifying the development of inflectional diversity}},
volume = {30},
year = {2010}
}
@article{Hothorn2006,
author = {Hothorn, Torsten and Buehlmann, Peter and Dudoit, Sandrine and Molinaro, Annette and {Van Der Laan}, Mark},
journal = {Biostatistics},
keywords = {cforest},
mendeley-tags = {cforest},
number = {3},
pages = {355--373},
title = {{Survival Ensembles}},
volume = {7},
year = {2006}
}
@manual{Garnier2018a,
annote = {R package version 0.3.0},
author = {Garnier, Simon},
title = {{viridisLite: Default Color Maps from 'matplotlib' (Lite Version)}},
url = {https://cran.r-project.org/package=viridisLite},
year = {2018}
}
@article{Kyle2015,
abstract = {This study explores the construct of lexical sophistication and its applications for measuring second language lexical and speaking proficiency. In doing so, the study introduces the Tool for the Automatic Analysis of LExical Sophistication (TAALES), which calculates text scores for 135 classic and newly developed lexical indices related to word frequency, range, bigram and trigram frequency, academic language, and psycholinguistic word information. TAALES is freely available; runs on Windows, Mac, and Linux operating systems; and has a simple graphic user interface that allows for batch processing of .txt files. The tool is fast, reliable, and outputs results to a comma-separated value file that can be accessed using spreadsheet software. The study examines the ability of TAALES indices to explain the variance in human judgments of lexical proficiency and speaking proficiency for second language (L2) learners. Overall, these indices were able to explain 47.5{\%} of the variance in holistic scores of lexical proficiency and 48.7{\%} of the variance in holistic scores of speaking proficiency. This study has important implications for second language acquisition, for assessing L2 learners' productive skills (writing and speaking), and for L2 pedagogy. Limitations and future directions are also discussed.},
author = {Kyle, Kristopher and Crossley, Scott A.},
doi = {10.1002/tesq.194},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kyle, Crossley/Kyle, Crossley{\_}2015{\_}Automatically Assessing Lexical Sophistication Indices, Tools, Findings, and Application.pdf:pdf},
isbn = {1545-7249},
issn = {15457249},
journal = {TESOL Quarterly},
keywords = {taales},
mendeley-tags = {taales},
number = {4},
pages = {757--786},
pmid = {23535757},
title = {{Automatically Assessing Lexical Sophistication: Indices, Tools, Findings, and Application}},
volume = {49},
year = {2015}
}
@inproceedings{Tutin2013,
abstract = {This paper presents an on-going project of corpus-cum-dictionary in the field of academic multiword expressions in French. This project is a lexicographic and pedagogical application of the Scientext corpus and aims to provide writing tools to help academic learners of French as a foreign language to produce high quality texts. Our system is based on a large syntactically annotated corpus and provides an onomasiological and a semasiological access to phraseological entries, including corpus examples stored in dynamic web pages.},
address = {Tallinn},
author = {Tutin, A and Falaise, Achille},
booktitle = {Elex},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Tutin, Falaise/Tutin, Falaise{\_}2013{\_}Multiword expressions in scientific discourse a corpus-driven database.pdf:pdf},
isbn = {978-1-932432-87-9},
keywords = {attitudinal multiword expressions,collocations,corpora,multiword expressions},
pages = {1--6},
title = {{Multiword expressions in scientific discourse: a corpus-driven database}},
url = {http://hal.archives-ouvertes.fr/hal-00953810/},
year = {2013}
}
@article{Polat2019,
author = {Polat, Nihat and Mahalingappa, Laura and Mancilla, Rae L.},
doi = {10.1093/applin/amz034},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Polat, Mahalingappa, Mancilla/Polat, Mahalingappa, Mancilla{\_}2019{\_}Longitudinal Growth Trajectories of Written Syntactic Complexity The Case of Turkish Learners in an.pdf:pdf},
journal = {Applied Linguistics},
number = {0},
pages = {1--25},
title = {{Longitudinal Growth Trajectories of Written Syntactic Complexity : The Case of Turkish Learners in an Intensive English Program}},
volume = {0},
year = {2019}
}
@manual{Cheng2019,
annote = {R package version 0.8.0},
author = {Cheng, Joe and Chang, Winston},
title = {{later: Utilities for Delaying Function Execution}},
url = {https://cran.r-project.org/package=later},
year = {2019}
}
@article{Ishwaran2007,
author = {Ishwaran, H and Kogalur, U B},
journal = {R News},
month = {oct},
number = {2},
pages = {25--31},
title = {{Random survival forests for R}},
url = {https://cran.r-project.org/doc/Rnews/},
volume = {7},
year = {2007}
}
@article{Garner2018,
author = {Garner, James and Crossley, Scott A. and Kyle, Kristopher},
doi = {10.1016/j.system.2018.12.001},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Garner, Crossley, Kyle/Garner, Crossley, Kyle{\_}2018{\_}N-gram measures and L2 writing proficiency.pdf:pdf},
issn = {0346251X},
journal = {System},
pages = {176--187},
title = {{N-gram measures and L2 writing proficiency}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0346251X1830201X},
volume = {80},
year = {2018}
}
@incollection{Hulstijn2010,
author = {Hulstijn, Jan H},
booktitle = {Communicative proficiency and linguistic development : Intersections between SLA and language testing},
editor = {Bartning, Inge and Martin, Maisa and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hulstijn/Hulstijn{\_}2010{\_}Linking L2 proficiency to L2 acquisition Opportunities and challenges of profiling research 1.pdf:pdf},
pages = {233--238},
publisher = {European Second Language Association},
title = {{Linking L2 proficiency to L2 acquisition : Opportunities and challenges of profiling research 1}},
volume = {1},
year = {2010}
}
@manual{Wickham2019f,
annote = {R package version 0.4.0},
author = {Wickham, Hadley},
title = {{forcats: Tools for Working with Categorical Variables (Factors)}},
url = {https://cran.r-project.org/package=forcats},
year = {2019}
}
@article{Blanche-Benveniste1999,
author = {Blanche-Benveniste, Claire and Adam, J-P},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Blanche-Benveniste, Adam/Blanche-Benveniste, Adam{\_}1999{\_}La conjugaison des verbes Virtuelle, attestée, defective The conjugation of verbs Virtual, attested, def.pdf:pdf},
journal = {Recherches sur le français parlé},
pages = {87--112},
title = {{La conjugaison des verbes: Virtuelle, attestée, defective [The conjugation of verbs: Virtual, attested, defective]}},
volume = {15},
year = {1999}
}
@manual{Chang2018,
annote = {R package version 0.5.1},
author = {Chang, Winston},
title = {{webshot: Take Screenshots of Web Pages}},
url = {https://cran.r-project.org/package=webshot},
year = {2018}
}
@article{Bartning2009,
author = {Bartning, Inge and Forsberg, Fanny and Hancock, Victorine},
doi = {10.1075/eurosla.9.10bar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Forsberg, Hancock/Bartning, Forsberg, Hancock{\_}2009{\_}Resources and obstacles in very advanced French Formulaic language, information structure and morphosyn.pdf:pdf},
issn = {15681491},
journal = {EUROSLA Yearbook},
number = {2004},
pages = {185--211},
title = {{Resources and obstacles in very advanced French: Formulaic language, information structure and morphosyntax}},
volume = {9},
year = {2009}
}
@article{Ehret2016,
abstract = {We present a proof-of-concept study that sketches the use of compression algorithms to assess Kolmogorov complexity, which is a text-based, quantitative, holistic, and global measure of structural surface redundancy. Kolmogorov complexity has been used to explore cross-linguistic complexity variation in linguistic typology research, but we are the first to apply it to naturalistic second language acquisition (SLA) data. We specifically investigate the relationship between the complexity of second language (L2) English essays and the amount of instruction the essay writers have received. Analysis shows that increased L2 instructional exposure predicts increased overall complexity and increased morphological complexity, but decreased syntactic complexity (defined here as less rigid word order). While the relationship between L2 instructional exposure and complexity is robust across a number of first language (L1) backgrounds, L1 background does predict overall complexity levels.},
author = {Ehret, Katharina and Szmrecsanyi, Benedikt},
doi = {10.1177/0267658316669559},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ehret, Szmrecsanyi/Ehret, Szmrecsanyi{\_}2016{\_}Compressing learner language An information-theoretic measure of complexity in SLA production data.pdf:pdf},
journal = {Second Language Research},
number = {Special Issue},
pages = {1--23},
title = {{Compressing learner language: An information-theoretic measure of complexity in SLA production data}},
url = {https://journals.sagepub.com/doi/pdf/10.1177/0267658316669559},
year = {2016}
}
@article{Coltheart1981,
author = {Coltheart, M},
journal = {Quarterly Journal of Experimental Psychology Section A},
number = {4},
pages = {497--505},
title = {{The MRC Psycholinguistics Database}},
volume = {33},
year = {1981}
}
@article{Grolemund2011,
author = {Grolemund, Garrett and Wickham, Hadley},
journal = {Journal of Statistical Software},
number = {3},
pages = {1--25},
title = {{Dates and Times Made Easy with {\{}lubridate{\}}}},
url = {http://www.jstatsoft.org/v40/i03/},
volume = {40},
year = {2011}
}
@book{Mitchell2017,
address = {London},
author = {Mitchell, Rosamond and Tracy-Ventura, Nicole and McManus, Kevin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mitchell, Tracy-Ventura, McManus/Mitchell, Tracy-Ventura, McManus{\_}2017{\_}Anglophone students abroad.pdf:pdf},
keywords = {langsnap},
mendeley-tags = {langsnap},
publisher = {Routledge},
title = {{Anglophone students abroad}},
year = {2017}
}
@article{Monroe1975,
author = {Monroe, James H},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Monroe/Monroe{\_}1975{\_}Measuring and Enhancing Syntactic Fluency in French.pdf:pdf},
journal = {The French Review},
number = {6},
pages = {1023--1031},
title = {{Measuring and Enhancing Syntactic Fluency in French}},
volume = {48},
year = {1975}
}
@incollection{Gries2019a,
abstract = {In this chapter, we provide an overview of quantitative approaches to co-occurrence data. We begin with a brief terminological overview of different types of co-occurrence that are prominent in corpus-linguistic studies and then discuss the computation of some widely-used measures of association used to quantify co-occurrence. We present two representative case studies, one exploring lexical collocation and learner proficiency, the other creative uses of verbs with argument structure constructions. In addition, we highlight how most widely-used measures actually all fall out from viewing corpus-linguistic association as an instance of regression modeling and discuss newer developments and potential improvements of association measure research such as utilizing directional measures of association, not uncritically conflating frequency and association-strength information in association measures, type frequencies, and entropies.},
address = {Berlin},
author = {Gries, Stefan Th. and Durrant, Philip},
booktitle = {Practical handbook of corpus linguistics (preprint)},
editor = {Gries, Stefan Th. and Paquot, Magali},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries, Durrant/Gries, Durrant{\_}2019{\_}Analyzing co-occurrence data.pdf:pdf},
publisher = {Springer},
title = {{Analyzing co-occurrence data}},
year = {2019}
}
@manual{Wickham2019t,
annote = {R package version 1.4.1},
author = {Wickham, Hadley},
title = {{httr: Tools for Working with URLs and HTTP}},
url = {https://cran.r-project.org/package=httr},
year = {2019}
}
@incollection{Bardel2018,
address = {Cambridge},
author = {Bardel, Camilla and Gudmundson, Anna},
booktitle = {High-level language proficiency in second language and multilingual contexts},
editor = {Hyltenstam, Kenneth and Fant, Lars and Bartning, Inge},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bardel, Gudmundson/Bardel, Gudmundson{\_}2018{\_}Developing Lexical Complexity in Oral Production Limitations and Possibilities of the Advanced L2 Learner.pdf:pdf},
isbn = {9781316809686},
pages = {120--145},
publisher = {Cambridge University Press},
title = {{Developing Lexical Complexity in Oral Production: Limitations and Possibilities of the Advanced L2 Learner}},
year = {2018}
}
@manual{Jeppson2018,
annote = {R package version 0.2.0},
author = {Jeppson, Haley and Hofmann, Heike and Cook, Di},
title = {{ggmosaic: Mosaic Plots in the 'ggplot2' Framework}},
url = {https://cran.r-project.org/package=ggmosaic},
year = {2018}
}
@manual{Ishwaran2019,
annote = {R package version 2.9.1},
author = {Ishwaran, H and Kogalur, U B},
publisher = {manual},
title = {{Fast Unified Random Forests for Survival, Regression, and Classification (RF-SRC)}},
url = {https://cran.r-project.org/package=randomForestSRC},
year = {2019}
}
@manual{Cheng2018,
annote = {R package version 0.1.1.1},
author = {Cheng, Joe},
title = {{miniUI: Shiny UI Widgets for Small Screens}},
url = {https://cran.r-project.org/package=miniUI},
year = {2018}
}
@article{Xu2018,
author = {Xu, Yiran},
doi = {10.1016/j.system.2018.11.008},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Xu/Xu{\_}2018{\_}Changes in interlanguage complexity during study abroad A meta-analysis preprint.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Xu/Xu{\_}2018{\_}Changes in interlanguage complexity during study abroad A meta-analysis preprint(2).pdf:pdf},
issn = {0346251X},
journal = {System},
publisher = {Elsevier Ltd},
title = {{Changes in interlanguage complexity during study abroad: A meta-analysis [preprint]}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0346251X18306420},
year = {2018}
}
@article{Thevenin1999,
abstract = {La morphologie joue un r{\^{o}}le essentiel en Fran{\c{c}}ais {\`{a}} l'{\'{e}}crit. En effet, de nombreuses marques morphologiques n'ont pas de correspondant oral. Ceci est le cas des flexions du nombre: -s pour le pluriel des noms et adjectifs et -nt pour les verbes {\`{a}} la troisi{\`{e}}me personne du pr{\'{e}}sent de /'indicatif. Des recherches ant{\'{e}}rieures (Totereau, Th{\'{e}}venin et Fayol, 1997; Totereau, Fayol et Barrouillet, 1998) ont montr{\'{e}} que d'une part, l'interpr{\'{e}}tation de ces marques pr{\'{e}}c{\`{e}}de leur production, que le traitement de la flexion nominale (-s) est plus pr{\'{e}}coce et mieux assur{\'{e}} que celui de la flexion adjectivale (-s), et que l'apparition de la flexion verbale (-nt) est encore plus tardive. D'autre part, ces {\'{e}}tudes ont permis d'observer des erreurs de surg{\'{e}}n{\'{e}}ralisations : utilisation erron{\'{e}}e des flexions d'abord nominale aux verbes (Us timbres) et, plus tard et plus rarement, de la flexion verbale aux noms et adjectifs (les timbrent rougent). Toutes ces recherches pr{\'{e}}sentent une insuffisance majeure: les conditions de l'apprentissage n'y ont pas {\'{e}}t{\'{e}} contr{\^{o}}l{\'{e}}es. L'exp{\'{e}}rience rapport{\'{e}}e ici vise pr{\'{e}}cis{\'{e}}ment {\`{a}} tester que l'acquisition de la morpho- logie du nombre {\`{a}} J'{\'{e}}crit par des enfants de la premi{\`{e}}re {\`{a}} /a troisi{\`{e}}me ann{\'{e}}es primaires s'effectue de mani{\`{e}}re plus pr{\'{e}}coce et rapide lorsque d'une part, les r{\`{e}}gles d'accord donnent lieu {\`{a}} une instruction directe plut{\^{o}}t qu'{\`{a}} une" simple" impr{\'{e}}gnation par l'{\'{e}}crit (Groupe Contr{\^{o}}le) ; et d'autre part, que l'apprentissage est plus efficace lorsqu'il comporte des {\'{e}}valuations et corrections explicites (Groupe avec feed-back) en plus de l'enseignement direct des r{\`{e}}gles et de la pratique d'exercices (Groupe sans feed-back). Les r{\'{e}}sultats montrent que l'introduction d'une instruction directe assortie d'exercices (Groupe sans feed-back et groupe avec feed-back) entra{\^{I}}ne tr{\'{e}}s pr{\'{e}}cocement des modifications profondes des performances: le non-marquage dispara{\^{I}}t d{\`{e}}s la premi{\`{e}}re ann{\'{e}}e primaire, la fr{\'{e}}quence des accords exacts augmente pour toutes les cat{\'{e}}gories grammaticales. L},
author = {Thevenin, Marie-Genevi{\`{e}}ve and Totereau, Corinne and Jarousse, Jean-Pierre and Fayol, Michel},
doi = {10.3406/rfp.1999.1093},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Thevenin et al/Thevenin et al.{\_}1999{\_}L'apprentissageenseignement de la morphologie {\'{e}}crite du nombre en fran{\c{c}}ais.pdf:pdf},
issn = {0556-7807},
journal = {Revue fran{\c{c}}aise de p{\'{e}}dagogie},
number = {1},
pages = {39--52},
title = {{L'apprentissage/enseignement de la morphologie {\'{e}}crite du nombre en fran{\c{c}}ais}},
volume = {126},
year = {1999}
}
@article{Housen2016a,
author = {Ellis, Nick C},
doi = {10.1017/S027226311600005X},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis/Ellis{\_}2016{\_}Salience, cognition, language complexity, and complex adaptive systems.pdf:pdf},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
pages = {341--351},
title = {{Salience, cognition, language complexity, and complex adaptive systems}},
volume = {38},
year = {2016}
}
@incollection{Treffers-Daller2013a,
address = {Amsterdam/Philidelphia},
author = {Treffers-Daller, Jeanine},
booktitle = {Vocabulary knowledge: Human ratings and automated measures},
editor = {Jarvis, S and Daller, M},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Treffers-Daller/Treffers-Daller{\_}2013{\_}Measuring lexical diversity among L2 learners of French an exploration of the validity of D, MTLD and HD-D as measu.pdf:pdf},
keywords = {stats},
mendeley-tags = {stats},
pages = {79--104},
publisher = {John Benjamins},
title = {{Measuring lexical diversity among L2 learners of French: an exploration of the validity of D, MTLD and HD-D as measures of language ability.}},
year = {2013}
}
@manual{Csardi2019b,
annote = {R package version 2.0.3},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and Podg{\'{o}}rski, Kuba and Geldreich, Rich},
title = {{zip: Cross-Platform 'zip' Compression}},
url = {https://cran.r-project.org/package=zip},
year = {2019}
}
@incollection{Rubin2019,
author = {Rubin, Rachel and Housen, Alex and Paquot, Magali},
booktitle = {Perspectives on the Second Language Phrasicon: The View from Learner Corpora},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Rubin, Housen, Paquot/Rubin, Housen, Paquot{\_}Unknown{\_}Phraseological complexity as an index of L2 Dutch writing proficiency A partial replication study.docx:docx},
title = {{Phraseological complexity as an index of L2 Dutch writing proficiency: A partial replication study}}
}
@article{Griesa,
author = {Gries, Stefan Th.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}Unknown{\_}On classification trees and random forests in corpus linguistics some words of caution and suggestions for improvement.pdf:pdf},
journal = {Corpus Linguistics and Linguistic Theory},
pages = {1--24},
title = {{On classification trees and random forests in corpus linguistics: some words of caution and suggestions for improvement}}
}
@manual{Bache2014,
annote = {R package version 1.5},
author = {Bache, Stefan Milton and Wickham, Hadley},
title = {{magrittr: A Forward-Pipe Operator for R}},
url = {https://cran.r-project.org/package=magrittr},
year = {2014}
}
@article{Holst2019,
author = {Holst, Klaus K and Budtz-Joergensen, Esben},
doi = {10.1007/s00180-012-0344-y},
journal = {Biostatistics},
title = {{A two-stage estimation procedure for non-linear structural equation models}},
year = {2019}
}
@article{Laufer2011,
abstract = {The present study investigates the use of English verb-noun collocations in the writing of native speakers of Hebrew at three proficiency levels. For this purpose, we compiled a learner corpus that consists of about 300,000 words of argumentative and descriptive essays. For comparison purposes, we selected LOCNESS, a corpus of young adult native speakers of English. We retrieved the 220 most frequently occurring nouns in the LOCNESS corpus and in the learner corpus, created concordances for them, and extracted verb-noun collocations. Subsequently, we performed two types of comparisons: learners were compared with native speakers on the frequency of collocation use and learners were compared with other learners of different second-language proficiencies on the frequency and correctness of collocations. The data revealed that learners at all three proficiency levels produced far fewer collocations than native speakers, that the number of collocations increased only at the advanced level, and that errors, particularly interlingual ones, continued to persist even at advanced levels of proficiency. We discuss the results in light of the nature of collocations and communicative learning and suggest some pedagogical implications.},
author = {Laufer, Batia and Waldman, Tina},
doi = {10.1111/j.1467-9922.2010.00621.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Laufer, Waldman/Laufer, Waldman{\_}2011{\_}Verb-Noun Collocations in Second Language Writing A Corpus Analysis of Learners' English.pdf:pdf},
isbn = {0023-8333},
issn = {00238333},
journal = {Language Learning},
keywords = {Collocations,Corpus analysis,Foreign language lexical development,Foreign language writing,Lexis,Multiword units,Verb-noun collocations,Vocabulary},
number = {2},
pages = {647--672},
title = {{Verb-Noun Collocations in Second Language Writing: A Corpus Analysis of Learners' English}},
volume = {61},
year = {2011}
}
@article{Housen2009,
author = {Housen, Alex and Kuiken, Folkert},
doi = {10.1093/applin/amp048},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Housen, Kuiken/Housen, Kuiken{\_}2009{\_}Complexity, Accuracy, and Fluency in Second Language Acquisition.pdf:pdf},
issn = {01426001},
journal = {Applied Linguistics},
number = {4},
pages = {461--473},
title = {{Complexity, Accuracy, and Fluency in Second Language Acquisition}},
volume = {30},
year = {2009}
}
@manual{Gamer2019a,
annote = {R package version 0.84.1},
author = {Gamer, Matthias and Lemon, Jim and {\textless}puspendra.pusp22@gmail.com{\textgreater}, Ian Fellows Puspendra Singh},
title = {{irr: Various Coefficients of Interrater Reliability and Agreement}},
url = {https://cran.r-project.org/package=irr},
year = {2019}
}
@techreport{Gries,
author = {Gries, Stefan Th.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}Unknown{\_}Managing synchronic corpus data with the British National Corpus (BNC).pdf:pdf},
pages = {1--12},
title = {{Managing synchronic corpus data with the British National Corpus (BNC)}}
}
@incollection{Malvern1997,
address = {Clevedon},
author = {Malvern, D and Richards, B},
booktitle = {Evolving Models of Language},
editor = {Ryan, A and Wray, A},
keywords = {lexdiv{\_}D},
mendeley-tags = {lexdiv{\_}D},
pages = {58--71},
publisher = {Multilingual Matters},
title = {{A New Measure of Lexical Diversity}},
year = {1997}
}
@article{Bates2013,
author = {Bates, Douglas and Eddelbuettel, Dirk},
journal = {Journal of Statistical Software},
number = {5},
pages = {1--24},
title = {{Fast and Elegant Numerical Linear Algebra Using the {\{}RcppEigen{\}} Package}},
url = {http://www.jstatsoft.org/v52/i05/},
volume = {52},
year = {2013}
}
@article{Paquot2012,
abstract = {Formulaic language is at the heart of corpus linguistic research, and learner corpus research (LCR) is no exception. As multiword units of all kinds (e.g., collocations, phrasal verbs, speech formulae) are notoriously difficult for learners, and corpus linguistic techniques are an extremely powerful way of exploring them, they were an obvious area for investigation by researchers from the very early days of LCR. In the first part of this article, the focus is on the types of learner corpus data investigated and the most popular method used to analyze them. The second section describes the types of word sequences analyzed in learner corpora and the methodologies used to extract them. In the rest of the article, we summarize some of the main findings of LCR studies of the learner phrasicon, distinguishing between co-occurrence and recurrence. Particular emphasis is also placed on the relationship between learners' use of formulaic sequences and transfer from the learner's first language. The article concludes with some proposals for future research in the field. Copyright {\textcopyright} 2012 Cambridge University Press.},
author = {Paquot, Magali and Granger, Sylviane},
doi = {10.1017/S0267190512000098},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot, Granger/Paquot, Granger{\_}2012{\_}Formulaic language in learner corpora.pdf:pdf},
issn = {02671905},
journal = {Annual Review of Applied Linguistics},
number = {2012},
pages = {130--149},
title = {{Formulaic language in learner corpora}},
volume = {32},
year = {2012}
}
@manual{Hornik2019,
annote = {R package version 0.1-45},
author = {Hornik, Kurt and Meyer, David and Buchta, Christian},
title = {{slam: Sparse Lightweight Arrays and Matrices}},
url = {https://cran.r-project.org/package=slam},
year = {2019}
}
@article{Zarco-Tejada2018,
author = {Zarco-Tejada, Maria Angeles},
doi = {10.1093/llc/fqy067},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Zarco-Tejada/Zarco-Tejada{\_}2018{\_}Automatic profiling of L2-simplified texts Identifying discriminate features of linguistic proficiency.pdf:pdf},
issn = {2055-7671},
journal = {Digital Scholarship in the Humanities},
title = {{Automatic profiling of L2-simplified texts: Identifying discriminate features of linguistic proficiency}},
url = {https://academic.oup.com/dsh/advance-article/doi/10.1093/llc/fqy067/5224800},
year = {2018}
}
@incollection{Ayres-Bennett2004,
address = {Cambridge},
author = {Ayres-Bennett, Wendy},
booktitle = {Sociolinguistic Variation in Seventeenth-Century France},
doi = {10.1017/cbo9780511486630.003},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ayres-Bennett/Ayres-Bennett{\_}2004{\_}Spoken and written French.pdf:pdf},
isbn = {9780511486630},
number = {May},
pages = {17--60},
publisher = {Cambridge University Press},
title = {{Spoken and written French}},
year = {2004}
}
@manual{Eddelbuettel2019,
annote = {R package version 1.69.0-1},
author = {Eddelbuettel, Dirk and Emerson, John W and Kane, Michael J},
title = {{BH: Boost C++ Header Files}},
url = {https://cran.r-project.org/package=BH},
year = {2019}
}
@manual{Csardi2015a,
annote = {R package version 1.0.0},
author = {Csardi, Gabor and Sorhus, Sindre},
title = {{praise: Praise Users}},
url = {https://cran.r-project.org/package=praise},
year = {2015}
}
@article{Zeileis2004,
author = {Zeileis, Achim},
doi = {10.18637/jss.v011.i10},
journal = {Journal of Statistical Software},
number = {10},
pages = {1--17},
title = {{Econometric Computing with {\{}HC{\}} and {\{}HAC{\}} Covariance Matrix Estimators}},
volume = {11},
year = {2004}
}
@article{Dickinson2014,
abstract = {We present a strategy for dependency annotation of corpora of second language learners, dividing the annotation into different layers and separating linguistic constraints from realizations. Specifically, subcategorization information is required to compare to the annotation of realized dependencies. Building from this, we outline dependency annotation for coordinate structures, detailing a number of constructions such as right node raising and the coordination of unlikes. We conclude that branching structures are preferable to treating the conjunct as the head, as this avoids duplicating annotation.},
author = {Dickinson, Markus and Ragheb, Marwa},
doi = {10.1075/la.215.08dic},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dickinson, Ragheb/Dickinson, Ragheb{\_}2014{\_}Dependency annotation of coordination for learner language.pdf:pdf},
pages = {161--182},
title = {{Dependency annotation of coordination for learner language}},
year = {2014}
}
@article{Batista2016,
abstract = {Researchers have developed several tests of receptive vocabulary knowledge suitable for use with learners of English, but options are few for learners of French. This situation motivated the authors to create a new vocabulary size measure for French, the Test de la taille du vocabulaire (TTV). The measure is closely modelled on Nation's (1983) Vocabulary Levels Test (VLT) and follows the guidelines written by Schmitt, Schmitt, and Clapham (2001). Initially, a pilot version was trialled with 63 participants; then an improved version was administered to 175 participants at four proficiency levels. Results attest to the TTV's validity: mean scores across the four frequency sections decreased as the tested words became less frequent, and more proficient learner groups outperformed less proficient groups. The TTV in its current form is intended to be of practical use to teachers and learners, but it is also expected to evolve; ideas for future improvements are discussed.},
author = {Batista, Roselene and Horst, Marlise},
doi = {10.3138/cmlr.2820},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Batista, Horst/Batista, Horst{\_}2016{\_}A new receptive vocabulary size test for French.pdf:pdf},
issn = {17101131},
journal = {Canadian Modern Language Review},
keywords = {Assessment,French L2 vocabulary,Frequency,Vocabulary size},
number = {2},
pages = {211--233},
title = {{A new receptive vocabulary size test for French}},
volume = {72},
year = {2016}
}
@article{Wiechmann2008,
abstract = {Collostruction strength, i.e. the degree of attraction that a word Cj exhibits to a construction Ck, has been argued to be exploited in processes of on-line comprehension, for example, to parse ambiguous structures. There are, however, many ways to express this quantity and a large body of candidate measures can be found in the computational and corpus linguistic literature. The present study provides a comprehensive empirical evaluation of 47 competing (variants of) measures of association in order to assess their usefulness for models of sentence comprehension. To that end, the degree of adequacy of a given measure is evaluated against its performance in a task of predicting human behavior in an eye-tracking experiment that investigated the reading of a local syntactic complementation ambiguity (Kennison 2001). The analysis shows that individual measures in fact arrive at different estimations of degrees of attraction between verbs and the relevant complementation patterns, and hence differ in their power to predict human reading behavior. On the basis of the obtained results, it is suggested that minimum sensitivity (Pedersen and Bruce 1996) is best suited as an expression of collostruction strength. {\textcopyright} Walter de Gruyter.},
author = {Wiechmann, Daniel},
doi = {10.1515/CLLT.2008.011},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wiechmann/Wiechmann{\_}2008{\_}On the computation of construction strength Testing measures of association as expressions of lexical bias.pdf:pdf},
issn = {16137027},
journal = {Corpus Linguistics and Linguistic Theory},
keywords = {Association measures,Collostruction strength,Language processing,Sentence comprehension},
number = {2},
pages = {253--290},
title = {{On the computation of construction strength: Testing measures of association as expressions of lexical bias}},
volume = {4},
year = {2008}
}
@manual{Rinker2018,
address = {Buffalo, New York},
annote = {version 0.9.0},
author = {Rinker, Tyler W},
title = {{{\{}textreadr{\}}: Read Text Documents into R}},
url = {http://github.com/trinker/textreadr},
year = {2018}
}
@article{Matthews2018,
abstract = {Despite the current potential to use computers to automatically generate a large range of text-based indices, many issues remain unresolved about how to apply these data in established language teaching and assessment contexts. One way to resolve these issues is to explore the degree to which automatically generated indices, which are reflective of key measures of text quality, align with parallel measures derived from locally relevant, human evaluations of texts. This study describes the automated evaluation of 104 English as a second language texts through use of the computational tool Coh-Metrix, which was used to generate indices reflecting text cohesion, lexical characteristics, and syntactic complexity. The same texts were then independently evaluated by two experienced human assessors through use of an analytic scoring rubric. The interrelationships between the computer and human generated evaluations of the texts are presented in this paper with a particular focus on the automatically generated indices that were most strongly linked to the human generated measures. A synthesis of these findings is then used to discuss the role that such automated evaluation may have in the teaching and assessment of second language writing.},
author = {Matthews, Joshua and Wijeyewardene, Ingrid},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Matthews, Wijeyewardene/Matthews, Wijeyewardene{\_}2018{\_}Exploring relationships between automated and human evaluations of L2 texts.pdf:pdf},
issn = {10943501},
journal = {Language Learning {\&} Technology},
keywords = {143,158,2018,22,3,Assessment/Testing,Language Teaching Methodology,Research Methods,Writing,and,apa citation,assessment,english,exploring relationships between automated,human evaluations of l2,i,j,language,language learning,language teaching methodology,learned in this study,matthews,research methods,s,technology,testing,texts,wijeyewardene,writing},
number = {3},
pages = {143--158},
title = {{Exploring relationships between automated and human evaluations of L2 texts}},
volume = {22},
year = {2018}
}
@manual{Venables2019,
annote = {R package version 1.4-0. S original by Bill Venables, packages for R by Kurt Hornik and Martin Maechler.},
author = {Venables, Bill and Hornik, Kurt and Maechler, Martin},
title = {{polynom: A Collection of Functions to Implement a Class for Univariate Polynomial Manipulations}},
url = {https://cran.r-project.org/package=polynom},
year = {2019}
}
@article{Fox2003,
author = {Fox, John},
journal = {Journal of Statistical Software},
number = {15},
pages = {1--27},
title = {{Effect Displays in {\{}R{\}} for Generalised Linear Models}},
url = {http://www.jstatsoft.org/v08/i15/},
volume = {8},
year = {2003}
}
@phdthesis{Gayraud2000,
address = {Lyon},
author = {Gayraud, Fr{\'{e}}d{\'{e}}rique},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gayraud/Gayraud{\_}2000{\_}Le d{\'{e}}veloppement de la diff{\'{e}}renciation oral{\'{e}}crit vu {\`{a}} travers le lexique.pdf:pdf},
school = {(Unpublished doctoral dissertation). Universit{\'{e}} Lumi{\`{e}}re},
title = {{Le d{\'{e}}veloppement de la diff{\'{e}}renciation oral/{\'{e}}crit vu {\`{a}} travers le lexique}},
year = {2000}
}
@incollection{Raupach1984,
address = {Tubingen},
author = {Raupach, M},
booktitle = {Second language productions},
editor = {Dechert, Hans W. and Mohle, Dorothea and Raupach, Manfred},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Raupach/Raupach{\_}1984{\_}Formulae in second language speech production.pdf:pdf},
pages = {114--137},
publisher = {Gunter Nar},
title = {{Formulae in second language speech production}},
year = {1984}
}
@article{Futrell2015,
abstract = {Explaining the variation between human languages and the constraints on that variation is a core goal of linguistics. In the last 20 y, it has been claimed that many striking universals of cross-linguistic variation follow from a hypothetical principle that dependency length-the distance between syntactically related words in a sentence-is minimized. Various models of human sentence production and comprehension predict that long dependencies are difficult or inefficient to process; minimizing dependency length thus enables effective communication without incurring processing difficulty. However, despite widespread application of this idea in theoretical, empirical, and practical work, there is not yet large-scale evidence that dependency length is actually minimized in real utterances across many languages; previous work has focused either on a small number of languages or on limited kinds of data about each language. Here, using parsed corpora of 37 diverse languages, we show that overall dependency lengths for all languages are shorter than conservative random baselines. The results strongly suggest that dependency length minimization is a universal quantitative property of human languages and support explanations of linguistic variation in terms of general properties of human information processing.},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Futrell, Richard and Mahowald, Kyle and Gibson, Edward},
doi = {10.1073/pnas.1502134112},
eprint = {arXiv:1408.1149},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Futrell, Mahowald, Gibson/Futrell, Mahowald, Gibson{\_}2015{\_}Large-scale evidence of dependency length minimization in 37 languages.pdf:pdf},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {33},
pages = {10336--10341},
pmid = {26240370},
title = {{Large-scale evidence of dependency length minimization in 37 languages}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1502134112},
volume = {112},
year = {2015}
}
@inproceedings{Schaefer2015b,
abstract = {In this paper, I present the COW14 tool chain, which comprises a web corpus creation tools called texrex, wrappers for existing linguistic annotation tools as well as an online query software called Colibri2 . By detailed descriptions of the implementation and systematic evaluations of the performance of the software on different types of systems, I show that the COW14 architecture is capable of handling the creation of corpora of up to at least 100 billion tokens. I also introduce our running demo system which currently serves corpora of up to roughly 20 billion tokens in Dutch, Englisch, French, German, Spanish, and Swedish.},
address = {Lancaster},
author = {Sch{\"{a}}fer, Roland},
booktitle = {Proceedings of challenges in the management of large corpora 3 (CMLC-3)},
editor = {Ba{\'{n}}ski, Piotr and Biber, Hanno and Breiteneder, Evelyn and Kupietz, Marc and L{\"{u}}ngen, Harald and Witt, Andreas},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Sch{\"{a}}fer/Sch{\"{a}}fer{\_}2015{\_}Processing and querying large web corpora with the COW14 architecture(2).pdf:pdf},
keywords = {frcow},
mendeley-tags = {frcow},
organization = {UCREL},
publisher = {IDS},
title = {{Processing and querying large web corpora with the COW14 architecture}},
year = {2015}
}
@manual{Wickham2019l,
annote = {R package version 1.4.1},
author = {Wickham, Hadley},
title = {{httr: Tools for Working with URLs and HTTP}},
url = {https://cran.r-project.org/package=httr},
year = {2019}
}
@manual{Ooms2018a,
annote = {R package version 1.3},
author = {Ooms, Jeroen},
title = {{antiword: Extract Text from Microsoft Word Documents}},
url = {https://cran.r-project.org/package=antiword},
year = {2018}
}
@manual{Stephens2018,
annote = {R package version 2.2.0},
author = {Stephens, Jeremy and Simonov, Kirill and Xie, Yihui and Dong, Zhuoer and Wickham, Hadley and Horner, Jeffrey and Reikoch and Beasley, Will and O'Connor, Brendan and Warnes, Gregory R},
title = {{yaml: Methods to Convert R Data to YAML and Back}},
url = {https://cran.r-project.org/package=yaml},
year = {2018}
}
@manual{Neuwirth2014,
annote = {R package version 1.1-2},
author = {Neuwirth, Erich},
title = {{RColorBrewer: ColorBrewer Palettes}},
url = {https://cran.r-project.org/package=RColorBrewer},
year = {2014}
}
@manual{Wickham2019p,
annote = {R package version 0.8.3},
author = {Wickham, Hadley and Fran{\c{c}}ois, Romain and Henry, Lionel and M{\"{u}}ller, Kirill},
title = {{dplyr: A Grammar of Data Manipulation}},
url = {https://cran.r-project.org/package=dplyr},
year = {2019}
}
@misc{Lumley2019a,
annote = {R package version 3.35-1},
author = {Lumley, Thomas},
title = {survey: analysis of complex survey samples},
year = {2019}
}
@article{Cumming2013,
author = {Cumming, Geoff},
doi = {10.1177/0956797613504966},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cumming/Cumming{\_}2013{\_}The New Statistics Why and How.pdf:pdf},
journal = {Psychological Science},
number = {???},
title = {{The New Statistics : Why and How}},
volume = {???},
year = {2013}
}
@article{Johnson1944,
author = {Johnson, W.},
journal = {Psychological Monographs},
keywords = {lexdiv{\_}msttr},
mendeley-tags = {lexdiv{\_}msttr},
pages = {1--15},
title = {{Studies in Language Behavior: I. A Program of Research}},
volume = {56},
year = {1944}
}
@manual{Csardi2018a,
annote = {R package version 1.1.1},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and Core, R and Wickham, Hadley and Chang, Winston and Flight, Robert M and M{\"{u}}ller, Kirill and Hester, Jim},
title = {{sessioninfo: R Session Information}},
url = {https://cran.r-project.org/package=sessioninfo},
year = {2018}
}
@article{Paquota,
author = {Paquot, Magali and Naets, Hubert and Gries, Stefan Th.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot, Naets, Gries/Paquot, Naets, Gries{\_}Unknown{\_}Using syntactic co-occurrences to trace phraseological complexity development in learner writing verb obje.pdf:pdf},
keywords = {stats},
mendeley-tags = {stats},
title = {{Using syntactic co-occurrences to trace phraseological complexity development in learner writing: verb + object structures in LONGDALE}}
}
@book{Eisenstein2018,
author = {Eisenstein, Jacob},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Eisenstein/Eisenstein{\_}2018{\_}Natural Language Processing.pdf:pdf},
title = {{Natural Language Processing}},
year = {2018}
}
@manual{Pedersen2020,
annote = {R package version 0.2.3},
author = {Pedersen, Thomas Lin and Ooms, Jeroen and Govett, Devon},
title = {{systemfonts: System Native Font Finding}},
url = {https://cran.r-project.org/package=systemfonts},
year = {2020}
}
@article{Bulte2018,
abstract = {The present study aims to contribute to a fuller understanding of how the L2 production of L2 learners varies over time in terms of syntactic complexity by analyzing a substantive number of English L2 writing samples (n = 11) produced by a sizable group of learners (n = 10) over a relatively long period of time (19 months), using a judicious selection of quantitative measures of syntactic complexity. The focus is on synchronic and diachronic variation, both within and across learners. Our analyses show that whereas development over time is relatively regular at the group level, individual developmental paths are characterized by a high degree of variability and often deviate from the mean group trends.},
author = {Bult{\'{e}}, Bram and Housen, Alex},
doi = {10.1111/ijal.12196},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}}, Housen/Bult{\'{e}}, Housen{\_}2018{\_}Syntactic complexity in L2 writing Individual pathways and emerging group trends.pdf:pdf},
isbn = {1473-4192},
issn = {14734192},
journal = {International Journal of Applied Linguistics (United Kingdom)},
keywords = {individual variation,longitudinal development,syntactic complexity},
number = {1},
pages = {147--164},
title = {{Syntactic complexity in L2 writing: Individual pathways and emerging group trends}},
volume = {28},
year = {2018}
}
@incollection{Broeder1993,
address = {Cambridge},
author = {Broeder, Peter and Extra, Guus and van Hout, Roeland},
booktitle = {Adult language acqusition: cross-linguistic perspectives},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Broeder, Extra, van Hout/Broeder, Extra, van Hout{\_}1993{\_}Richness and variety in the developing lexicon.pdf:pdf},
pages = {145--163},
publisher = {Cambridge University Press},
title = {{Richness and variety in the developing lexicon}},
volume = {1},
year = {1993}
}
@manual{Allaire2020a,
annote = {R package version 2.3},
author = {Allaire, J J and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
title = {{rmarkdown: Dynamic Documents for R}},
url = {https://github.com/rstudio/rmarkdown},
year = {2020}
}
@manual{Urbanek2013,
annote = {R package version 0.1-7},
author = {Urbanek, Simon},
title = {{png: Read and write PNG images}},
url = {https://cran.r-project.org/package=png},
year = {2013}
}
@book{Fox2019,
address = {Thousand Oaks CA},
author = {Fox, John and Weisberg, Sanford},
edition = {3rd},
publisher = {Sage},
title = {{An R Companion to Applied Regression}},
url = {http://tinyurl.com/carbook},
year = {2019}
}
@article{Baayen2011,
abstract = {{\textless}p{\textgreater}Three classifiers from machine learning (the generalized linear mixed model, memory based learning, and support vector machines) are compared with a naive discriminative learning classifier, derived from basic principles of error-driven learning characterizing animal and human learning. Tested on the dative alternation in English, using the Switchboard data from (BRESNAN; CUENI; NIKITINA; BAAYEN, 2007), naive discriminative learning emerges with stateof-the-art predictive accuracy. Naive discriminative learning offers a united framework for understanding the learning of probabilistic distributional patterns, for classification, and for a cognitive grounding of distinctive collexeme analysis.{\textless}/p{\textgreater}},
author = {Baayen, R. Harald},
doi = {10.1590/S1984-63982011000200003},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Baayen/Baayen{\_}2011{\_}Corpus linguistics and naive discriminative learning.pdf:pdf},
isbn = {0094243X (ISSN); 9780735407954 (ISBN)},
issn = {1984-6398},
journal = {Revista Brasileira de Lingu{\'{i}}stica Aplicada},
number = {2},
pages = {295--328},
title = {{Corpus linguistics and naive discriminative learning}},
url = {http://www.scielo.br/scielo.php?script=sci{\_}arttext{\&}pid=S1984-63982011000200003{\&}lng=en{\&}tlng=en},
volume = {11},
year = {2011}
}
@manual{Microsoft2019,
annote = {R package version 1.4.7},
author = {Microsoft and Weston, Steve},
title = {{foreach: Provides Foreach Looping Construct}},
url = {https://cran.r-project.org/package=foreach},
year = {2019}
}
@article{Ellis2014,
abstract = {We used free association and verbal fluency tasks to investigate verb-argument constructions (VACs) and the ways in which their processing is sensitive to statistical patterns of usage (verb type-token frequency distribution, VAC-verb contingency, verb-VAC semantic prototypicality). In experiment 1, 285 native speakers of English generated the first word that came to mind to fill the V slot in 40 sparse VAC frames such as 'he across the', 'it of the', etc. In experiment 2, 40 English speakers generated as many verbs that fit each frame as they could think of in a minute. For each VAC, we compared the results from the experiments with corpus analyses of verb selection preferences in 100 million words of usage and with the semantic network structure of the verbs in these VACs. For both experiments, multiple regression analyses predicting the frequencies of verb types generated for each VAC show independent contributions of (i) verb frequency in the VAC, (ii) VAC-verb contingency and (iii) verb prototypicality in terms of centrality within the VAC semantic network. VAC processing involves rich associations, tuned by verb type and token frequencies and their contingencies of usage, which interface syntax, lexis and semantics. We consider the implications for the mental representation of VACs. {\textcopyright} 2014 by Walter de Gruyter Berlin/Boston 2014.},
author = {Ellis, Nick C and O'Donnell, Matthew Brook and R{\"{o}}mer, Ute},
doi = {10.1515/cog-2013-0031},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, O'Donnell, R{\"{o}}mer/Ellis, O'Donnell, R{\"{o}}mer{\_}2014{\_}The processing of verb-argument constructions is sensitive to form, function, frequency, contingency and p.pdf:pdf},
issn = {09365907},
journal = {Cognitive Linguistics},
keywords = {Construction grammar,Contingency,Free association task,Frequency,Implicit learning,Semantic prototypicality,Tallying,Usage,Verb-argument constructions},
number = {1},
pages = {55--98},
title = {{The processing of verb-argument constructions is sensitive to form, function, frequency, contingency and prototypicality}},
volume = {25},
year = {2014}
}
@article{Lesterhuis2018,
author = {Lesterhuis, Marije and {Van Daal}, Tine and {Van Gasse}, Roos and Coertjens, Liesje and Donche, Vincent and {De Maeyer}, Sven},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lesterhuis et al/Lesterhuis et al.{\_}2018{\_}When Teachers Compare Argumentative Texts Decisions informed by multiple complex aspects of text quality.pdf:pdf},
journal = {L1-Educational Studies in Language and Literature},
keywords = {argumentative writing,comparative judgement,decision,teachers,text assessment,validity},
pages = {1--22},
title = {{When Teachers Compare Argumentative Texts: Decisions informed by multiple complex aspects of text quality}},
volume = {18},
year = {2018}
}
@article{Balvet2015,
author = {Balvet, A.},
doi = {10.1093/fs/knu291},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Balvet/Balvet{\_}2015{\_}Penser le lexique-grammaire perspectives actuelles (Review).pdf:pdf},
issn = {0016-1128},
journal = {French Studies},
number = {1},
pages = {138--138},
title = {{Penser le lexique-grammaire: perspectives actuelles (Review)}},
url = {https://academic.oup.com/fs/article-lookup/doi/10.1093/fs/knu291},
volume = {69},
year = {2015}
}
@article{Zeileis2002a,
author = {Zeileis, Achim and Hothorn, Torsten},
journal = {R News},
number = {3},
pages = {7--10},
title = {{Diagnostic Checking in Regression Relationships}},
url = {https://cran.r-project.org/doc/Rnews/},
volume = {2},
year = {2002}
}
@article{Jiang2015,
abstract = {Dependency distance is closely related to human working memory capacity, but is also influenced by other non-cognitive factors. Studies of dependency distance contribute to the understanding of the universalities and peculiarities of languages as well as human cognitive processes in language. Forty two sentence sets were selected from a parallel English-Chinese dependency treebank to examine the progressive properties of dependency distance with the change of sentence length in the two languages. It was found that: (1) the probability distribution models of dependency distance of both languages are not affected by either sentence length or the type of language; (2) the quantity of adjacent dependencies in the two languages are identical, but the quantity of adjacent dependencies of Chinese fluctuates within a limited range, while that of English shows a falling tendency; (3) the mean dependency distances (MDDs) of Chinese are always higher than those of English, and both MDDs show slight ascending trends; (4) compared with dependency distance, dependency direction is a more reliable metric for language classification. These findings suggest that: (1) the universal cognition mechanism may be the major factor affecting the general traits of dependency distance, while language-related factors such as sentence length may affect certain traits of dependency distance; and (2) Chinese taxes working memory more than English.},
annote = {dependency grammar},
author = {Jiang, Jingyang and Liu, Haitao},
doi = {10.1016/j.langsci.2015.04.002},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jiang, Liu/Jiang, Liu{\_}2015{\_}The effects of sentence length on dependency distance, dependency direction and the implications-Based on a parallel Eng.pdf:pdf},
isbn = {0388-0001},
issn = {03880001},
journal = {Language Sciences},
keywords = {Dependency direction,Dependency distance,Probability distribution,Sentence length,Working memory},
number = {866},
pages = {93--104},
publisher = {Elsevier Ltd},
title = {{The effects of sentence length on dependency distance, dependency direction and the implications-Based on a parallel English-Chinese dependency treebank}},
url = {http://dx.doi.org/10.1016/j.langsci.2015.04.002},
volume = {50},
year = {2015}
}
@article{Denis2012,
abstract = {This paper investigates how to best couple hand-annotated data with information extracted from an external lexical resource to improve POS tagging performance. Focusing mostly on French tagging, we introduce aMaximum Entropy MarkovModel-based tagging system that is enriched with information extracted from a morphological resource. This system gives a 97.75{\%}accuracy on the French Treebank, an error reduction of 25{\%} (38{\%} on unknown words) over the same taggerwithout lexical information.We performa series of experiments that help understanding how this lexical information helps improving tagging accuracy. We also conduct experiments on datasets and lexicons of varying sizes in order to assess the best trade-off between annotating data vs. developing a lexicon. We find that the use of a lexicon improves the quality of the tagger at any stage of development of either resource, and that for fixed performance levels the availability of the full lexicon consistently reduces the need for supervised data by at least one half.},
author = {Denis, Pascal and Sagot, Beno{\^{i}}t},
doi = {10.1007/s10579-012-9193-0},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Denis, Sagot/Denis, Sagot{\_}2012{\_}Coupling an annotated corpus and a lexicon for state-of-the-art POS tagging.pdf:pdf},
issn = {1574020X},
journal = {Language Resources and Evaluation},
keywords = {French,Language resource development,MElt,Maximum entropy models,Morphosyntactic lexicon,Part-of-speech tagging},
mendeley-tags = {MElt},
number = {4},
pages = {721--736},
title = {{Coupling an annotated corpus and a lexicon for state-of-the-art POS tagging}},
volume = {46},
year = {2012}
}
@article{Vanhove2019,
author = {Vanhove, Jan and Bonvin, Audrey and Lambelet, Amelia and Berthele, Raphael},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Vanhove et al/Vanhove et al.{\_}2019{\_}Predicting perceptions of the lexical richness of short French, German, and Portuguese texts using text-based indice.pdf:pdf},
journal = {Journal of Writing Research (accepted)},
title = {{Predicting perceptions of the lexical richness of short French, German, and Portuguese texts using text-based indices}},
year = {2019}
}
@manual{Vaidyanathan2018,
annote = {R package version 1.3},
author = {Vaidyanathan, Ramnath and Xie, Yihui and Allaire, J J and Cheng, Joe and Russell, Kenton},
title = {{htmlwidgets: HTML Widgets for R}},
url = {https://cran.r-project.org/package=htmlwidgets},
year = {2018}
}
@incollection{Geeraerts2006,
address = {Berlin},
author = {Geeraerts, Dirk},
booktitle = {Cognitive Linguistics: Basic Readings},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Geeraerts/Geeraerts{\_}2006{\_}A rough guide to cognitive linguistics.pdf:pdf},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
pages = {1--28},
publisher = {Walter de Gruyter},
title = {{A rough guide to cognitive linguistics}},
year = {2006}
}
@article{Liaw2002,
author = {Liaw, Andy and Wiener, Matthew},
journal = {R News},
number = {3},
pages = {18--22},
title = {{Classification and Regression by randomForest}},
url = {https://cran.r-project.org/doc/Rnews/},
volume = {2},
year = {2002}
}
@book{Haspelmath2010,
abstract = {This introduction to morphology assumes no prior knowledge of linguistics and presents the field of morphology in an accessible way. Emphasis is put on presenting a range of morphological phenomena from a wide variety of languages CN - P241 .H37 2010},
archivePrefix = {arXiv},
arxivId = {arXiv:1304.2046v1},
author = {Haspelmath, Martin and Sims, Andrea D.},
booktitle = {Understanding language series},
doi = {10.4324/9780203776506},
eprint = {arXiv:1304.2046v1},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Haspelmath, Sims/Haspelmath, Sims{\_}2010{\_}Understanding morphology.pdf:pdf},
isbn = {978-0-340-95001-2},
issn = {00222267},
keywords = {Comparative and general,Grammar,Morphology},
pmid = {16765300},
title = {{Understanding morphology}},
year = {2010}
}
@article{Eddelbuettel2014,
author = {Eddelbuettel, Dirk and Sanderson, Conrad},
journal = {Computational Statistics and Data Analysis},
month = {mar},
pages = {1054--1063},
title = {{RcppArmadillo: Accelerating R with high-performance C++ linear algebra}},
url = {http://dx.doi.org/10.1016/j.csda.2013.02.005},
volume = {71},
year = {2014}
}
@article{Harley1989,
abstract = {The L2 lexical proficiency of 69 grade 6 French immersion students is compared with that of 22 native French-speaking peers, based on verb use in five written compositions. Measures of lexical error, variety, specificity, and sophistication show clear differences between the two groups. The learners' patterns of use of verb vocabulary are considered in relation to frequency and utility in French, the degree of congruence between L2 and L1, and the morpho-syntactic complexity of some specific types of French verbs. Results are further discussed in relation to observational data from grade 6 immersion classrooms. {\textcopyright} 1989, Cambridge University Press. All rights reserved.},
author = {Harley, Birgit and King, Mary Lou},
doi = {10.1017/S0272263100008421},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Harley, King/Harley, King{\_}1989{\_}Verb lexis in the written compositions of young L2 learners.pdf:pdf},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
number = {4},
pages = {415--439},
title = {{Verb lexis in the written compositions of young L2 learners}},
volume = {11},
year = {1989}
}
@manual{WithcontributionsbyAntoineLucas2019,
annote = {R package version 0.6.20},
author = {{with contributions by Antoine Lucas}, Dirk Eddelbuettel and Tuszynski, Jarek and Bengtsson, Henrik and Urbanek, Simon and Frasca, Mario and Lewis, Bryan and Stokely, Murray and Muehleisen, Hannes and Murdoch, Duncan and Hester, Jim and Wu, Wush and Kou, Qiang and Onkelinx, Thierry and Lang, Michel and Simko, Viliam and Hornik, Kurt and Neal, Radford and Bell., Kendon},
title = {{digest: Create Compact Hash Digests of R Objects}},
url = {https://cran.r-project.org/package=digest},
year = {2019}
}
@incollection{Lindqvist2013,
abstract = {The aims of this chapter are a) to give a comprehensive description of a new tool for lexical profiling by reporting how it was developed, and b) to indicate possible areas of use and future developments of the tool. The tool has been used for meas- uring the lexical sophistication of Swedish learners of French and Italian. The dif- ferent steps of development have partly been presented in previous studies (Bardel {\&}Lindqvist, 2011; Bardel, Gudmundson {\&} Lindqvist, 2012; Lindqvist, Bardel {\&} Gudmundson, 2011) but are complemented here through a detailed account of the tool, in order to enable replication and use of the method with other languages. The outline of this chapter is as follows: first, as a background, we provide a sur- vey of methods designed to measure lexical richness in L2 production. Then we discuss the inherent differences between written and spoken language and what these differences may imply when lexical richness is measured. Next, we present a new method for analyzing L2 learners' lexical profiles in oral production data, giving a detailed technical description of the creation of the tool. We then dis- cuss pros and cons with frequency-based measures in general and present our solutions to some of the problems brought up. Finally, we suggest some poten- tial areas of use and discuss some possible improvements of the method.},
author = {Lindqvist, Christina and Gudmundson, Anna and Bardel, Camilla},
booktitle = {L2 vocabulary acquisition, knowledge and use: New perspectives on assessment and corpus analysis (Eurosla Monograph Series)},
editor = {Bardel, Camilla and Lindqvist, Christina and Laufer, Batia},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lindqvist, Gudmundson, Bardel/Lindqvist, Gudmundson, Bardel{\_}2013{\_}A new approach to measuring lexical sophistication in L2 oral production.pdf:pdf},
isbn = {9781300884071},
pages = {109--126},
publisher = {EUROSLA},
title = {{A new approach to measuring lexical sophistication in L2 oral production}},
volume = {2},
year = {2013}
}
@article{Ellis2006,
author = {Ellis, Nick C},
doi = {10.1093/applin/ami038},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis/Ellis{\_}2006{\_}Language Acquisition as Rational Contingency Learning.pdf:pdf},
journal = {Applied Linguistics},
number = {1},
pages = {1--24},
title = {{Language Acquisition as Rational Contingency Learning}},
volume = {27},
year = {2006}
}
@book{Venables2002,
address = {New York},
annote = {ISBN 0-387-95457-0},
author = {Venables, W N and Ripley, B D},
edition = {Fourth},
publisher = {Springer},
title = {{Modern Applied Statistics with S}},
url = {http://www.stats.ox.ac.uk/pub/MASS4},
year = {2002}
}
@inproceedings{Vergne2001,
address = {Tours},
author = {Vergne, Jacques},
booktitle = {TALN},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Vergne/Vergne{\_}2001{\_}Analyse syntaxique automatique des langues du cominatoire au calculatoire.pdf:pdf},
month = {jul},
title = {{Analyse syntaxique automatique des langues: du cominatoire au calculatoire}},
year = {2001}
}
@book{Queneau1950,
address = {Paris},
author = {Queneau, R},
publisher = {Gallimard},
title = {{B{\^{a}}tons, chiffres et lettres}},
year = {1950}
}
@incollection{Fløttum2006,
address = {Amsterdam},
author = {Fl{\o}ttum, Kjersti and Dahl, Trine and Kim, Torodd},
booktitle = {Academic Voices: Across languages and disciplines},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Fl{\o}ttum, Dahl, Kim/Fl{\o}ttum, Dahl, Kim{\_}2006{\_}Introduction.pdf:pdf},
keywords = {KIAP},
mendeley-tags = {KIAP},
pages = {1--28},
publisher = {John Benjamins},
title = {{Introduction}},
year = {2006}
}
@manual{Gillespie2019a,
annote = {R package version 1.0.2},
author = {Gillespie, Colin},
title = {{benchmarkme: Crowd Sourced System Benchmarks}},
url = {https://cran.r-project.org/package=benchmarkme},
year = {2019}
}
@manual{Kassambara2020,
annote = {R package version 0.2.5},
author = {Kassambara, Alboukadel},
title = {{ggpubr: 'ggplot2' Based Publication Ready Plots}},
url = {https://cran.r-project.org/package=ggpubr},
year = {2020}
}
@incollection{Towell2012,
abstract = {The aim of this chapter, which is written from the perspective of psycholinguistic SLA research, is to establish a possible relationship between representations, processes and mechanisms of second language learning and knowledge as defined from within psycholinguistic SLA on the one hand, and the more behavioural performance outcomes such as complexity, accuracy and fluency on the other hand. In the first section of this chapter the view of second language acquisition presented in Towell and Hawkins (1994) is presented. On the basis of this view, an argument is put forward in favour of a tripartite composition of second language acquisition: one element dealing with language competence, one with learned linguistic knowledge and one with language processing. Each of these elements will have a bearing on complexity, accuracy and fluency, although not on a simple one-to-one basis. It is further argued that each element has specific learning dimensions. For second language acquisition to succeed and for learners to be able to use complex language accurately and fluently, it is essential for all three dimensions to be successful and to be integrated with each other. This must take place within appropriate memory systems. Empirical evidence is presented in the second part of the chapter to examine the role which each of the elements plays. It is shown that the acquisition of competence takes longer than is sometimes expected and that learners make use of strategies such as mimicking or generalising constructions in the absence of full competence. Explicit learned linguistic knowledge is seen to be speeded-up but not transformed into implicit knowledge. Learners are shown to become faster speakers over time but their individual Speaking Rate is shown to be relative to that of their Speaking Rate in the LI. It is argued that, whilst LI and L2 both contain the three acquisitional elements, the balance is different between the two with the L2 depending much more on speeded-up learnt linguistic knowledge. It is suggested that the understanding of the development of complexity, accuracy and fluency would be improved through a dialogue between acquisitionists and those who measure performance progression in these areas.},
address = {Amsterdam},
author = {Towell, Richard J.},
booktitle = {Dimensions of L2 Performance and Proficiency : Complexity, Accuracy and Fluency in SLA},
chapter = {3},
doi = {10.1075/lllt.32.03tow},
editor = {Housen, Alex and Kuiken, Folkert and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Towell/Towell{\_}2012{\_}Complexity, accuracy and fluency from the perspective of psycholinguistic second language acquisition research.pdf:pdf},
pages = {47--70},
publisher = {John Benjamins},
title = {{Complexity, accuracy and fluency from the perspective of psycholinguistic second language acquisition research}},
year = {2012}
}
@manual{Wickham2017,
annote = {R package version 1.1.0},
author = {Wickham, Hadley and Hester, Jim and M{\"{u}}ller, Kirill and Cook, Daniel},
title = {{memoise: Memoisation of Functions}},
url = {https://cran.r-project.org/package=memoise},
year = {2017}
}
@inproceedings{Charest2007,
address = {Toulouse},
author = {Charest, Simon and Brunelle, {\'{E}}ric and Fontaine, Jean and Pelletier, Bertrand},
booktitle = {Actes de la 14{\`{e}}me conf{\'{e}}rence sur le Traitement Automatique des Langues Naturelles},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Charest et al/Charest et al.{\_}2007{\_}{\'{E}}laboration Automatique D'Un Dictionnaire De Cooccurrences Grand Public.pdf:pdf},
keywords = {analyseur,antidote,co-occurrences,collocations,cooccurrences,corpus,correcteur,grammar checker,parser},
pages = {283--292},
title = {{{\'{E}}laboration Automatique D'Un Dictionnaire De Cooccurrences Grand Public}},
year = {2007}
}
@article{Bernardini2019,
author = {Bernardini, Petra and Granfeldt, Jonas},
doi = {10.1111/ijal.12257},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bernardini, Granfeldt/Bernardini, Granfeldt{\_}2019{\_}On cross ‐ linguistic variation and measures of linguistic complexity in learner texts Italian , French an.pdf:pdf},
journal = {International Journal of Applied Linguistics},
number = {[Special Issue]},
pages = {1--22},
title = {{On cross ‐ linguistic variation and measures of linguistic complexity in learner texts : Italian , French and English}},
year = {2019}
}
@book{Templin1957,
address = {Minneapolis},
author = {Templin, M},
keywords = {lexdiv{\_}ttr},
mendeley-tags = {lexdiv{\_}ttr},
publisher = {The University of Minnesota Press},
title = {{Certain Language Skills in Children: Their development and interrelationships}},
year = {1957}
}
@manual{Talbot2014,
annote = {R package version 0.3},
author = {Talbot, Justin},
title = {{labeling: Axis Labeling}},
url = {https://cran.r-project.org/package=labeling},
year = {2014}
}
@inproceedings{Johnson2009,
abstract = {This paper discusses some of the ways that the “statistical revolution” has changed and continues to change the relationship between linguistics and computational lin- guistics. I claim that it is more useful in parsing to make an open world assumption about possible linguistic structures, rather than the closed world assumption usu- ally made in grammar-based approaches to parsing, and I sketch two different ways in which grammar-based approaches might be modified to achieve this. I also de- scribe some of the ways in which proba- bilistic models are starting to have a sig- nificant impact on psycholinguistics and language acquisition. In language acqui- sition Bayesian techniques may let us em- pirically evaluate the role of putative uni- versals in universal grammar.},
address = {Athens},
author = {Johnson, Mark},
booktitle = {Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics Virtuous, Vicious or Vacuous? - ILCL '09},
doi = {10.3115/1642038.1642041},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Johnson/Johnson{\_}2009{\_}How the statistical revolution changes (computational) linguistics.pdf:pdf},
month = {mar},
pages = {3--11},
title = {{How the statistical revolution changes (computational) linguistics}},
url = {http://portal.acm.org/citation.cfm?doid=1642038.1642041},
year = {2009}
}
@incollection{Levshina2015,
address = {Amsterdam},
author = {Levshina, Natalia},
booktitle = {How to do linguistics with R: Data exploration and statistical analysis},
doi = {10.1075/z.195},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Levshina/Levshina{\_}2015{\_}Conditional inference trees and random forests.pdf:pdf},
isbn = {9789027268457},
pages = {291--300},
publisher = {John Benjamins},
title = {{Conditional inference trees and random forests}},
year = {2015}
}
@manual{Hothorn2019,
annote = {R package version 1.0-10},
author = {Hothorn, Torsten},
title = {{TH.data: TH's Data Archive}},
url = {https://cran.r-project.org/package=TH.data},
year = {2019}
}
@misc{DouglasNychka2017,
address = {Boulder, CO, USA},
annote = {R package version 9.8-6},
author = {{Douglas Nychka} and {Reinhard Furrer} and {John Paige} and {Stephan Sain}},
doi = {10.5065/D6W957CT},
institution = {University Corporation for Atmospheric Research},
title = {{fields: Tools for spatial data}},
url = {https://github.com/NCAR/Fields},
year = {2017}
}
@article{Osborne2011,
abstract = {Individual speakers vary considerably in their rate of speech, their syntactic choices, and the organization of information in their discourse. This study, based on a corpus of monologue productions from native and non-native speakers of English and French, examines the relations between temporal fluency, syntactic complexity and informational content. The purpose is to identify which features, or combinations of features, are common to more fluent speakers, and which are more idiosyncratic in nature. While the syntax of fluent speakers is not necessarily more complex than that of less fluent speakers, it is suggested that they are able to deliver content more efficiently through a combination of less hesitant speech and of lexical and syntactic choices that allow them to package information more economically.},
author = {Osborne, John},
doi = {10.1075/ijcl.16.2.06osb},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Osborne/Osborne{\_}2011{\_}Fluency, complexity and informativeness in native and non-native speech.pdf:pdf},
issn = {1384-6655},
journal = {International Journal of Corpus Linguistics},
keywords = {fluency,information content,learner corpora,syntactic complexity},
number = {2},
pages = {276--298},
title = {{Fluency, complexity and informativeness in native and non-native speech}},
volume = {16},
year = {2011}
}
@article{Brants2000,
abstract = {This paper presents the results of an investigation on inter-annotator agreement for the NEGRA corpus, consisting of German newspaper texts. The corpus is syntactically annotated with part-of-speech and structural information. Agreement for part-of-speech is 98.6{\%}, the labeled F-score for structures is 92.4{\%}. The two annotations are used to create a common final version by discussing differences and by several iterations of cleaning. Initial and final versions are compared. We identify categories causing large numbers of differences and categories that are handled inconsistently.},
author = {Brants, Thorsten},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Brants/Brants{\_}2000{\_}Inter-annotator agreement for a German newspaper corpus.pdf:pdf},
journal = {2nd International Conference on Language Resources and Evaluation},
title = {{Inter-annotator agreement for a German newspaper corpus}},
year = {2000}
}
@manual{Urbanek2019,
annote = {R package version 0.9-11},
author = {Urbanek, Simon},
title = {{rJava: Low-Level R to Java Interface}},
url = {https://cran.r-project.org/package=rJava},
year = {2019}
}
@manual{Allaire2020,
annote = {R package version 2.3},
author = {Allaire, J J and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe and Chang, Winston and Iannone, Richard},
title = {{rmarkdown: Dynamic Documents for R}},
url = {https://github.com/rstudio/rmarkdown},
year = {2020}
}
@manual{Csardi2017a,
annote = {R package version 1.2.0},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and Sorhus, Sindre},
title = {{clisymbols: Unicode Symbols at the R Prompt}},
url = {https://cran.r-project.org/package=clisymbols},
year = {2017}
}
@manual{Chang2019a,
annote = {R package version 2.4.0},
author = {Chang, Winston},
title = {{R6: Encapsulated Classes with Reference Semantics}},
url = {https://cran.r-project.org/package=R6},
year = {2019}
}
@manual{Hornik2018,
annote = {R package version 0.2-0},
author = {Hornik, Kurt},
title = {{NLP: Natural Language Processing Infrastructure}},
url = {https://cran.r-project.org/package=NLP},
year = {2018}
}
@article{Drouin2007,
author = {Drouin, Patrick},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Drouin/Drouin{\_}2007{\_}Identification automatique du lexique scientifique transdisciplinaire.pdf:pdf},
title = {{Identification automatique du lexique scientifique transdisciplinaire}},
year = {2007}
}
@article{Pallotti2015,
abstract = {Although a growing number of second language acquisition (SLA) studies take linguistic complexity as a dependent variable, the term is still poorly defined and often used with different meanings, thus posing serious problems for research synthesis and knowledge accumulation. This article proposes a simple, coherent view of the construct, which is defined in a purely structural way, i.e. the complexity directly arising from the number of linguistic elements and their interrelationships. Issues of cognitive cost (difficulty) or developmental dynamics (acquisition) are explicitly excluded from this theoretical definition and its operationalization. The article discusses how the complexity of an interlanguage system can be assessed based on the limited samples with which SLA researchers usually work. For the areas of morphology, syntax and the lexicon, some measures are proposed that are coherent with the purely structural view advocated, and issues related to their operationalization are critically scrutinized.},
annote = {• complexity: that which arises directly from the number of linguistic elements and their interrelationships (in a text) 
‣ kolmogorov complexity
‣ effective complexity 
◦ morphological complexity
‣ number of exponents
‣ X number of form-function relationships
‣ X processing costs 
◦ syntactic complexity 
‣ length of phrase
‣ number of clauses per unit
‣ number of word-order patterns 
‣ X mean length of clause, subordination ratio
‣ X acquisitional timing
◦ lexical complexity 
‣ lexical diversity measures (Giraud, D) 
‣ X complexity of individual words 
‣ X density},
author = {Pallotti, Gabriele},
doi = {10.1177/0267658314536435},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Pallotti/Pallotti{\_}2015{\_}A simple view of linguistic complexity.pdf:pdf},
isbn = {0267-6583},
issn = {02676583},
journal = {Second Language Research},
keywords = {complexity,interlanguage analysis,lexicon,linguistic complexity,linguistic typology,morphology,quantitative linguistics,research methods,syntax},
mendeley-tags = {complexity},
number = {11},
pages = {117--134},
title = {{A simple view of linguistic complexity}},
volume = {31},
year = {2015}
}
@article{Klein1997,
abstract = {In this article, we discuss the implications of the fact that adult second language learners (outside the classroom) universally develop a well-structured, efficient and simple form of language–the Basic Variety (BV). Three questions are asked as to (1) the structural properties of the BV, (2) the status of these properties and (3) why some structural properties of ‘fully fledged' languages are more complex. First, we characterize the BV in four respects: its lexical repertoire, the principles according to which utterances are structured, and temporality and spatiality expressed. The organizational principles proposed are small in number, and interact. We analyse this interaction, describing how the BV is put to use in various complex verbal tasks, in order to establish both what its communicative potentialities are, and also those discourse contexts where the constraints come into conflict and where the variety breaks down. This latter phenomenon provides a partial answer to the third question,concerning the relative complexity of ‘fully fledged' languages–they have devices to deal with such cases. As for the second question, it is argued firstly that the empirically established continuity of the adult acquisition process precludes any assignment of the BV to a mode of linguistic expression (e.g., ‘protolanguage') distinct from that of ‘fully fledged' languages and, moreover, that the organizational constraints of the BV belong to the core attributes of the human language capacity, whereas a number of complexifications not attested in the BV are less central properties of this capacity. Finally, it is shown that the notion of feature strength, as used in recent versions of Generative Grammar, allows a straightforward characterization of the BV as a special case of an I-language, in the sense of this theory. Under this perspective, the acquisition of an I-language beyond the BV can essentially be described as a change in feature strength.},
author = {Klein, Wolfgang and Perdue, Clive},
doi = {10.1191/026765897666879396},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Klein, Perdue/Klein, Perdue{\_}1997{\_}The Basic Variety (or Couldn't natural languages be much simpler).pdf:pdf},
isbn = {90 272 3357 8},
issn = {02676583},
journal = {Second Language Research},
number = {4},
title = {{The Basic Variety (or: Couldn't natural languages be much simpler?)}},
volume = {13},
year = {1997}
}
@article{Peters2019,
abstract = {This study describes the development of an English and French multiple choice vocabulary test – the VocabLab tests – that measure learners' knowl- edge at four frequency levels up to the most frequent 5,000 words: the 2,000-level, 3,000-level, 4,000-level, and the 5,000-level. The two tests aimed to address some of the limitations of tests currently in use. First, they are sampled from recent frequency lists. Second, they are geared towards Dutch-speaking learners of English and French in Flanders. Third, they attempt to minimize guessing by including an “I don't know”-option. The findings showed that the tests are internally consistent. Mean scores decreased when the words were less frequent, lending evidence to the tests' construct validity. Additionally, the tests seem to be able to discriminate between different proficiency levels. As both tests were developed according to the same principles, they can be used to compare learners' English and French vocabulary knowledge.},
author = {Peters, Elke and Velghe, Tom and {Van Rompaey}, Tinne},
doi = {10.1075/itl.17029.pet},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Peters, Velghe, Van Rompaey/Peters, Velghe, Van Rompaey{\_}2019{\_}The VocabLab tests The development of an English and French vocabulary test.pdf:pdf},
issn = {1783-1490},
journal = {International Journal of Applied Linguistics},
keywords = {English,French,Frequency,Vocabulary knowledge,Vocabulary levels,Vocabulary test},
number = {1},
pages = {53--78},
title = {{The VocabLab tests: The development of an English and French vocabulary test}},
volume = {170},
year = {2019}
}
@inproceedings{Schmid1994,
address = {Manchester},
author = {Schmid, Helmut},
booktitle = {Proceedings of International Conference on New Methods in Language Processing},
keywords = {treetagger},
mendeley-tags = {treetagger},
title = {{Probabilistic Part-of-Speech Tagging Using Decision Trees}},
year = {1994}
}
@misc{Greenwell2019,
author = {Greenwell, Brandon and Boehmke, Brad and Gray, Bernie},
keywords = {vip},
mendeley-tags = {vip},
title = {{vip: Variable importance plots}},
url = {https://cran.r-project.org/package=vip},
year = {2019}
}
@phdthesis{Evert2004,
author = {Evert, Stefan},
booktitle = {The Statistics of Word Occurances: Word Pairs and Collocations},
doi = {10.1073/pnas.141413598},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Evert/Evert{\_}2004{\_}The statistics of word cooccurrences.pdf:pdf},
isbn = {0027-8424 (Print)},
issn = {00278424},
pmid = {11447261},
school = {Universit{\"{a}}t Stuttgart},
title = {{The statistics of word cooccurrences}},
type = {PhD Dissertation},
url = {http://elib.uni-stuttgart.de/opus/volltexte/2005/2371/pdf/Evert2005phd.pdf?q=chapter-5-collocations{\%}5Cnpapers2://publication/uuid/DE3D00C5-1A39-4780-BB6B-168159642E75},
year = {2004}
}
@article{Dunn2018,
author = {Dunn, Jonathan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dunn/Dunn{\_}2018{\_}Multi-unit association measures Moving beyond pairs of words.pdf:pdf},
journal = {International Journal of Corpus Linguistics},
keywords = {association strength,multi-unit association,sequences,$\delta$p},
number = {2},
pages = {183--215},
title = {{Multi-unit association measures Moving beyond pairs of words}},
volume = {23},
year = {2018}
}
@manual{Henry2020b,
annote = {R package version 0.4.6},
author = {Henry, Lionel and Wickham, Hadley},
title = {{rlang: Functions for Base Types and Core R and 'Tidyverse' Features}},
url = {https://cran.r-project.org/package=rlang},
year = {2020}
}
@article{Macaro2006,
abstract = {This paper investigates the effect of explicit grammar instruction on grammatical knowledge and writing proficiency in first-year students of French at a UK university. Previous research suggests that explicit grammar instruction results in gains in explicit knowledge and its application in specific grammar-related tasks, but there is less evidence that it results in gains in production tasks. A cohort of 12 students received a course in French grammar immediately prior to their university studies in order to determine whether a short but intensive burst of explicit instruction, a pedagogical approach hitherto unexamined in the literature, was sufficiently powerful to bring about an improvement in their grammatical knowledge and performance in production tasks. Participants were tested at three points over five months, and the results were compared with a group which did not receive the intervention. Our results support previous findings that explicit instruction leads to gains in some aspects of grammar tests but not gains in accuracy in either translation or free composition. Reasons for these findings are discussed in relation to theories of language development and the limitations of working memory.},
author = {Macaro, Ernesto and Masterman, Liz},
doi = {10.1191/1362168806lr197oa},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Macaro, Masterman/Macaro, Masterman{\_}2006{\_}Does intensive explicit grammar instruction make all the difference.pdf:pdf},
issn = {13621688},
journal = {Language Teaching Research},
number = {3},
pages = {297--327},
title = {{Does intensive explicit grammar instruction make all the difference?}},
volume = {10},
year = {2006}
}
@manual{Gohel2020b,
annote = {R package version 0.2.2},
author = {Gohel, David and Wickham, Hadley and Henry, Lionel and Ooms, Jeroen},
title = {{gdtools: Utilities for Graphical Rendering}},
url = {https://cran.r-project.org/package=gdtools},
year = {2020}
}
@manual{Daroczi2018,
annote = {R package version 0.6.3},
author = {Dar{\'{o}}czi, Gergely and Tsegelskyi, Roman},
title = {{pander: An R 'Pandoc' Writer}},
url = {https://cran.r-project.org/package=pander},
year = {2018}
}
@techreport{Berger2017,
author = {Berger, Susanne and Graham, Nathaniel and Zeileis, Achim},
institution = {Working Papers in Economics and Statistics, Research Platform Empirical and Experimental Economics, Universit{\"{a}}t Innsbruck},
month = {jul},
number = {2017-12},
title = {{Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in {\{}R{\}}}},
type = {Working Paper},
url = {http://econpapers.repec.org/RePEc:inn:wpaper:2017-12},
year = {2017}
}
@article{Filipovic2013,
abstract = {We propose a new model of second language acquisition consisting of multiple interacting principles and inspired by work on complex adaptive systems. The model is referred to as CASP, short for complex adaptive system principles for second language acquisition. It is informed by a broad range of linguistic and psycholinguistic research and supported empirically by recent second language research studies based on a learner corpus. The novelty of our model lies in the definitions that we propose for a number of general and specific principles of learning, in the interactions that we demonstrate between them, in the predictions that we make and illustrate empirically, and in our integration of research findings from numerous areas of the language sciences. The result is a broadly based theory of SLA, which can potentially solve some of the traditional puzzles in this field, e.g., involving when transfer from an L1 does and does not occur.},
author = {Filipovi{\'{c}}, Luna and Hawkins, John A.},
doi = {10.1515/ling-2013-0005},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Filipovi{\'{c}}, Hawkins/Filipovi{\'{c}}, Hawkins{\_}2013{\_}Multiple factors in second language acquisition The CASP model.pdf:pdf},
isbn = {0024-3949},
issn = {00243949},
journal = {Linguistics},
keywords = {L1 transfer into L2,complex adaptive systems,cooperating and competing principles,learning and processing,multifactor model of second language acquisition},
number = {1},
pages = {145--176},
title = {{Multiple factors in second language acquisition: The CASP model}},
volume = {51},
year = {2013}
}
@article{Godfrey2014,
author = {Godfrey, LeeAnne and Treacy, Corbin and Tarone, Elaine},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Godfrey, Treacy, Tarone/Godfrey, Treacy, Tarone{\_}2014{\_}Change in French Second Language Writing in Study Abroad and Domestic Contexts.pdf:pdf},
journal = {Foreign Language Annals},
number = {1},
pages = {48--65},
title = {{Change in French Second Language Writing in Study Abroad and Domestic Contexts}},
volume = {47},
year = {2014}
}
@article{Greenwell2017,
author = {Greenwell, Brandon},
journal = {The R Journal},
keywords = {pdp},
mendeley-tags = {pdp},
number = {1},
pages = {421--436},
title = {{pdp: An R package for constructing partial dependence plots}},
volume = {9},
year = {2017}
}
@manual{Teetor2018,
annote = {R package version 0.1.0},
author = {Teetor, Nathan},
title = {{zeallot: Multiple, Unpacking, and Destructuring Assignment}},
url = {https://cran.r-project.org/package=zeallot},
year = {2018}
}
@misc{Vanhove2018,
author = {Vanhove, Jan},
title = {{Computer code for cleaning, tagging, and analysing the texts}},
url = {https://osf.io/479um/},
year = {2018}
}
@article{Veronique2017a,
author = {V{\'{e}}ronique, Georges Daniel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/V{\'{e}}ronique/V{\'{e}}ronique{\_}2017{\_}R{\'{e}}ponse {\`{a}} Wander Lowie L'{\'{e}}mergentisme, la recherche sur l'acquisition des langues et la didactique des langues {\'{e}}tra.pdf:pdf},
journal = {Recherches en didactique des langues et des cultures: Les Cahiers de l'Acedle [En Ligne]},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
number = {1},
pages = {1--12},
title = {{R{\'{e}}ponse {\`{a}} Wander Lowie: L'{\'{e}}mergentisme, la recherche sur l'acquisition des langues et la didactique des langues {\'{e}}trang{\`{e}}res}},
url = {http://journals.openedition.org/rdlc/1385},
volume = {14},
year = {2017}
}
@book{Vinay1995,
address = {Amsterdam},
author = {Vinay, Jean-Paul and Darbelnet, Jean},
publisher = {John Benjamins},
title = {{Comparative stylistics of French and English}},
translator = {Sager, Juan and Hamel, M-J},
year = {1995}
}
@article{Paquot2019,
author = {Paquot, Magali},
doi = {10.1177/0267658317694221},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot/Paquot{\_}2017{\_}The phraseological dimension in interlanguage complexity research(3).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot/Paquot{\_}2019{\_}The phraseological dimension in interlanguage complexity research.pdf:pdf},
isbn = {0267658317694},
issn = {0267-6583},
journal = {Second Language Research},
number = {1},
pages = {121--145},
title = {{The phraseological dimension in interlanguage complexity research}},
url = {http://journals.sagepub.com/doi/10.1177/0267658317694221},
volume = {35},
year = {2019}
}
@manual{Chang2019,
annote = {R package version 1.3.2},
author = {Chang, Winston and Cheng, Joe and Allaire, J J and Xie, Yihui and McPherson, Jonathan},
title = {{shiny: Web Application Framework for R}},
url = {https://cran.r-project.org/package=shiny},
year = {2019}
}
@article{New2007,
abstract = {We examine the use of film subtitles as an approximation of word frequencies in human interactions. Because subtitle files are widely available on the Internet, they may present a fast and easy way to obtain word frequency measures in language registers other than text writing. We compiled a corpus of 52 million French words, coming from a variety of films. Frequency measures based on this corpus compared well to other spoken and written frequency measures, and explained variance in lexical decision times in addition to what is accounted for by the available French written frequency measures. {\textcopyright} 2007 Cambridge University Press.},
author = {New, Boris and Brysbaert, Marc and Veronis, Jean and Pallier, Christophe},
doi = {10.1017/S014271640707035X},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/New et al/New et al.{\_}2007{\_}The use of film subtitles to estimate word frequencies.pdf:pdf},
issn = {14691817},
journal = {Applied Psycholinguistics},
keywords = {frantext},
mendeley-tags = {frantext},
pages = {661--677},
title = {{The use of film subtitles to estimate word frequencies}},
volume = {28},
year = {2007}
}
@manual{Ooms2019e,
annote = {R package version 1.1},
author = {Ooms, Jeroen},
title = {{qpdf: Split, Combine and Compress PDF Files}},
url = {https://cran.r-project.org/package=qpdf},
year = {2019}
}
@article{Cavalla2009,
author = {Cavalla, Cristelle},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cavalla/Cavalla{\_}2009{\_}La phras{\'{e}}ologie en classe de FLE.pdf:pdf},
journal = {Les langues modernes},
title = {{La phras{\'{e}}ologie en classe de FLE}},
volume = {1},
year = {2009}
}
@article{Deng2020,
author = {Deng, Yaochen and Lei, Lei and Liu, Dilin},
doi = {10.1093/applin/amz069},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Deng, Lei, Liu/Deng, Lei, Liu{\_}2020{\_}Calling for More Consistency, Refinement, and Critical Consideration in the Use of Syntactic Complexity Measures for.pdf:pdf},
issn = {0142-6001},
journal = {Applied Linguistics},
pages = {1--9},
title = {{Calling for More Consistency, Refinement, and Critical Consideration in the Use of Syntactic Complexity Measures for Writing}},
year = {2020}
}
@incollection{Ortega2018,
address = {Amsterdam},
author = {Ortega, Lourdes and Lee, Sang-ki and Miyata, Munehiko},
booktitle = {Language Learning Discourse and Cognition},
editor = {Pickering, Lucy and Vyvyan, Evans},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ortega, Lee, Miyata/Ortega, Lee, Miyata{\_}2018{\_}What is happened Your amazon.com order has shipped Overpassivization and unaccusativity as L2 construction lea.pdf:pdf},
keywords = {cognitive-e ff ects,frequency,l2 constructions},
publisher = {John Benjamins},
title = {{What is happened ? Your amazon.com order has shipped Overpassivization and unaccusativity as L2 construction learning}},
year = {2018}
}
@manual{Maechler2019,
annote = {R package version 2.1.0 --- For new features, see the 'Changelog' file (in the package source)},
author = {Maechler, Martin and Rousseeuw, Peter and Struyf, Anja and Hubert, Mia and Hornik, Kurt},
title = {{cluster: Cluster Analysis Basics and Extensions}},
year = {2019}
}
@article{Zuchowski2018,
author = {Zuchowski, L},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Zuchowski/Zuchowski{\_}2018{\_}Complexity as a contrast between dynamics and phenomenology.pdf:pdf},
isbn = {1355219817},
journal = {Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics},
pages = {86--99},
title = {{Complexity as a contrast between dynamics and phenomenology}},
volume = {63},
year = {2018}
}
@book{Sinclair1991,
address = {Oxford},
author = {Sinclair, John},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Sinclair/Sinclair{\_}1991{\_}Corpus, concordance, collocation.pdf:pdf},
isbn = {9780194371445},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
publisher = {Oxford University Press},
title = {{Corpus, concordance, collocation}},
year = {1991}
}
@article{Veronique2017,
author = {V{\'{e}}ronique, Georges Daniel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/V{\'{e}}ronique/V{\'{e}}ronique{\_}2017{\_}La grammaire en fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re questions d'acquisition et d'intervention.pdf:pdf},
isbn = {9782377470242},
journal = {Lidil [En Ligne]},
title = {{La grammaire en fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re : questions d'acquisition et d'intervention}},
url = {http://journals.openedition.org/lidil/4734},
volume = {56},
year = {2017}
}
@manual{Berkelaar2019,
annote = {R package version 5.6.13.3},
author = {Berkelaar, Michel and Others},
title = {{lpSolve: Interface to 'Lp{\_}solve' v. 5.5 to Solve Linear/Integer Programs}},
url = {https://cran.r-project.org/package=lpSolve},
year = {2019}
}
@article{Liu2008,
abstract = {Linguistic complexity is a measure of the cognitive difficulty of human language processing. The present paper proposes dependency distance, in the framework of dependency grammar, as an insightful metric of complexity. Three hypotheses are formulated: (1) The human language parser prefers linear orders that minimize the average dependency distance of the recognized sentence (2) There is a threshold that the average dependency distance of most sentences or texts of human languages does not exceed (3) Grammar and cognition combine to keep dependency distance within the threshold. Twenty corpora from different languages with dependency syntactic annotation are used to test these hypotheses. The paper reports the average dependency distance in these corpora and analyzes the factors which influence dependency distance. The findings — that average dependency distance has a tendency to be minimized in human language and that there is a threshold of less than 3 words in average dependency distance and grammar plays an important role in constraining distance —support all three hypotheses, although some questions are still open for further research.},
author = {Liu, Haitao},
doi = {10.17791/jcs.2008.9.2.159},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Liu/Liu{\_}2008{\_}Dependency Distance as a Metric of Language Comprehension Difficulty.pdf:pdf},
isbn = {1598-2327},
issn = {1598-2327},
journal = {Journal of Cognitive Science},
number = {2},
pages = {159--191},
title = {{Dependency Distance as a Metric of Language Comprehension Difficulty}},
url = {http://www.kci.go.kr/kciportal/landing/article.kci?arti{\_}id=ART001303326},
volume = {9},
year = {2008}
}
@inproceedings{Paquot2017,
address = {Prague},
author = {Paquot, Magali and Naets, Hubert},
booktitle = {ICAME 38},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot, Naets/Paquot, Naets{\_}2017{\_}The role of the reference corpus in studies of EFL learners' use of statistical collocations.pdf:pdf},
title = {{The role of the reference corpus in studies of EFL learners' use of statistical collocations}},
year = {2017}
}
@article{Wright2017,
author = {Wright, Marvin N and Ziegler, Andreas},
doi = {10.18637/jss.v077.i01},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--17},
title = {{{\{}ranger{\}}: A Fast Implementation of Random Forests for High Dimensional Data in {\{}C++{\}} and {\{}R{\}}}},
volume = {77},
year = {2017}
}
@phdthesis{Bulut2016,
author = {Bulut, Alma},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bulut/Bulut{\_}2016{\_}Acquisition des locutions verbales et des constructions {\`{a}} verbe support en fran{\c{c}}ais.pdf:pdf},
school = {Concordia University},
title = {{Acquisition des locutions verbales et des constructions {\`{a}} verbe support en fran{\c{c}}ais}},
type = {Master Thesis},
year = {2016}
}
@phdthesis{Arvidsson2019a,
author = {Arvidsson, Klara},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Arvidsson/Arvidsson{\_}2019{\_}C'est {\c{c}}a, en fait. D{\'{e}}velopper l'idiomaticit{\'{e}} dans une L2 pendant le s{\'{e}}jour linguistique.pdf:pdf},
school = {Stockholm University},
title = {{"C'est {\c{c}}a, en fait." D{\'{e}}velopper l'idiomaticit{\'{e}} dans une L2 pendant le s{\'{e}}jour linguistique}},
type = {Doctoral Dissertation},
year = {2019}
}
@manual{Cheng2019a,
annote = {R package version 1.5.1},
author = {Cheng, Joe and Bravo, Hector Corrada and Ooms, Jeroen and Chang, Winston},
title = {{httpuv: HTTP and WebSocket Server Library}},
url = {https://cran.r-project.org/package=httpuv},
year = {2019}
}
@article{Vandeweerd2021b,
author = {Vandeweerd, Nathan and Housen, Alex and Paquot, Magali},
journal = {International Journal of Learner Corpus Research},
title = {{Applying phraseological complexity measures to L2 French: A partial replication study}}
}
@manual{Garnier2018,
annote = {R package version 0.5.1},
author = {Garnier, Simon},
title = {{viridis: Default Color Maps from 'matplotlib'}},
url = {https://cran.r-project.org/package=viridis},
year = {2018}
}
@article{ForsbergLundell2018,
annote = {created a productive collocation test based on collocations identified in the L1 Le Monde corpus (MI and freq); could distinguish between B and C levels **but there was also collocation knowledge at the B2 level, so this is not all or nothing},
author = {{Forsberg Lundell}, Fanny and Lindqvist, Christina and Edmonds, Amanda},
doi = {10.3138/cmlr.2017-0093},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Forsberg Lundell, Lindqvist, Edmonds/Forsberg Lundell, Lindqvist, Edmonds{\_}2018{\_}Productive collocation knowledge at advanced CEFR levels Evidence from the development of a te.pdf:pdf},
issn = {0008-4506},
journal = {Canadian Modern Language Review},
number = {4},
pages = {627--649},
title = {{Productive collocation knowledge at advanced CEFR levels: Evidence from the development of a test for advanced L2 French}},
url = {https://utpjournals.press/doi/10.3138/cmlr.2017-0093},
volume = {74},
year = {2018}
}
@inproceedings{Jarvis2013,
address = {Dallas},
author = {Jarvis, Scott},
booktitle = {AAAL},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2013{\_}Lexical diversity Modeling and measuring multidimensional compositional complexity.pdf:pdf},
keywords = {complexity,diversity},
mendeley-tags = {complexity,diversity},
title = {{Lexical diversity: Modeling and measuring multidimensional compositional complexity}},
year = {2013}
}
@manual{Corporation2019,
annote = {R package version 1.0.15},
author = {Corporation, Microsoft and Weston, Steve},
title = {{doParallel: Foreach Parallel Adaptor for the 'parallel' Package}},
url = {https://cran.r-project.org/package=doParallel},
year = {2019}
}
@manual{Hester2019a,
annote = {R package version 1.3.1},
author = {Hester, Jim},
title = {{glue: Interpreted String Literals}},
url = {https://cran.r-project.org/package=glue},
year = {2019}
}
@book{Blanche-Benveniste1997,
address = {Paris},
author = {Blanche-Benveniste, Claire},
publisher = {{\'{E}}ditions OPHRYS},
title = {{Approches de la langue parl{\'{e}}e en fran{\c{c}}ais}},
year = {1997}
}
@article{Seguin2012,
author = {S{\'{e}}guin, Hubert},
doi = {10.7202/602776ar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/S{\'{e}}guin/S{\'{e}}guin{\_}2012{\_}Fr{\'{e}}quences d'utilisation des mots en fran{\c{c}}ais {\'{e}}crit contemporain. Jean Baudot, 1992, Les Presses de l'Universit{\'{e}} d.pdf:pdf},
issn = {0710-0167},
journal = {Revue qu{\'{e}}b{\'{e}}coise de linguistique},
number = {2},
pages = {179},
title = {{Fr{\'{e}}quences d'utilisation des mots en fran{\c{c}}ais {\'{e}}crit contemporain. Jean Baudot, 1992, Les Presses de l'Universit{\'{e}} de Montr{\'{e}}al, 432 p.}},
volume = {22},
year = {2012}
}
@manual{Gillespie2019,
annote = {R package version 1.0.2},
author = {Gillespie, Colin},
title = {{benchmarkmeData: Data Set for the 'benchmarkme' Package}},
url = {https://cran.r-project.org/package=benchmarkmeData},
year = {2019}
}
@manual{Kooperberg2019,
annote = {R package version 1.1.15},
author = {Kooperberg, Charles},
title = {{polspline: Polynomial Spline Routines}},
url = {https://cran.r-project.org/package=polspline},
year = {2019}
}
@manual{Ewing2019,
annote = {R package version 1.7.1},
author = {Ewing, Mark},
title = {{mgsub: Safe, Multiple, Simultaneous String Substitution}},
url = {https://cran.r-project.org/package=mgsub},
year = {2019}
}
@article{Lloyd2001,
author = {Lloyd, Seth},
doi = {10.1109/MCS.2001.939938},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lloyd/Lloyd{\_}2001{\_}Measures of Complexity A Nonexhaustive List.PDF:PDF},
issn = {1066033X},
journal = {IEEE Control Systems},
number = {4},
pages = {7--8},
title = {{Measures of Complexity: A Nonexhaustive List}},
volume = {21},
year = {2001}
}
@article{Mailhot2019,
abstract = {Studies on morphological processing in French, as in other languages, have shown disparate results. We argue that a critical and long-overlooked factor that could underlie these diverging results is the methodological differences in the calculation of morphological variables across studies. To address the need for a common morphological database, we present MorphoLex-FR, a sizeable and freely available database with 12 variables for prefixes, roots, and suffixes for the 38,840 words of the French Lexicon Project. MorphoLex-FR constitutes a first step to render future studies addressing morphological processing in French comparable. The procedure we used for morphological segmentation and variable computation is effectively the same as that in MorphoLex, an English morphological database. This will allow for cross-linguistic comparisons of future studies in French and English that will contribute to our understanding of how morphologically complex words are processed. To validate these variables, we explored their influence on lexical decision latencies for morphologically complex nouns in a series of hierarchical regression models. The results indicated that only morphological variables related to the suffix explained lexical decision latencies. The frequency and family size of the suffix exerted facilitatory effects, whereas the percentage of more frequent words in the morphological family of the suffix was inhibitory. Our results are in line with previous studies conducted in French and in English. In conclusion, this database represents a valuable resource for studies on the effect of morphology in visual word processing in French.},
author = {Mailhot, Hugo and Wilson, Maximiliano A. and Macoir, Jo{\"{e}}l and Deacon, S. H{\'{e}}l{\`{e}}ne and S{\'{a}}nchez-Guti{\'{e}}rrez, Claudia},
doi = {10.3758/s13428-019-01297-z},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mailhot et al/Mailhot et al.{\_}2019{\_}MorphoLex-FR A derivational morphological database for 38,840 French words.pdf:pdf},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Database,French,Lexical decision,Morphology,Psycholinguistic variables,Visual word recognition,morpholex},
mendeley-tags = {morpholex},
number = {Ld},
publisher = {Behavior Research Methods},
title = {{MorphoLex-FR: A derivational morphological database for 38,840 French words}},
year = {2019}
}
@manual{Michalke2018a,
annote = {(Version 0.1-3)},
author = {Michalke, Meik},
title = {{sylly.en: Language Support for 'sylly' Package: English}},
url = {http://reaktanz.de/?c=hacking{\&}s=koRpus},
year = {2018}
}
@article{Skehan2009a,
abstract = {Complexity, accuracy, and fluency have proved useful measures of second language performance. The present article will re-examine these measures themselves, arguing that fluency needs to be rethought if it is to be measured effectively, and that the three general measures need to be supplemented by measures of lexical use. Building upon this discussion, generalizations are reviewed which focus on inter-relationships between the measures, especially between accuracy and complexity, since positive correlations between these two areas have been less common in the literature. Some examples of accuracy–complexity correlations are reviewed. The central issue here is how to account for these correlations, and so the discussion explores rival claims from the Cognition and Trade-off Hypotheses. It is argued that such joint raised performance between accuracy and complexity is not a function of task difficulty, as the Cognition Hypothesis would predict, but that instead it reflects the joint operation of separate task and task condition factors. Extending the theoretical discussion, connection is made with the Levelt model of first language speaking, and it is proposed that the results obtained in the task-based performance literature can be linked to this model, modified to take account of differences between first and second language processing, particularly as these stem from differences in the underlying mental lexicons.},
archivePrefix = {arXiv},
arxivId = {astro-ph/9903154},
author = {Skehan, Peter},
doi = {10.1093/applin/amp047},
eprint = {9903154},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Skehan/Skehan{\_}2009{\_}Modelling second language performance Integrating complexity, accuracy, fluency, and lexis.pdf:pdf},
isbn = {0142-6001},
issn = {01426001},
journal = {Applied Linguistics},
number = {4},
pages = {510--532},
primaryClass = {astro-ph},
title = {{Modelling second language performance: Integrating complexity, accuracy, fluency, and lexis}},
volume = {30},
year = {2009}
}
@article{Fox2018,
author = {Fox, John and Weisberg, Sanford},
doi = {10.18637/jss.v087.i09},
journal = {Journal of Statistical Software},
number = {9},
pages = {1--27},
title = {{Visualizing Fit and Lack of Fit in Complex Regression Models with Predictor Effect Plots and Partial Residuals}},
url = {https://www.jstatsoft.org/v087/i09},
volume = {87},
year = {2018}
}
@manual{Sievert2018,
author = {Sievert, Carson},
title = {{plotly for R}},
url = {https://plotly-r.com},
year = {2018}
}
@article{Rohdenburg1996,
author = {Rohdenburg, G{\"{U}}nter},
doi = {10.1515/cogl.1996.7.2.149},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Rohdenburg/Rohdenburg{\_}1996{\_}Cognitive Complexity and Increased Grammatical Explicitness in English.pdf:pdf},
isbn = {0195129849},
issn = {16133641},
journal = {Cognitive Linguistics},
number = {2},
pages = {149--182},
title = {{Cognitive Complexity and Increased Grammatical Explicitness in English}},
volume = {7},
year = {1996}
}
@incollection{Polio2001,
address = {London},
author = {Polio, Charlene},
booktitle = {On Second Language Writing},
editor = {Silva, Tony J.; and Matsuda, P. K.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Polio/Polio{\_}2001{\_}Research Methodology in Second Language Writing Research.pdf:pdf},
publisher = {Lawrence Erlbaum},
title = {{Research Methodology in Second Language Writing Research}},
year = {2001}
}
@article{Granger1997,
author = {Granger, Sylviane},
doi = {10.1177/007542429702500410},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger/Granger{\_}1997{\_}Automated retrieval of passives from native and learner corpora Precision and recall.pdf:pdf},
issn = {00754242},
journal = {Journal of English Linguistics},
number = {4},
pages = {365--374},
title = {{Automated retrieval of passives from native and learner corpora: Precision and recall}},
volume = {25},
year = {1997}
}
@manual{Muller2020,
annote = {R package version 0.5.3},
author = {M{\"{u}}ller, Kirill},
title = {{hms: Pretty Time of Day}},
url = {https://cran.r-project.org/package=hms},
year = {2020}
}
@phdthesis{VanRyckeghem2008,
author = {{Van Ryckeghem}, Victoria},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Van Ryckeghem/Van Ryckeghem{\_}2008{\_}L'organisation discursive et les connecteurs temporels en fran{\c{c}}ais et en n{\'{e}}erlandais L1 et L2.pdf:pdf},
school = {Universiteit Gent},
title = {{L'organisation discursive et les connecteurs temporels en fran{\c{c}}ais et en n{\'{e}}erlandais L1 et L2}},
type = {Master Thesis},
year = {2008}
}
@article{Treffers-Daller2018,
author = {Treffers-Daller, Jeanine and Parslow, Patrick and Williams, Shirley},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Treffers-Daller, Parslow, Williams/Treffers-Daller, Parslow, Williams{\_}2018{\_}Diversity Can Help Discriminate Between.pdf:pdf},
journal = {Applied Linguistics},
title = {{Diversity Can Help Discriminate Between}},
year = {2018}
}
@inproceedings{SchaeferBildhauer2012full,
abstract = {Over the last decade, methods of web corpus construction and the evaluation of web corpora have been actively researched. Prominently, the WaCky initiative has provided both theoretical results and a set of web corpora for selected European languages. We present a software toolkit for web corpus construction and a set of siginificantly larger corpora (up to over 9 billion tokens) built using this software. First, we discuss how the data should be collected to ensure that it is not biased towards certain hosts. Then, we describe our software toolkit which performs basic cleanups as well as boilerplate removal, simple connected text detection as well as shingling to remove duplicates from the corpora. We finally report evaluation results of the corpora built so far, for example w. r. t. the amount of duplication contained and the text type/genre distribution. Where applicable, we compare our corpora to the WaCky corpora, since it is inappropriate, in our view, to compare web corpora to traditional or balanced corpora. While we use some methods applied by the WaCky initiative, we can show that we have introduced incremental improvements.},
address = {Istanbul, Turkey},
author = {Sch{\"{a}}fer, Roland and Bildhauer, Felix},
booktitle = {Proceedings of the eighth international conference on language resources and evaluation (LREC'12)},
editor = {Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Doğan, Mehmet Uğur and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Sch{\"{a}}fer, Bildhauer/Sch{\"{a}}fer, Bildhauer{\_}2012{\_}Building large corpora from the web using a new efficient tool chain.pdf:pdf},
isbn = {978-2-9517408-7-7},
keywords = {frcow},
mendeley-tags = {frcow},
pages = {486--493},
publisher = {European Language Resources Association (ELRA)},
title = {{Building large corpora from the web using a new efficient tool chain}},
year = {2012}
}
@manual{Bryan2017,
annote = {R package version 1.0.1},
author = {Bryan, Jennifer and Wickham, Hadley},
title = {{gh: 'GitHub' 'API'}},
url = {https://cran.r-project.org/package=gh},
year = {2017}
}
@article{Lindqvist2011,
abstract = {This study investigates Swedish learners' lexical richness in French and Italian L2. A frequency-based measure was used to compare the lexical richness of learners at different proficiency levels to that of native speakers. Frequency bands based on oral L1 data were created for both languages to serve as a benchmark. For French, the results show that there are differences between two groups of learners at different proficiency levels concerning lexical richness. Moreover, the most advanced learners have a lexical profile that is similar to that of a control group of native speakers, suggesting that these learners are native-like as far as lexical richness is concerned. The results for Italian also point at differences between the learner groups. However, the most advanced group does not reach the degree of lexical richness of the native speakers. The overall results support earlier proposals of a discriminating capacity of lexical frequency profiling methods for L2 proficiency.},
author = {Lindqvist, Christina and Bardel, Camilla and Gudmundson, Anna},
doi = {10.1515/iral.2011.013},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lindqvist, Bardel, Gudmundson/Lindqvist, Bardel, Gudmundson{\_}2011{\_}Lexical richness in the advanced learner's oral production of French and Italian L2.pdf:pdf},
issn = {0019042X},
journal = {IRAL - International Review of Applied Linguistics in Language Teaching},
number = {3},
pages = {221--240},
title = {{Lexical richness in the advanced learner's oral production of French and Italian L2}},
volume = {49},
year = {2011}
}
@article{Jaffre1992,
author = {Jaffr{\'{e}}, Jean-pierre},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jaffr{\'{e}}/Jaffr{\'{e}}{\_}1992{\_}Le traitement {\'{e}}l{\'{e}}mentaire de l ' orthographe les proc{\'{e}}dures graphiques.pdf:pdf},
journal = {Langue fran{\c{c}}aise},
pages = {27--48},
title = {{Le traitement {\'{e}}l{\'{e}}mentaire de l ' orthographe : les proc{\'{e}}dures graphiques}},
volume = {95},
year = {1992}
}
@book{Rescher1998,
address = {London},
author = {Rescher, Nicholas},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Rescher/Rescher{\_}1998{\_}Complexity A Philosophical Overview.pdf:pdf},
publisher = {Transaction Publishers},
title = {{Complexity: A Philosophical Overview}},
year = {1998}
}
@inproceedings{Bourigault2005,
address = {Dourdan},
author = {Bourigault, Didier and Fabre, C{\'{e}}cile and Fr{\'{e}}rot, C{\'{e}}cile and Jacques, Marie-Paule and Syntex, Sylwia Ozdowska},
booktitle = {Actes des 12{\`{e}}mes journ{\'{e}}es sur le Traitement Automatique des Langues Naturelles},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bourigault et al/Bourigault et al.{\_}2005{\_}Syntex , analyseur syntaxique de corpus To cite this version.pdf:pdf},
title = {{Syntex , analyseur syntaxique de corpus To cite this version}},
year = {2005}
}
@manual{Mori2019,
annote = {R package version 0.5.2},
author = {Mori, Kota},
title = {{striprtf: Extract Text from RTF File}},
url = {https://cran.r-project.org/package=striprtf},
year = {2019}
}
@manual{Bengtsson2018,
annote = {R package version 0.54.0},
author = {Bengtsson, Henrik},
title = {{matrixStats: Functions that Apply to Rows and Columns of Matrices (and to Vectors)}},
url = {https://cran.r-project.org/package=matrixStats},
year = {2018}
}
@manual{Ooms2019a,
annote = {R package version 2.2},
author = {Ooms, Jeroen},
title = {{pdftools: Text Extraction, Rendering and Converting of PDF Documents}},
url = {https://cran.r-project.org/package=pdftools},
year = {2019}
}
@article{DeLeeuw2015,
abstract = {The measurement and reporting of model error is of basic importance when construct- ing models. Here, a general method and an R package, A3, are presented to support the assessment and communication of the quality of a model fit along with metrics of variable importance. The presented method is accurate, robust, and adaptable to a wide range of predictive modeling algorithms. The method is described along with case studies and a usage guide. It is shown how the method can be used to obtain more accurate models for prediction and how this may simultaneously lead to altered inferences and conclusions about the impact of potential drivers within a system.},
author = {{De Leeuw}, Jan},
doi = {10.1002/wics.10},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/De Leeuw/De Leeuw{\_}2015{\_}Journal of statistical software.pdf:pdf},
issn = {19395108},
journal = {Journal of Statistical Software},
keywords = {goodness of fit,model selection,variable importance},
number = {7},
pages = {128--129},
title = {{Journal of statistical software}},
volume = {66},
year = {2015}
}
@article{Ellis2002,
abstract = {This article shows how language processing is intimately tuned to input frequency. Examples are given of frequency effects in the processing of phonology, phonotactics, reading, spelling, lexis, mor-phosyntax, formulaic language, language comprehension, grammat-icality, sentence production, and syntax. The implications of these effects for the representations and developmental sequence of SLA are discussed. Usage-based theories hold that the acquisition of lan-guage is exemplar based. It is the piecemeal learning of many thou-sands of constructions and the frequency-biased abstraction of regularities within them. Determinants of pattern productivity include the power law of practice, cue competition and constraint satisfac-tion, connectionist learning, and effects of type and token frequency. The regularities of language emerge from experience as categories and prototypical patterns. The typical route of emergence of con-structions is from formula, through low-scope pattern, to construction. Frequency plays a large part in explaining sociolinguistic variation and language change. Learners' sensitivity to frequency in all these domains has implications for theories of implicit and explicit learning and their interactions. The review concludes by considering the his-tory of frequency as an explanatory concept in theoretical and ap-plied linguistics, its 40 years of exile, and its necessary reinstatement as a bridging variable that binds the different schools of language ac-quisition research. There is a lot more to the perception of language than meets the eye or ear. A percept is a complex state of consciousness in which antecedent sensation is supplemented by consequent ideas that are closely combined to it by asso-ciation. The cerebral conditions of the perception of things are thus the paths of association irradiating from them. If a certain sensation is strongly associ-ated with the attributes of a certain thing, that thing is almost sure to be per-ceived when we get that sensation. Where the sensation is associated with more than one reality, however, unconscious processes weigh the odds, and we perceive the most probable thing: " all brain-processes are such as give rise to what we may call FIGURED consciousness " (James, 1890, p. 82, emphasis in original). Accurate and fluent language perception, then, rests on the compre-hender having acquired the appropriately weighted range of associations for each element of the language input. Psycholinguistic and cognitive linguistic theories of language acquisition hold that all linguistic units are abstracted from language use. In these usage-based perspectives, the acquisition of grammar is the piecemeal learning of many thousands of constructions and the frequency-biased abstraction of reg-ularities within them. Language learning is the associative learning of repre-sentations that reflect the probabilities of occurrence of form-function mappings. Frequency is thus a key determinant of acquisition because " rules " of language, at all levels of analysis (from phonology, through syntax, to dis-course), are structural regularities that emerge from learners' lifetime analysis of the distributional characteristics of the language input. Learners have to figure language out. This review illustrates (a) how frequency underpins regularity effects in the acquisition of orthographic, phonological, and morphological form, and (b) that learning accords to the power law of practice. It shows, for example, that there are effects of bigram frequency in visual word identification and of pho-notactic knowledge in speech segmentation, effects of spelling-to-sound corre-spondences in reading, and cohort effects in spoken-word recognition. There are effects of neighbors and the proportion of friends (items that share sur-face-pattern cues and have the same interpretation) to enemies (items that share surface-pattern cues but have different interpretations) in reading and spelling, morphology, and spoken-word recognition. At higher levels, it can be shown that language comprehension is determined by the listeners' vast amount of statistical information about the behavior of lexical items in their language and that, at least for English, verbs provide some of the strongest constraints on the resolution of syntactic ambiguities. Comprehenders know the relative frequencies with which individual verbs appear in different tenses, in active versus passive structures and in intransitive versus transitive struc-tures, the typical kinds of subjects and objects that a verb takes, and many other such facts. Such information is acquired through experience with input that exhibits these distributional properties. It is not some idiosyncratic fact},
author = {Ellis, Nick C},
doi = {10.1017/S0272263102002024},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis/Ellis{\_}2002{\_}Frequency effects in language processing A review with implications for theories of implicit and explicit language acquisitio.pdf:pdf},
issn = {1470-1545},
journal = {Studies in Second Language Acquisition},
keywords = {Grammar,Language Processing,Language Research,Linguistic Input,Morphology (Languages),Phonology,Second Language Learning,Spelling,Syntax,Vocabulary Development,Word Frequency},
number = {2},
pages = {143--188},
publisher = {UCL Universit{\'{e}} Catholique de Louvain},
title = {{Frequency effects in language processing: A review with implications for theories of implicit and explicit language acquisition}},
volume = {24},
year = {2002}
}
@manual{Csardi2018c,
annote = {R package version 1.0.0},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and Boudra, Fathi and Dieter, Rex and Krammer, Kevin and White, Jeremy},
title = {{xopen: Open System Files, 'URLs', Anything}},
url = {https://cran.r-project.org/package=xopen},
year = {2018}
}
@article{Gries2015b,
abstract = {Much statistical analysis of psycholinguistic data is now being done with so-called mixed-effects regression models. This development was spearheaded by a few highly influential introductory articles that (i) showed how these regression models are superior to what was the previous gold standard and, perhaps even more importantly, (ii) showed how these models are used practically. Corpus linguistics can benefit from mixed-effects/multi-level models for the same reason that psycholinguistics can - because, for example, speaker-specific and lexically specific idiosyncrasies can be accounted for elegantly; but, in fact, corpus linguistics needs them even more because (i) corpus-linguistic data are observational and, thus, usually unbalanced and messy/noisy, and (ii) most widely used corpora come with a hierarchical structure that corpus linguists routinely fail to consider. Unlike nearly all overviews of mixed-effects/multi-level modelling, this paper is specifically written for corpus linguists to get more of them to start using these techniques more. After a short methodological history, I provide a nontechnical introduction to mixed-effects models and then discuss in detail one example - particle placement in English - to show how mixed-effects/multilevel modelling results can be obtained and how they are far superior to those of traditional regression modelling. {\textcopyright} Edinburgh University Press.},
author = {Gries, Stefan Th.},
doi = {10.3366/cor.2015.0068},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2015{\_}The most under-used statistical method in corpus linguistics Multi-level (and mixed-effects) models.pdf:pdf},
isbn = {1749-5032$\backslash$r1755-1676},
issn = {17551676},
journal = {Corpora},
keywords = {Corpus structure,Lexically specific effects multi-level modelling,Speaker-specific effects,Varying slopes and intercepts,Verb-particle construction},
number = {1},
pages = {95--125},
title = {{The most under-used statistical method in corpus linguistics: Multi-level (and mixed-effects) models}},
volume = {10},
year = {2015}
}
@incollection{Kuiken2011a,
address = {Amsterdam},
author = {Kuiken, Folkert and Vedder, Ineke},
booktitle = {Second Language Task Complexity : Researching the Cognition Hypothesis of Language Learning and Performance},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiken, Vedder/Kuiken, Vedder{\_}2011{\_}Task complexity and linguistic performance in L2 writing and speaking.pdf:pdf},
pages = {91--104},
publisher = {John Benjamins},
title = {{Task complexity and linguistic performance in L2 writing and speaking}},
year = {2011}
}
@article{Zeileis2006,
author = {Zeileis, Achim},
doi = {10.18637/jss.v016.i09},
journal = {Journal of Statistical Software},
number = {9},
pages = {1--16},
title = {{Object-Oriented Computation of Sandwich Estimators}},
volume = {16},
year = {2006}
}
@article{Paquot2018,
abstract = {ABSTRACTThe main objective of this article is to demonstrate with the help of learner corpus data the practical relevance of the phraseological dimension of language for writing assessment in higher education. Phraseological competence is now widely recognized as an important part of fluent and idiomatic language use, but its development has not received the attention it deserves in the CEFR. The study investigates the development of linguistic correlates of syntactic, lexical, and phraseological complexity in learner texts at B2, C1, and C2 and shows that while no measure of syntactic or lexical complexity seems to have an impact on human raters' overall judgement of writing quality, two measures of phraseological complexity explain 25{\%} of the variance in the data set. Results suggest that incorporating phraseological competence into the scoring rubrics of university entrance language tests would help language test developers add construct validity to language assessment in higher education. More general...},
author = {Paquot, Magali},
doi = {10.1080/15434303.2017.1405421},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot/Paquot{\_}2018{\_}Phraseological competence A missing component in university entrance language tests Insights from a study of EFL learners'.pdf:pdf},
issn = {15434311},
journal = {Language Assessment Quarterly},
number = {1},
pages = {29--43},
publisher = {Routledge},
title = {{Phraseological competence: A missing component in university entrance language tests? Insights from a study of EFL learners' use of statistical collocations}},
url = {https://doi.org/10.1080/15434303.2017.1405421},
volume = {15},
year = {2018}
}
@incollection{Veronique2017b,
address = {Brussels},
author = {Veronique, Georges Daniel},
booktitle = {Complexit{\'{e}}S},
editor = {Hadermann, Pascale and Housen, Alex and {Van Raemdonck}, Dan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Veronique/Veronique{\_}2017{\_}Vers l'{\'{e}}nonc{\'{e}} complexe en fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re quelques voies de d{\'{e}}veloppement.pdf:pdf},
pages = {101--122},
publisher = {P.I.E. PETER LANG S.A.},
title = {{Vers l'{\'{e}}nonc{\'{e}} complexe en fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re : quelques voies de d{\'{e}}veloppement}},
year = {2017}
}
@manual{Tremblay2015,
annote = {R package version 2.10},
author = {Tremblay, Antoine and University, Dalhousie and Ransijn, Johannes and of Copenhagen, University},
title = {{LMERConvenienceFunctions: Model Selection and Post-hoc Analysis for (G)LMER Models}},
url = {https://cran.r-project.org/package=LMERConvenienceFunctions},
year = {2015}
}
@phdthesis{Buyl2016,
author = {Buyl, Afke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Buyl/Buyl{\_}2016{\_}Theoretical foundations of PT.pdf:pdf},
title = {{Theoretical foundations of PT}},
year = {2016}
}
@manual{Perry2018,
annote = {R package version 1.1.4},
author = {Perry, Patrick O},
title = {{utf8: Unicode Text Processing}},
url = {https://cran.r-project.org/package=utf8},
year = {2018}
}
@inproceedings{Bulte2009,
address = {Lancaster},
author = {Bult{\'{e}}, Bram and Housen, Alex},
booktitle = {Task Based Language Teaching Conference},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}}, Housen/Bult{\'{e}}, Housen{\_}2009{\_}The development of lexical proficiency in L2 speaking and writing tasks by Dutch-speaking learners of French in Brus.pdf:pdf},
title = {{The development of lexical proficiency in L2 speaking and writing tasks by Dutch-speaking learners of French in Brussels}},
year = {2009}
}
@misc{Newman1998,
author = {Newman, D J and Hettich, S and Blake, C L and Merz, C J},
institution = {University of California, Irvine, Dept. of Information and Computer Sciences},
title = {{UCI Repository of machine learning databases}},
url = {http://www.ics.uci.edu/{~}mlearn/MLRepository.html},
year = {1998}
}
@incollection{Carlo2009,
address = {Paris},
author = {Carlo, Catherine and Granget, Cyrille and Kim, Jin-Ok and Prodeau, Mireille},
booktitle = {L'aquisition de la grammaire du fran{\c{c}}ais, langue {\'{e}}trang{\`{e}}re},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Carlo et al/Carlo et al.{\_}2009{\_}De l'{\'{e}}nonc{\'{e}} simple {\`{a}} l'{\'{e}}nonc{\'{e}} complexe.pdf:pdf},
pages = {219--288},
publisher = {Didier},
title = {{De l'{\'{e}}nonc{\'{e}} simple {\`{a}} l'{\'{e}}nonc{\'{e}} complexe}},
year = {2009}
}
@book{Wolfe-Quintero1998,
address = {Honolulu},
author = {Wolfe-Quintero, Kate and Inagaki, Shunji and Kim, Hae-Yong},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wolfe-Quintero, Inagaki, Kim/Wolfe-Quintero, Inagaki, Kim{\_}1998{\_}Second Language Development in Writing Measures of Fluency, Accuracy {\&} Complexity.pdf:pdf},
publisher = {Second Language Teaching {\&} Curriculum Center},
title = {{Second Language Development in Writing: Measures of Fluency, Accuracy {\&} Complexity}},
year = {1998}
}
@article{Skehan2009,
abstract = {Complexity, accuracy, and fluency have proved useful measures of second language performance. The present article will re-examine these measures themselves, arguing that fluency needs to be rethought if it is to be measured effectively, and that the three general measures need to be supplemented by measures of lexical use. Building upon this discussion, generalizations are reviewed which focus on inter-relationships between the measures, especially between accuracy and complexity, since positive correlations between these two areas have been less common in the literature. Some examples of accuracy–complexity correlations are reviewed. The central issue here is how to account for these correlations, and so the discussion explores rival claims from the Cognition and Trade-off Hypotheses. It is argued that such joint raised performance between accuracy and complexity is not a function of task difficulty, as the Cognition Hypothesis would predict, but that instead it reflects the joint operation of separate task and task condition factors. Extending the theoretical discussion, connection is made with the Levelt model of first language speaking, and it is proposed that the results obtained in the task-based performance literature can be linked to this model, modified to take account of differences between first and second language processing, particularly as these stem from differences in the underlying mental lexicons.},
author = {Skehan, Peter},
doi = {10.1093/applin/amp047},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Skehan/Skehan{\_}2009{\_}Modelling second language performance Integrating complexity, accuracy, fluency, and lexis(2).pdf:pdf},
issn = {01426001},
journal = {Applied Linguistics},
number = {4},
pages = {510--532},
title = {{Modelling second language performance: Integrating complexity, accuracy, fluency, and lexis}},
volume = {30},
year = {2009}
}
@manual{Koenker2019,
annote = {R package version 5.51},
author = {Koenker, Roger},
title = {{quantreg: Quantile Regression}},
url = {https://cran.r-project.org/package=quantreg},
year = {2019}
}
@article{Fox2009,
author = {Fox, John and Hong, Jangman},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--24},
title = {{Effect Displays in {\{}R{\}} for Multinomial and Proportional-Odds Logit Models: Extensions to the {\{}effects{\}} Package}},
url = {http://www.jstatsoft.org/v32/i01/},
volume = {32},
year = {2009}
}
@incollection{Demol2008,
address = {Amsterdam},
author = {Demol, Annemie and Hadermann, Pascale},
booktitle = {Linking up contrastive and learner corpus research},
doi = {10.1163/9789401206204_011},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Demol, Hadermann/Demol, Hadermann{\_}2008{\_}An exploratory study of discourse organisation in French L1, Dutch L1, French L2 and Dutch L2 written narratives.pdf:pdf},
keywords = {lcf},
mendeley-tags = {lcf},
pages = {255--282},
publisher = {Rodopi},
title = {{An exploratory study of discourse organisation in French L1, Dutch L1, French L2 and Dutch L2 written narratives}},
year = {2008}
}
@article{Gell-Mann1995,
author = {Gell-Mann, Murray},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gell-Mann/Gell-Mann{\_}1995{\_}What is complexity Remarks on simplicity and complexity.pdf:pdf},
journal = {Complexity},
number = {1},
pages = {16--19},
title = {{What is complexity? Remarks on simplicity and complexity}},
volume = {1},
year = {1995}
}
@manual{Wickham2018c,
annote = {R package version 1.0.2},
author = {Wickham, Hadley and Hester, Jim and Chang, Winston},
title = {{pkgload: Simulate Package Installation and Attach}},
url = {https://cran.r-project.org/package=pkgload},
year = {2018}
}
@incollection{Kormos2014,
address = {Amsterdam},
author = {Kormos, Judit},
booktitle = {Task-Based Language Learning: Insights from and for L2 Writing},
editor = {Byrnes, Heidi and Manchón, Rosa M.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kormos/Kormos{\_}2014{\_}Differences across modalities of performance An investigation of linguistic and discourse complexity in narrative tasks.pdf:pdf},
pages = {193--216},
publisher = {John Benjamins},
title = {{Differences across modalities of performance: An investigation of linguistic and discourse complexity in narrative tasks}},
year = {2014}
}
@article{Kuiken2019,
author = {Kuiken, Folkert and Vedder, Ineke and Housen, Alex and {De Clercq}, Bastien},
doi = {10.1111/ijal.12255},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiken et al/Kuiken et al.{\_}2019{\_}Variation in syntactic complexity Introduction.pdf:pdf},
issn = {0802-6106},
journal = {International Journal of Applied Linguistics},
number = {[Special Issue]},
pages = {1--10},
title = {{Variation in syntactic complexity: Introduction}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ijal.12255},
year = {2019}
}
@book{Carroll1964,
address = {Engelwood Cliffs},
author = {Carroll, J.B.},
keywords = {lexdiv{\_}cttr},
mendeley-tags = {lexdiv{\_}cttr},
publisher = {Prentice Hall},
title = {{Language and Thought}},
year = {1964}
}
@manual{Gohel2020c,
annote = {R package version 0.3.12},
author = {Gohel, David},
title = {{officer: Manipulation of Microsoft Word and PowerPoint Documents}},
url = {https://cran.r-project.org/package=officer},
year = {2020}
}
@incollection{Lord2002,
author = {Lord, Carol},
booktitle = {Complex Sentences in Grammar and Discourse. Essays in honor of Sandra A. Thompson.},
editor = {Bybee, Joan and Noonan, Michael},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lord/Lord{\_}2002{\_}Are subordinate clauses more difficult.pdf:pdf},
issn = {9027297150},
pages = {231--242},
publisher = {John Benjamins},
title = {{Are subordinate clauses more difficult?}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=l-WbrWslFHQC{\&}oi=fnd{\&}pg=PA223{\&}dq=Are+subordinate+clauses+more+difficult{\%}3F{\&}ots=9cw{\_}rCPisI{\&}sig=kXe{\_}qr8xs7Prouf{\_}Os{\_}OOf2r2e4},
year = {2002}
}
@inproceedings{LoBosco2018,
address = {Trento},
author = {{Lo Bosco}, Giosu{\'{e}} and Pilato, Giovanni and Schicchi, Daniele},
booktitle = {NL4AI},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lo Bosco, Pilato, Schicchi/Lo Bosco, Pilato, Schicchi{\_}2018{\_}A Sentence based System for Measuring Syntax Complexity using a Recurrent Deep Neural Network.pdf:pdf},
keywords = {deep,natural language processing,text simplification},
month = {nov},
pages = {95--101},
title = {{A Sentence based System for Measuring Syntax Complexity using a Recurrent Deep Neural Network}},
year = {2018}
}
@inproceedings{Dascalu2012,
author = {Dascălu, Mihai and Trausan-matu, Stefan and Dessus, Philippe},
booktitle = {ICWL 2012},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dascălu, Trausan-matu, Dessus/Dascălu, Trausan-matu, Dessus{\_}2012{\_}Towards an Integrated Approach for Evaluating Textual Complexity for Learning Purposes.pdf:pdf},
keywords = {latent semantic analysis,readability,support,textual complexity},
pages = {268--278},
title = {{Towards an Integrated Approach for Evaluating Textual Complexity for Learning Purposes}},
year = {2012}
}
@manual{Rinker2018b,
address = {Buffalo, New York},
annote = {version 1.6.0},
author = {Rinker, Tyler W},
title = {{{\{}textshape{\}}: Tools for Reshaping Text}},
url = {https://github.com/trinker/textshape},
year = {2018}
}
@article{Gries2015a,
abstract = {The advent of usage-/exemplar-based approaches has resulted in a major change in the theoretical landscape of linguistics, but also in the range of methodologies that are brought to bear on the study of language acquisition/learning, structure, and use. In particular, methods from corpus linguistics are now frequently used to study distributional characteristics of linguistics units and what they reveal about cognitive and psycholinguistic processes. This paper surveys a range of psycholinguistic notions that are becoming ever more important in theoretical and cognitive linguistics—for example, frequency, entrenchment, dispersion, contingency, surprisal, Zipfian distributions—and current corpus-linguistic approaches toward exploring these notions and their roles for linguistic cognition.},
author = {Gries, Stefan Th. and Ellis, Nick C},
doi = {10.1111/lang.12119},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries, Ellis/Gries, Ellis{\_}2015{\_}Statistical Measures for Usage-Based Linguistics.pdf:pdf},
isbn = {1467-9922},
issn = {14679922},
journal = {Language Learning},
keywords = {Associative learning,Contingency/association,Corpus data,Dispersion,Frequency,Psycholinguistics,Surprisal},
number = {1},
pages = {228--255},
title = {{Statistical Measures for Usage-Based Linguistics}},
volume = {65},
year = {2015}
}
@article{Gries2019,
author = {Gries, Stefan Th.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2019{\_}15 Years of Collostructions Some Long Overdue AdditionsCorrections (Toof Actually All Sorts of Corpus-Linguistics Measures).pdf:pdf},
journal = {International Journal of Corpus Linguistics},
number = {3},
pages = {387--414},
title = {{15 Years of Collostructions: Some Long Overdue Additions/Corrections (To/of Actually All Sorts of Corpus-Linguistics Measures)}},
volume = {24},
year = {2019}
}
@article{Artstein2008,
abstract = {This article is a survey of methods for measuring agreement among corpus annotators. It exposes the mathematics and underlying assumptions of agreement coefficients, covering Krippendorff's alpha as well as Scott's pi and Cohen's kappa; discusses the use of coefficients in several annotation tasks; and argues that weighted, alpha-like coefficients, traditionally less used than kappa-like measures in computational linguistics, may be more appropriate for many corpus annotation tasks-but that their use makes the interpretation of the value of the coefficient even harder. {\textcopyright} 2008 Association for Computational Linguistics.},
author = {Artstein, Ron and Poesio, Massimo},
doi = {10.1162/coli.07-034-R2},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Artstein, Poesio/Artstein, Poesio{\_}2008{\_}Inter-coder agreement for computational linguistics.pdf:pdf},
issn = {15309312},
journal = {Computational Linguistics},
number = {4},
pages = {555--596},
title = {{Inter-coder agreement for computational linguistics}},
volume = {34},
year = {2008}
}
@manual{Leisch2010,
annote = {R package version 2.1-1},
author = {Leisch, Friedrich and Dimitriadou, Evgenia},
title = {{mlbench: Machine Learning Benchmark Problems}},
year = {2010}
}
@manual{Csardi2018b,
annote = {R package version 1.2.0},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and M{\"{u}}ller, Kirill and Hester, Jim},
title = {{desc: Manipulate DESCRIPTION Files}},
url = {https://cran.r-project.org/package=desc},
year = {2018}
}
@manual{Pinheiro2019,
annote = {R package version 3.1-140},
author = {Pinheiro, Jose and Bates, Douglas and DebRoy, Saikat and Sarkar, Deepayan and {R Core Team}},
title = {{{\{}nlme{\}}: Linear and Nonlinear Mixed Effects Models}},
url = {https://cran.r-project.org/package=nlme},
year = {2019}
}
@incollection{Cobb2004,
abstract = {Extensive analysis of corpora has offered learners of English a solution to the problem of which among the many thousands of English words are most useful to know by identifying lists of high frequency words that make up the core of the language. Of particular interest to university-bound learners is Coxhead's (2000) Academic Word List (AWL). Analyses indicate that knowing the 570 word families on this list along with the 2000 most frequent families consistently offers coverage of about 85{\%} of the words learners will encounter in reading an academic text in English. This finding raises the question of whether such lists can be identified in other languages. The research reported in this chapter provides an initial answer in the case of French. Lists of the 2000 most frequent French word families were built into an online lexical frequency profiling program (Vocabprofil) and their coverage powers tested. Analyses of texts using this tool confirmed the usefulness of the lists in identifying distinct and consistent profiles for French texts of three specific genres (newspaper, popular expository, and medical). Comparisons using parallel French and English texts indicated that the 2000 most frequent word families of French offer the reader a surprisingly high level of coverage (roughly 85{\%}), a level that can only be achieved in English with the knowledge of the most frequent 2000 words plus the 570 AWL words. In other words, the French 2000 list seems to serve both everyday and academic purposes more effectively than its English counterpart, such that there appears to be no need for an additional AWL-like list in French to facilitate the comprehension of academic texts. With the coverage powers of the French 2000 list so high, there appears to be little or no space left in the lexis of French for such a list to occupy.},
address = {Amsterdam},
author = {Cobb, Tom and Horst, Marlise},
booktitle = {Vocabulary in a second language : Selection, acquisition, and testing},
doi = {10.1075/lllt.10.04cob},
editor = {Bogaards, Paul and Laufer, Batia},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cobb, Horst/Cobb, Horst{\_}2004{\_}Is there room for an academic word list in French.pdf:pdf},
pages = {15--38},
publisher = {John Benjamins},
title = {{Is there room for an academic word list in French?}},
year = {2004}
}
@manual{Lang2019,
annote = {R package version 1.1.4},
author = {Lang, Michel and {R Core Team}},
title = {{backports: Reimplementations of Functions Introduced Since R-3.0.0}},
url = {https://cran.r-project.org/package=backports},
year = {2019}
}
@article{Erman2015,
abstract = {Keywords: L2 acquisition;formulaic language;socio-pragmatics;idiomaticity;nativelike performance;multiword structures Acquisition L2;langage pr{\'{e}}fabriqu{\'{e}};socio-pragmatique;idiomatique;authenticit{\'{e}};s{\'{e}}quences pr{\'{e}}fabriqu{\'{e}}es Nativelike expression in L2 speech is investigated by comparing quantity and distribution of different types of multiword structures (MWSs) in the speech of very advanced L2 speakers with native speakers. Swedish speakers of L2 English, L2 French and L2 Spanish (average LOR in the UK, France and Chile 7–10 years) performing two oral tasks, a role play, and an online retelling task, are compared with matching native speakers, totalling 140,000 words. The L2 groups were nativelike in their use of MWSs as social routines in the role play. Collocations, the dominant category in the retelling task, were underrepresented in all three L2 groups compared to the native groups. Furthermore, the English NNSs were nativelike on more measurements of MWSs than the French and Spanish NNSs.},
author = {Erman, Britt and Denke, Annika and Fant, Lars and {Forsberg Lundell}, Fanny},
doi = {10.1111/ijal.12061},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Erman et al/Erman et al.{\_}2015{\_}Nativelike expression in the speech of long-residency L2 users A study of multiword structures in L2 English, French a.pdf:pdf},
isbn = {1473-4192},
issn = {14734192},
journal = {International Journal of Applied Linguistics},
keywords = {Formulaic language,Idiomaticity,L2 acquisition,Multiword structures,Nativelike performance,Socio-pragmatics},
number = {2},
pages = {160--182},
title = {{Nativelike expression in the speech of long-residency L2 users: A study of multiword structures in L2 English, French and Spanish}},
volume = {25},
year = {2015}
}
@inproceedings{InstitutLangageetCommunicationUCLouvain2019,
address = {Louvain-la-Neuve},
author = {{Institut Langage et Communication (UCLouvain)}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Institut Langage et Communication (UCLouvain)/Institut Langage et Communication (UCLouvain){\_}2019{\_}Anonymisation et RGPD Quel(s) impact(s) pour la recherche.pdf:pdf},
title = {{Anonymisation et RGPD : Quel(s) impact(s) pour la recherche?}},
year = {2019}
}
@article{ForsbergLundell2014b,
abstract = {The present study investigates the possibilities for adult learners to attain nativelikeness in the domain of lexis. Aspects investigated are general lexical knowledge (C-test), receptive deep knowledge, productive collocation knowledge, and productive lexico-pragmatic knowledge in a group of long-residency Swedish French second language (L2) users in France and a matched native control group. The analysis includes correlations between these different vocabulary aspects as well as their relation to the length of residence in the target-language (TL) community. The study reveals that it is possible for L2 learners to attain nativelikeness in general lexical knowledge and lexico-pragmatic knowledge, whereas deep knowledge and collocations are especially difficult for L2 learners, supporting earlier research findings. Furthermore, a strong correlation is found between general lexical knowledge and collocations, but surprisingly not between any of the other aspects, or between vocabulary aspects and length of residence. The results are discussed in light of individual differences in research.},
author = {{Forsberg Lundell}, Fanny and Lindqvist, Christina},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Forsberg Lundell, Lindqvist/Forsberg Lundell, Lindqvist{\_}2014{\_}Lexical aspects of very advanced L2 French.pdf:pdf},
journal = {The Canadian Modern Language Review / La revue canadienne des langues vivantes},
number = {1},
pages = {28--49},
title = {{Lexical aspects of very advanced L2 French}},
url = {https://muse.jhu.edu/article/537157},
volume = {70},
year = {2014}
}
@book{Beacco2007,
address = {Paris},
author = {Beacco, J and Porquier, R},
publisher = {Didier},
title = {{Niveau A1 pour le fran{\c{c}}ais (utilisateur / apprenant {\'{e}}l{\'{e}}mentaire)}},
year = {2007}
}
@incollection{Erman2013,
abstract = {This book discusses current methodological debates on the synergy of Corpus Linguistics and Pragmatics research. The volume presents insightful Pragmatic analyses of corpora in new technological domains and devotes some chapters to the pragmatic description of spoken corpora from various theoretical traditions. The 'Yearbook of Corpus Linguistics and Pragmatics' series will give readers insight into how Pragmatics can be used to explain real corpus data, and, in addition, how corpora can explain Pragmatic intuitions, and from there, develop and refine theory. Corpus Linguistics can offer a meticulous methodology based on mathematics and statistics, while Pragmatics is characterized by its efforts to interpret intended meaning in real language. This yearbook offers a platform to scholars who combine both research methodologies to present rigorous and interdisciplinary findings about language in real use.0.},
address = {Dordrecht},
author = {Erman, Britt and Lewis, Margareta and Fant, Lars},
booktitle = {Yearbook of Corpus Linguistics and Pragmatics 2013},
doi = {10.1007/978-94-007-6250-3},
editor = {Romero-Trillo, Jesús},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Erman, Lewis, Fant/Erman, Lewis, Fant{\_}2013{\_}Multiword Structures in Different Materials, and with Different Goals and Methodologies.pdf:pdf},
isbn = {978-94-007-6249-7},
keywords = {conceptual metaphor,corpus-based,metaphorical uses of time,phraseological behaviour,theory},
pages = {77--103},
publisher = {Springer},
title = {{Multiword Structures in Different Materials, and with Different Goals and Methodologies}},
url = {http://link.springer.com/10.1007/978-94-007-6250-3},
year = {2013}
}
@article{Dunning1993,
abstract = {Much work has been done on the statistical analysis of text. In some cases reported in the literature, inappropriate statistical methods have been used, and statistical significance of results have not been addressed. In particular, asymptotic normality assumptions have often been used unjustifiably, leading to flawed results.This assumption of normal distribution limits the ability to analyze rare events. Unfortunately rare events do make up a large fraction of real text.However, more applicable methods based on likelihood ratio tests are available that yield good results with relatively small samples. These tests can be implemented efficiently, and have been used for the detection of composite terms and for the determination of domain-specific terms. In some cases, these measures perform much better than the methods previously used. In cases where traditional contingency table methods work well, the likelihood ratio tests described here are nearly identical.This paper describes the basis of a measure based on likelihood ratios that can be applied to the analysis of text.},
author = {Dunning, Ted},
doi = {10.1163/15685381-00002885},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dunning/Dunning{\_}1993{\_}Accurate Methods for the Statistics of Surprise and Coincidence.pdf:pdf},
isbn = {0891-2017},
issn = {08912017},
journal = {Journal of Computational Linguistics},
number = {1},
pages = {61--74},
pmid = {2694500},
title = {{Accurate Methods for the Statistics of Surprise and Coincidence}},
url = {http://portal.acm.org/citation.cfm?id=972454},
volume = {19},
year = {1993}
}
@phdthesis{Balakrishna2015,
address = {T{\"{u}}bingen},
author = {Balakrishna, Sowmya},
doi = {10.1145/3132847.3132886},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Balakrishna/Balakrishna{\_}2015{\_}Analyzing Text Complexity and Text Simplification Connecting Linguistics, Processing and Educational Applications.pdf:pdf},
isbn = {9781450349185},
school = {Eberhard Karls Universit{\"{a}}t T{\"{u}}bingen},
title = {{Analyzing Text Complexity and Text Simplification: Connecting Linguistics, Processing and Educational Applications}},
type = {Doctoral Dissertation},
year = {2015}
}
@manual{Grosser2019,
annote = {R package version 0.11.0},
author = {Grosser, Malte},
title = {{snakecase: Convert Strings into any Case}},
url = {https://cran.r-project.org/package=snakecase},
year = {2019}
}
@manual{Michalke2019a,
annote = {(Version 0.12-1)},
author = {Michalke, Meik},
title = {{koRpus: An R Package for Text Analysis}},
url = {https://reaktanz.de/?c=hacking{\&}s=koRpus},
year = {2019}
}
@article{Holst2013,
author = {Holst, Klaus K and Budtz-Joergensen, Esben},
doi = {10.1007/s00180-012-0344-y},
journal = {Computational Statistics},
number = {4},
pages = {1385--1452},
title = {{Linear Latent Variable Models: The lava-package}},
volume = {28},
year = {2013}
}
@article{Rohdenburg1996a,
abstract = {Promptedby John Hawkins' (1990, 1992) research, this paper introduces a complexity principle to accountfor the distribution of competing constructions involving different degrees of explicitness. The principle, which may interact with semantic and stylistic tendencies, states that more explicit grammatical alternatives tend to be preferred in cognitively more complex environments. Such complexity factors include discontinuous constructions of various kinds, passive constructions, and the length of the subjects, objects, and subordinate clauses concerned. While Hawkins' work is confined to (logically equivalent) word-order variants the present paper concentrates on formal contrasts involving the deletion (or addition) and the Substitution of grammatical (or closed-class) elements. The Variation phenomena used to illustrate the complexity principle are drawn both from present-day English and earlier forms of English. {\textcopyright} 1996, Walter de Gruyter. All rights reserved.},
author = {Rohdenburg, G{\"{u}}nter},
doi = {10.1515/cogl.1996.7.2.149},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Rohdenburg/Rohdenburg{\_}1996{\_}Cognitive Complexity and Increased Grammatical Explicitness in English(2).pdf:pdf},
issn = {16133641},
journal = {Cognitive Linguistics},
number = {2},
pages = {149--182},
title = {{Cognitive Complexity and Increased Grammatical Explicitness in English}},
volume = {7},
year = {1996}
}
@incollection{Jacques2018,
author = {Jacques, Marie-Paule and Tutin, Agn{\`{e}}s},
booktitle = {Lexique transversal et formules discursives des sciences humaines},
editor = {Jacques, Marie-Paule and Tutin, Agn{\`{e}}s},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jacques, Tutin/Jacques, Tutin{\_}2018{\_}Les expressions polylexicales transdisciplinaires dans les articles de recherche en sciences humaines retour d'e.pdf:pdf},
isbn = {9781784054854},
pages = {75--89},
title = {{Les expressions polylexicales transdisciplinaires dans les articles de recherche en sciences humaines : retour d'exp{\'{e}}rience}},
year = {2018}
}
@book{Porte2012,
address = {Cambridge},
author = {Porte, Graeme},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Porte/Porte{\_}2012{\_}Replication research in applied linguistics.png:png;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Porte/Porte{\_}2012{\_}Replication research in applied linguistics(2).png:png;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Porte/Porte{\_}2012{\_}Replication research in applied linguistics(2).pdf:pdf},
publisher = {Cambridge University Press},
title = {{Replication research in applied linguistics}},
year = {2012}
}
@manual{Lawrence2016,
annote = {R package version 4.4-0},
author = {Lawrence, Michael A},
title = {{ez: Easy Analysis and Visualization of Factorial Experiments}},
url = {https://cran.r-project.org/package=ez},
year = {2016}
}
@article{Gablasova2017,
abstract = {This article focuses on the use of collocations in language learning research (LLR). Collocations, as units of formulaic language, are becoming prominent in our under- standing of language learning and use; however,while the number of corpus-based LLR studies of collocations is growing, there is still a need for a deeper understanding of factors that play a role in establishing that two words in a corpus can be considered to be collocates. In this article we critically review both the application of measures used to identify collocability between words and the nature of the relationship between two collocates. Particular attention is paid to the comparison of collocability across different corpora representing different genres, registers, or modalities. Several issues involved in the interpretation of collocational patterns in the production of first language and second language users are also considered. Reflecting on the current practices in the field, further directions for collocation research are proposed.},
author = {Gablasova, Dana and Brezina, Vaclav and McEnery, Tony},
doi = {10.1111/lang.12225},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gablasova, Brezina, McEnery/Gablasova, Brezina, McEnery{\_}2017{\_}Collocations in Corpus-Based Language Learning Research Identifying, Comparing, and Interpreting the Ev.pdf:pdf},
isbn = {0031-9422},
issn = {14679922},
journal = {Language Learning},
keywords = {association measures,collocations,corpus linguistics,formulaic language,second language acquisition},
number = {1},
pages = {155--179},
pmid = {25192302},
title = {{Collocations in Corpus-Based Language Learning Research: Identifying, Comparing, and Interpreting the Evidence}},
volume = {67},
year = {2017}
}
@article{Laufer2011a,
abstract = {The present study investigates the use of English verb-noun collocations in the writing of native speakers of Hebrew at three proficiency levels. For this purpose, we compiled a learner corpus that consists of about 300,000 words of argumentative and descriptive essays. For comparison purposes, we selected LOCNESS, a corpus of young adult native speakers of English. We retrieved the 220 most frequently occurring nouns in the LOCNESS corpus and in the learner corpus, created concordances for them, and extracted verb-noun collocations. Subsequently, we performed two types of comparisons: learners were compared with native speakers on the frequency of collocation use and learners were compared with other learners of different second-language proficiencies on the frequency and correctness of collocations. The data revealed that learners at all three proficiency levels produced far fewer collocations than native speakers, that the number of collocations increased only at the advanced level, and that errors, particularly interlingual ones, continued to persist even at advanced levels of proficiency. We discuss the results in light of the nature of collocations and communicative learning and suggest some pedagogical implications. {\textcopyright} 2011 Language Learning Research Club, University of Michigan.},
author = {Laufer, Batia and Waldman, Tina},
doi = {10.1111/j.1467-9922.2010.00621.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Laufer, Waldman/Laufer, Waldman{\_}2011{\_}Verb-noun collocations in second language writing A corpus analysis of learners' English(2).pdf:pdf},
issn = {00238333},
journal = {Language Learning},
keywords = {Collocations,Corpus analysis,Foreign language lexical development,Foreign language writing,Lexis,Multiword units,Verb-noun collocations,Vocabulary},
number = {2},
pages = {647--672},
title = {{Verb-noun collocations in second language writing: A corpus analysis of learners' English}},
volume = {61},
year = {2011}
}
@article{Warton2011,
author = {Warton, David I. and Hui, Francis K. C.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Warton, Hui/Warton, Hui{\_}2011{\_}The arcsine is asinine the analysis of proportions in ecology.pdf:pdf},
journal = {Ecology},
number = {1},
pages = {3--10},
title = {{The arcsine is asinine: the analysis of proportions in ecology}},
volume = {92},
year = {2011}
}
@manual{Csardi2019,
annote = {R package version 1.1.0},
author = {Cs{\'{a}}rdi, G{\'{a}}bor},
title = {{cli: Helpers for Developing Command Line Interfaces}},
url = {https://cran.r-project.org/package=cli},
year = {2019}
}
@article{Bardel2011,
abstract = {This study is a follow-up to Lindqvist et al. (to press), where we investigated lexical frequency profiles of learners of French and Italian at different proficiency levels. By analyzing the proportion of low-frequency words used by the learners, we could distinguish proficiency levels that differ significantly at group level and correspond to morphosyntactic proficiency levels. However, some individual results within the groups indicated a need to analyze individual profiles in order to get a better picture of the actual quality of the learner's vocabulary knowledge. The present study focuses on thematic vocabulary and cognates among the low-frequency words used by learners at different proficiency levels. We suggest that investigating qualitative aspects of learners' word knowledge is a fruitful complement to traditional lexical profiling analysis. Such a combination can lead to a more complete picture of learners' lexical profiles. Although we are aware that word frequency is known to be a powerful factor in vocabulary acquisition, our on-going research aims at developing a more general lexical profiler that integrates additional aspects that we have found to be relevant for learnability.},
author = {Bardel, Camilla and Lindqvist, Christina},
doi = {10.1075/eurosla.11.06bar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bardel, Lindqvist/Bardel, Lindqvist{\_}2011{\_}Developing a lexical profiler for spoken French L2 and Italian L2 The role of frequency, thematic vocabulary and.pdf:pdf},
issn = {1568-1491},
journal = {EUROSLA Yearbook},
pages = {75--93},
title = {{Developing a lexical profiler for spoken French L2 and Italian L2: The role of frequency, thematic vocabulary and cognates}},
volume = {11},
year = {2011}
}
@manual{Wickham2020,
annote = {R package version 0.3.1},
author = {Wickham, Hadley and Henry, Lionel and Vaughan, Davis},
title = {{vctrs: Vector Helpers}},
url = {https://cran.r-project.org/package=vctrs},
year = {2020}
}
@book{Xie2016,
address = {Boca Raton, Florida},
annote = {ISBN 978-1138700109},
author = {Xie, Yihui},
publisher = {Chapman and Hall/CRC},
title = {{bookdown: Authoring Books and Technical Documents with {\{}R{\}} Markdown}},
url = {https://github.com/rstudio/bookdown},
year = {2016}
}
@article{Coxhead2000,
abstract = {This article describes the development and evaluation of a new academic word list (Coxhead, 1998), which was compiled from a corpus of 3.5 million running words of written academic text by examining the range and frequency of words outside the first 2,000 most frequently occurring words of English, as described by West (1953). The AWL contains 570 word families that account for approximately 10.0{\%} of the total words (tokens) in academic texts but only 1.4{\%} of the total words in a fiction collection of the same size. This difference in coverage provides evidence that the list contains predominantly academic words. By highlighting the words that university students meet in a wide range of academic texts, the AWL shows learners with academic goals which words are most worth studying. The list also provides a useful basis for further research into the nature of academic vocabulary.},
author = {Coxhead, Averil},
doi = {10.2307/3587951},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Coxhead/Coxhead{\_}2000{\_}A new academic word list.pdf:pdf},
issn = {00398322},
journal = {TESOL Quarterly},
number = {2},
pages = {213--238},
title = {{A new academic word list}},
volume = {34},
year = {2000}
}
@manual{Widgren2018,
annote = {R package version 0.21.0},
author = {Widgren, Stefan and Others},
title = {{{\{}git2r{\}}: Provides Access to Git Repositories}},
url = {https://cran.r-project.org/package=git2r},
year = {2018}
}
@article{Zeileis2003,
author = {Zeileis, Achim and Kleiber, Christian and Kr{\"{a}}mer, Walter and Hornik, Kurt},
journal = {Computational Statistics {\&} Data Analysis},
pages = {109--123},
title = {{Testing and Dating of Structural Changes in Practice}},
volume = {44},
year = {2003}
}
@manual{Gaslam2018,
annote = {R package version 0.4.0},
author = {Gaslam, Brodie},
title = {{fansi: ANSI Control Sequence Aware String Functions}},
url = {https://cran.r-project.org/package=fansi},
year = {2018}
}
@article{Crossley2013a,
abstract = {In assessments of second language (L2) writing, quality of lexis typically claims more variance than other factors, and the most readily operationalized measure of lexical quality is word frequency. This study compares two methods of automatically assessing word frequency in learner productions. The first method, a band-based method, involves lexical frequency profiling, a procedure that first groups individual words into families and then sorts these into corpus-based frequency bands. The second method, a count-based method, assigns a normalized corpus frequency count to each individual word form used, yielding an average count for a text. Both band and count-based methods were used to analyze 100 L2 learner and 30 native speaker freewrites that had been classified according to proficiency level (i.e., native speakers and beginning, intermediate and advanced L2 learners). Machine learning algorithms were used to classify the texts into their respective proficiency levels with results indicating that count-based word frequency indices accurately classified 58{\%} of the texts while band-based indices reported accuracies that were between 10{\%} and 22{\%} lower than count-based indices. {\textcopyright} 2013.},
author = {Crossley, Scott A. and Cobb, Tom and McNamara, Danielle S.},
doi = {10.1016/j.system.2013.08.002},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley, Cobb, McNamara/Crossley, Cobb, McNamara{\_}2013{\_}Comparing count-based and band-based indices of word frequency Implications for active vocabulary research.pdf:pdf},
issn = {0346251X},
journal = {System},
keywords = {Active and passive lexical proficiency,Band-based frequency measures,Computational linguistics,Count-based frequency measures,Frequency analysis,Frequency lists,Learner corpora,Lexical sophistication},
number = {4},
pages = {965--981},
publisher = {Elsevier Ltd},
title = {{Comparing count-based and band-based indices of word frequency: Implications for active vocabulary research and pedagogical applications}},
url = {http://dx.doi.org/10.1016/j.system.2013.08.002},
volume = {41},
year = {2013}
}
@inproceedings{Bartning2005,
author = {Bartning, Inge and Forsberg, Fanny},
booktitle = {Actes du XVI{\`{e}}me Congr{\`{e}}s des romanistes scandinaves},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Forsberg/Bartning, Forsberg{\_}2005{\_}Les s{\'{e}}quences pr{\'{e}}fabriqu{\'{e}}es {\`{a}} travers les stades de d{\'{e}}veloppement en fran{\c{c}}ais L2.pdf:pdf},
pages = {1--22},
title = {{Les s{\'{e}}quences pr{\'{e}}fabriqu{\'{e}}es {\`{a}} travers les stades de d{\'{e}}veloppement en fran{\c{c}}ais L2}},
year = {2005}
}
@article{Wickham2011,
author = {Wickham, Hadley},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--29},
title = {{The Split-Apply-Combine Strategy for Data Analysis}},
url = {http://www.jstatsoft.org/v40/i01/},
volume = {40},
year = {2011}
}
@manual{Chan2018,
annote = {R package version 0.5.16},
author = {Chan, Chung-hong and Chan, Geoffrey C H and Leeper, Thomas J and Becker, Jason},
title = {{rio: A Swiss-army knife for data file I/O}},
year = {2018}
}
@manual{Lincoln2019,
annote = {R package version 0.7.0},
author = {Lincoln, Matthew},
title = {{clipr: Read and Write from the System Clipboard}},
url = {https://cran.r-project.org/package=clipr},
year = {2019}
}
@manual{Xie2019,
annote = {R package version 1.7},
author = {Xie, Yihui},
title = {{formatR: Format R Code Automatically}},
url = {https://cran.r-project.org/package=formatR},
year = {2019}
}
@article{Johnson,
author = {Johnson, Steven G},
journal = {?},
number = {?},
pages = {?},
title = {{The NLopt nonlinear-optimization package}},
volume = {?}
}
@manual{Dahl2019,
annote = {R package version 1.8-4},
author = {Dahl, David B and Scott, David and Roosen, Charles and Magnusson, Arni and Swinton, Jonathan},
title = {{xtable: Export Tables to LaTeX or HTML}},
url = {https://cran.r-project.org/package=xtable},
year = {2019}
}
@book{CouncilofEurope2018,
author = {{Council of Europe}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Council of Europe/Council of Europe{\_}2018{\_}Common European Framework of Reference for Languages Learning, Teaching, Assessment.pdf:pdf},
title = {{Common European Framework of Reference for Languages: Learning, Teaching, Assessment}},
year = {2018}
}
@article{Crossley2015,
abstract = {This study analyzes lexical proficiency in oral and written texts produced by second language (L2) learners of English. The purpose of the study is to examine relationships between analytic scores of depth of lexical knowledge, breadth of lexical knowledge, and access to core lexical items and holistic scores of lexical proficiency. A corpus of 240 spoken texts and 240 written texts produced by beginning L2 learners, intermediate L2 learners, advanced L2 learners, and native speakers were scored for both analytic and holistic features of lexical proficiency by trained raters. Using a multiple regression analysis, the study found that collocation accuracy, lexical diversity, and word frequency are significant predictors of human evaluations of lexical proficiency. Collocation accuracy explained the greatest amount of variance in the holistic scores (84{\%} in the written samples and 89{\%} in the spoken samples). The authors discuss the importance of collocation accuracy in predicting human judgments of lexical proficiency.},
author = {Crossley, Scott A. and Salsbury, Tom and McNamara, Danielle S.},
doi = {10.1093/applin/amt056},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley, Salsbury, McNamara/Crossley, Salsbury, McNamara{\_}2015{\_}Assessing Lexical Proficiency Using Analytic Ratings A Case for Collocation Accuracy.pdf:pdf},
issn = {1477450X},
journal = {Applied Linguistics},
number = {5},
pages = {570--590},
title = {{Assessing Lexical Proficiency Using Analytic Ratings: A Case for Collocation Accuracy}},
volume = {36},
year = {2015}
}
@book{Eddelbuettel2013,
address = {New York},
annote = {ISBN 978-1-4614-6867-7},
author = {Eddelbuettel, Dirk},
doi = {10.1007/978-1-4614-6868-4},
publisher = {Springer},
title = {{Seamless {\{}R{\}} and {\{}C++{\}} Integration with {\{}Rcpp{\}}}},
year = {2013}
}
@article{Bartning2015,
abstract = {This article examines linguistic complexity in the noun phrase in spoken L1 and L2 French. Research on linguistic complexity in L2 has often concentrated on syntactic complexity, subordination in particular. In this study, we focus on syntactic complexity at the phrasal level, i.e. in the noun phrase, following the assumption put forward by Norris and Ortega (2009: 564) that internal NP complexity provides an important measure of very advanced learners. The present study examines pre- and post-modification in the noun phrase in the oral production of very advanced non-native speakers (NNS) and native speakers (NS) elicited through an on-line retelling of a clip from Modern Times. The results confirm our main hypothesis, that there are differences between NS and NNS: NS use more complex NPs, NPs with a higher mean number of words and more NPs with multiple modifiers.},
author = {Bartning, Inge and Arvidsson, Klara and {Forsberg Lundell}, Fanny},
doi = {10.1075/lia.6.2.01bar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Arvidsson, Forsberg Lundell/Bartning, Arvidsson, Forsberg Lundell{\_}2015{\_}Complexity at the phrasal level in spoken L1 and very advanced L2 French(2).pdf:pdf},
issn = {1879-7865},
journal = {Language, Interaction and Acquisition},
keywords = {advanced l2 french,high level proficiency,linguistic,noun phrase,on-line spoken production,syntactic complexity},
number = {2},
pages = {181--201},
title = {{Complexity at the phrasal level in spoken L1 and very advanced L2 French}},
volume = {6},
year = {2015}
}
@article{Kuznetsova2017,
author = {Kuznetsova, Alexandra and Brockhoff, Per B and Christensen, Rune H B},
doi = {10.18637/jss.v082.i13},
journal = {Journal of Statistical Software},
number = {13},
pages = {1--26},
title = {{{\{}lmerTest{\}} Package: Tests in Linear Mixed Effects Models}},
volume = {82},
year = {2017}
}
@article{Gadet1996,
author = {Gadet, Fran{\c{c}}oise},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gadet/Gadet{\_}1996{\_}Une distinction bien fragile oral {\'{e}}crit.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gadet/Gadet{\_}1996{\_}Une distinction bien fragile oral {\'{e}}crit(2).pdf:pdf},
journal = {Revue Tranel},
pages = {13--27},
title = {{Une distinction bien fragile: oral / {\'{e}}crit}},
volume = {25},
year = {1996}
}
@article{Arvidsson2019,
author = {Arvidsson, Klara},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Arvidsson/Arvidsson{\_}2019{\_}Quantity of target language contact in study abroad and knowledge of multiword expressions A Usage-Based approach to L2 d.pdf:pdf},
journal = {Study Abroad Research in Second Language Acquisition and International Education},
keywords = {expressions,l2 french,multiword,target language contact,usage-based approach},
number = {2},
pages = {145--167},
title = {{Quantity of target language contact in study abroad and knowledge of multiword expressions A Usage-Based approach to L2 development}},
volume = {4},
year = {2019}
}
@techreport{Abeille2003,
author = {Abeill{\'{e}}, Anne and Cl{\'{e}}ment, Lionel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Abeill{\'{e}}, Cl{\'{e}}ment/Abeill{\'{e}}, Cl{\'{e}}ment{\_}2003{\_}Annotation morpho-syntaxique.pdf:pdf},
institution = {Universit{\'{e}} Paris 7},
title = {{Annotation morpho-syntaxique}},
url = {http://www.llf.cnrs.fr/sites/sandbox.linguist.univ-paris-diderot.fr/files/statiques/french{\_}treebank/guide-morpho-synt.02.pdf},
year = {2003}
}
@article{Housen2009a,
author = {Housen, Alex and Kuiken, Folkert},
doi = {10.1093/applin/amp048},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Housen, Kuiken/Housen, Kuiken{\_}2009{\_}Complexity, accuracy, and fluency in second language acquisition(2).pdf:pdf},
issn = {01426001},
journal = {Applied Linguistics},
number = {4},
pages = {461--473},
title = {{Complexity, accuracy, and fluency in second language acquisition}},
volume = {30},
year = {2009}
}
@incollection{Brezina2018,
address = {Cambridge},
author = {Brezina, Vaclav},
booktitle = {Statistics in Corpus Linguistics},
editor = {V{\'{e}}ronique, Daniel},
pages = {66--101},
publisher = {Cambridge University Press},
title = {{Semantic and Discourse: Collocations, Keywords and Reliability of Manual Coding}},
year = {2018}
}
@manual{Michalke2018,
annote = {(Version 0.1-1)},
author = {Michalke, Meik},
title = {{koRpus.lang.fr: Language Support for 'koRpus' Package: French}},
url = {https://reaktanz.de/?c=hacking{\&}s=koRpus},
year = {2018}
}
@incollection{Agren2012,
abstract = {This chapter addresses the question of the growth of accuracy and complexity in L2 French from the perspective of developmental sequences of morphosyntax, developmental stages and linguistic profiling. The six developmental stages for L2 French proposed by Bartning and Schlyter (2004) are presented and exemplified and new results are added to the already detailed description of the development of the grammatical system in L2 French of Swedish learners. In addition, we present some recent applications of the model of Bartning and Schlyter, published after 2004. This model has proved to be a useful tool of assessment of language proficiency in L2 French and, consequently, the stages of morphosyntactic development have been used as independent measures in a number of studies that are briefly summarised in this chapter. 1 . I n t r o d u c t i o n In this chapter, we will focus on the growth of complexity and accuracy in L2 French from the perspective of developmental sequences of morphosyntax, devel opmental stages and linguistic profiling. We examine the systematic growth of morphosyntactic features expressed by the learner during the acquisition process (sequences). Furthermore, we investigate the relatedness of different developmen tal phenomena over time (stages). The developmental sequence studies focus on the acquisition orders of specific morphosyntactic features, such as tense mor phology, subject-verb agreement, negation, etc. They complement the develop mental index studies which consider the development of learners in more general terms through the use of fluency, accuracy and complexity measures (ratios) that 96 Malin Agren, Jonas Granfeldt {\&} Suzanne Schlyter are not necessarily tied to particular structures (words/T-unit, errors/T-unit, etc). Initially, the goal of the developmental index studies was to find an "objec tive" measure of L2 development (like MLU in LI acquisition). The index should correspond to "a developmental yardstick against which global (i.e. neither skill nor item specific) second language proficiency could be gauged" (Larsen-Freeman 1983:287). In contrast, developmental sequence studies entail detailed empirical analysis of the growing interlanguage and highlight of particular structures and patterns used (or omitted) by the learner at different points in time. Importantly, we are interested in the overall morphosyntactic system of learners at a given point in time, a system that we call developmental stage. The definition of a develop mental stage thus obviously includes the dimensions of variety (complexity) and correctness (accuracy) of different morphosyntactic structures as well as detailed i n f o r m a t i o n a b o u t t h e n a t u r e o f l e a r n e r s ' e r r o r s a n d o m i s s i o n s . Henceforth, we will use the notion of morphosyntactic complexity when referring to the growing ability of the L2 learner to use a wide and varied range of grammatical structures in the target language. Morphosyntactic accuracy will refer to an increasing target-likeness in the use of different morphosyntactic struc tures in L2 French (i.e. correct production in obligatory contexts). The outline of the present chapter is as follows. First, in Section 2, we give a short historical overview of research on developmental sequences and develop mental stages in L2 French with respect to morphosyntax. This idea will be exem plified by the systematic and gradual development of the L2 French produced},
address = {Amsterdam},
author = {{\AA}gren, Malin and Granfeldt, Jonas and Schlyter, Suzanne},
booktitle = {Dimensions of L2 performance and proficiency: Complexity, accuracy and fluency in SLA},
editor = {Housen, Alex and Kuiken, Folkert and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/{\AA}gren, Granfeldt, Schlyter/{\AA}gren, Granfeldt, Schlyter{\_}2012{\_}The growth of complexity and accuracy in L2 French Past observations and recent applications of develop.pdf:pdf},
pages = {95--120},
publisher = {John Benjamins},
title = {{The growth of complexity and accuracy in L2 French: Past observations and recent applications of developmental stages}},
year = {2012}
}
@manual{Warnes2017a,
annote = {R package version 2.18.0},
author = {Warnes, Gregory R and Bolker, Ben and Gorjanc, Gregor and Grothendieck, Gabor and Korosec, Ales and Lumley, Thomas and MacQueen, Don and Magnusson, Arni and Rogers, Jim and Others},
title = {{gdata: Various R Programming Tools for Data Manipulation}},
url = {https://cran.r-project.org/package=gdata},
year = {2017}
}
@techreport{Potter2012,
address = {Auckland, New Zealand},
author = {Potter, Simon},
institution = {The University of Auckland},
title = {{Introducing the selectr Package}},
url = {http://stattech.wordpress.fos.auckland.ac.nz/2012-10-introducing-the-selectr-package/},
year = {2012}
}
@incollection{Manchon2014,
address = {Amsterdam},
author = {Manch{\'{o}}n, Rosa M},
booktitle = {Task-based language learning: Insights from and for L2 writing},
editor = {Byrnes, Heidi and Manch{\'{o}}n, Rosa M.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Manch{\'{o}}n/Manch{\'{o}}n{\_}2014{\_}The internal dimension of tasks The interaction between task factors and learner factors in bringing about learning throug.pdf:pdf},
pages = {27--52},
publisher = {John Benjamins},
title = {{The internal dimension of tasks: The interaction between task factors and learner factors in bringing about learning through writing}},
year = {2014}
}
@article{Lindqvist2010,
abstract = {The goal of this study is to compare the lexical richness of the oral production of Swedish learners of French as a second language using the Lexical Frequency Profile method and the Vocabprofile program, elaborated by Laufer and Nation (1995) for written English. The French version of Vocabprofile is designed for written language; however, the study used oral data. The analysis focuses mainly on the use of infrequent words, which is supposed to indicate an advanced vocabulary. The comparison of two groups of advanced Swedish learners of French with a group of native speakers of French shows that the proportion of infrequent words increases with proficiency level. Moreover, the most advanced group has a lexical profile similar to that of the native speakers. However, using a database of written language to analyze spoken language does not seem entirely reliable, because of differences in frequency of certain words in oral and written language. {\textcopyright} 2010 The Canadian Modern Language Review.},
author = {Lindqvist, Christina},
doi = {10.3138/cmlr.66.3.393},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lindqvist/Lindqvist{\_}2010{\_}La richesse lexicale dans la production orale de l'apprenant avanc{\'{e}} de fran{\c{c}}ais.pdf:pdf},
issn = {17101131},
journal = {Canadian Modern Language Review},
keywords = {Advanced learner,Frequency,Lexical richness,Spoken French},
number = {3},
pages = {393--420},
title = {{La richesse lexicale dans la production orale de l'apprenant avanc{\'{e}} de fran{\c{c}}ais}},
volume = {66},
year = {2010}
}
@manual{Muller2018,
annote = {R package version 0.2.0},
author = {M{\"{u}}ller, Kirill},
title = {{plogr: The 'plog' C++ Logging Library}},
url = {https://cran.r-project.org/package=plogr},
year = {2018}
}
@book{Ladyman2013,
abstract = {Complex systems research is becoming ever more important in both the natural and social sciences. It is commonly implied that there is such a thing as a complex system, different examples of which are studied across many disciplines. However, there is no concise definition of a complex system, let alone a definition on which all scientists agree. We review various attempts to characterize a complex system, and consider a core set of features that are widely associated with complex systems in the literature and by those in the field. We argue that some of these features are neither necessary nor sufficient for complexity, and that some of them are too vague or confused to be of any analytical use. In order to bring mathematical rigour to the issue we then review some standard measures of complexity from the scientific literature, and offer a taxonomy for them, before arguing that the one that best captures the qualitative notion of the order produced by complex systems is that of the Statistical Complexity. Finally, we offer our own list of necessary conditions as a characterization of complexity. These conditions are qualitative and may not be jointly sufficient for complexity. We close with some suggestions for future work. {\textcopyright} 2012 Springer Science + Business Media B.V.},
author = {Ladyman, James and Lambert, James and Wiesner, Karoline},
booktitle = {European Journal for Philosophy of Science},
doi = {10.1007/s13194-012-0056-8},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ladyman, Lambert, Wiesner/Ladyman, Lambert, Wiesner{\_}2013{\_}What is a complex system.pdf:pdf},
isbn = {1319401200568},
issn = {18794912},
keywords = {Complex system,Complexity,Information,Statistical complexity},
number = {1},
pages = {33--67},
title = {{What is a complex system?}},
volume = {3},
year = {2013}
}
@book{Halliday2006,
address = {London},
author = {Halliday, Michael A.K. and Matthiessen, Christian M.I.M.},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
publisher = {Continuum},
title = {{Construing Experience Through Meaning}},
year = {2006}
}
@manual{Jockers2015,
author = {Jockers, Matthew L},
title = {{Syuzhet: Extract Sentiment and Plot Arcs from Text}},
url = {https://github.com/mjockers/syuzhet},
year = {2015}
}
@article{Bramley2019,
abstract = {ABSTRACT Comparative Judgement (CJ) is an increasingly widely investigated method in assessment for creating a scale, for example of the quality of essays. One area that has attracted attention in CJ studies is the optimisation of the selection of pairs of objects for judgement. One approach is known as adaptive comparative judgement (ACJ). It has been claimed in the literature that ACJ produces very high reliability, often higher than can be obtained by conventional marking. Bramley showed by simulation that adaptivity can substantially inflate the apparent reliability in ACJ. The empirical study described here compared an adaptive with a non-adaptive CJ study using GCSE English essays. An all-play-all set of comparisons of a subset of the essays allowed the extent of scale inflation to be quantified: the reported adaptive reliability was 0.97 whereas the deflated value was 0.84. The value from the non-adaptive study was 0.72. However, the scale from the non-adaptive study correlated slightly higher with external variables, suggesting the non-adaptive study was no less valid than the adaptive one.},
author = {Bramley, Tom and Vitello, Sylvia},
doi = {10.1080/0969594X.2017.1418734},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bramley, Vitello/Bramley, Vitello{\_}2019{\_}The effect of adaptivity on the reliability coefficient in adaptive comparative judgement.pdf:pdf},
issn = {1465329X},
journal = {Assessment in Education: Principles, Policy and Practice},
keywords = {Comparative judgement,adaptive,marking,reliability,validity},
number = {1},
pages = {43--58},
title = {{The effect of adaptivity on the reliability coefficient in adaptive comparative judgement}},
volume = {26},
year = {2019}
}
@article{VanderLoo2014,
author = {van der Loo, M P J},
journal = {The {\{}R{\}} {\{}J{\}}ournal},
number = {1},
pages = {111--122},
title = {{The stringdist package for approximate string matching}},
url = {https://cran.r-project.org/package=stringdist},
volume = {6},
year = {2014}
}
@article{Wickham2007,
author = {Wickham, Hadley},
journal = {Journal of Statistical Software},
number = {12},
pages = {1--20},
title = {{Reshaping Data with the {\{}reshape{\}} Package}},
url = {http://www.jstatsoft.org/v21/i12/},
volume = {21},
year = {2007}
}
@inproceedings{Jarvis2015,
address = {Aix-en-Provence},
author = {Jarvis, Scott},
booktitle = {EuroSLA},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2015{\_}Lexical Diversity.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2015{\_}Lexical Diversity(2).pdf:pdf},
keywords = {complexity,diversity},
mendeley-tags = {complexity,diversity},
title = {{Lexical Diversity}},
year = {2015}
}
@article{Qin2020,
abstract = {The present study examines adolescent and adult English-as-Foreign-Language (EFL) Learners' linguistic complexity and register flexibility in writing across academic and colloquial contexts. A total of 263 EFL learners from three first language (L1) backgrounds (Chinese, French, and Spanish) participated in this study. Each participant produced two written texts on the same topic: a personal email to a close friend and an academic report to an educational authority. A total of 526 texts were analyzed for lexical, syntactic, and discourse organizational features. Multilevel modeling results revealed positive associations between participants' English proficiency and their textual linguistic complexity. In contrast, the association between English proficiency and register flexibility was not consistent across the different linguistic levels analyzed and across the three L1 groups. Findings inform the design of pedagogical practices that anticipate the unique communicative challenges faced by EFL learners and teach communicative functions of complex linguistic forms.},
author = {Qin, Wenjuan and Uccelli, Paola},
doi = {10.1016/j.asw.2020.100465},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Qin, Uccelli/Qin, Uccelli{\_}2020{\_}Beyond linguistic complexity Assessing register flexibility in EFL writing across contexts.pdf:pdf},
issn = {10752935},
journal = {Assessing Writing},
keywords = {Cross-linguistic influence,English as a foreign language (EFL),Linguistic complexity,Register flexibility,Writing assessment},
number = {April},
pages = {100465},
publisher = {Elsevier},
title = {{Beyond linguistic complexity: Assessing register flexibility in EFL writing across contexts}},
url = {https://doi.org/10.1016/j.asw.2020.100465},
volume = {45},
year = {2020}
}
@article{Labbe2007,
author = {Labb{\'{e}}, Dominique},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Labb{\'{e}}/Labb{\'{e}}{\_}2007{\_}Coordination et subordination en fran{\c{c}}ais oral.pdf:pdf},
journal = {Les Nouvelles Journ{\'{e}}es de l'ERLA},
pages = {161--182},
title = {{Coordination et subordination en fran{\c{c}}ais oral}},
volume = {4},
year = {2007}
}
@article{Zeileis2002,
author = {Zeileis, Achim and Leisch, Friedrich and Hornik, Kurt and Kleiber, Christian},
journal = {Journal of Statistical Software},
number = {2},
pages = {1--38},
title = {{strucchange: An R Package for Testing for Structural Change in Linear Regression Models}},
url = {http://www.jstatsoft.org/v07/i02/},
volume = {7},
year = {2002}
}
@article{Laufer1995,
abstract = {This article shows that if there is some control over genre then there will be a close correspondence between the vocabulary size of intermediate learners as reflected in their writing and a more direct measure of vocabulary size The study proposes a new measure of lexical richness, the Lexical Frequency Profile, which looks at the proportion of high frequency general service and academic words in learners' writing The study shows that it is possible to obtain a reliable measure of lexical richness which is stable across two pieces of writing by the same learners It also discriminates between learners of different proficiency levels For learners of English as a second language, the Lexical Frequency Profile is seen as being a measure of how vocabulary size is reflected in use In this study, it was found that the Lexical Frequency Profile correlates well with an independent measure of vocabulary size This reliable and valid measure of lexical richness in writing will be useful for determining the factors that affect judgements of quality in writing and will be useful for examining how vocabulary growth is related to vocabulary use. {\textcopyright} 1995 Oxford University Press.},
author = {Laufer, Batia and Nation, Paul},
doi = {10.1093/applin/16.3.307},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Laufer, Nation/Laufer, Nation{\_}1995{\_}Vocabulary size and use Lexical richness in L2 written production(2).pdf:pdf},
issn = {01426001},
journal = {Applied Linguistics},
number = {3},
pages = {307--322},
title = {{Vocabulary size and use: Lexical richness in L2 written production}},
volume = {16},
year = {1995}
}
@phdthesis{Tran2014,
abstract = {Cette th{\`{e}}se propose une nouvelle approche des {\'{e}}crits scientifiques en prenant comme point de d{\'{e}}part les marqueurs discursifs (MD). Elle s'inscrit dans le cadre du Fran{\c{c}}ais sur Objectif Universitaire (FOU). Dans ce travail, nous nous int{\'{e}}ressons tout particuli{\`{e}}rement aux MD polylexicaux et les int{\'{e}}grons dans une conception large de la phras{\'{e}}ologie. La particularit{\'{e}} de cette recherche r{\'{e}}side dans le fait de relier les descriptions linguistiques des MD et la transposition didactique de ces unit{\'{e}}s lexicales {\`{a}} l'aide de corpus, ce qui est encore peu abord{\'{e}} dans le champ de la didactique francophone. Nous cherchons {\`{a}} r{\'{e}}pondre {\`{a}} des objectifs {\`{a}} la fois linguistiques et didactiques. Pour les objectifs linguistiques, nous mettons en place un mod{\`{e}}le d'analyse des MD polylexicaux associant les propri{\'{e}}t{\'{e}}s syntaxiques et s{\'{e}}mantiques et qui est tout {\`{a}} fait r{\'{e}}adaptable {\`{a}} d'autres MD. Les analyses linguistiques des MD serviront par la suite {\`{a}} l'enseignement/apprentissage de ces unit{\'{e}}s. Pour les objectifs didactiques, cette recherche vise {\`{a}} concevoir une m{\'{e}}thodologie d'enseignement/apprentissage des MD {\`{a}} partir de l'observation de corpus. Les consid{\'{e}}rations m{\'{e}}thodologiques propos{\'{e}}es dans le cadre de cette th{\`{e}}se ouvrent des pistes int{\'{e}}ressantes pour l'enseignement/apprentissage de ces {\'{e}}l{\'{e}}ments linguistiques ainsi que pour faciliter l'acc{\`{e}}s aux {\'{e}}crits scientifiques aupr{\`{e}}s des {\'{e}}tudiants non-natifs.},
annote = {L1 corpus of scientific writings},
author = {Tran, Hoai Thi Thu},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Tran/Tran{\_}2014{\_}Description de la phras{\'{e}}ologie transdisciplinaire des {\'{e}}crits scientifiques et r{\'{e}}flexions didactiques pour l ' enseignem.pdf:pdf},
keywords = {Phras{\'{e}}ologie transdisciplinaire scientifique,enseignement,fra{\c{c}}ais sur objectif universitaire,marqueurs discursifs,mod{\'{e}}lisation,{\'{E}}crits scientifiques},
school = {Universit{\'{e}} de Grenoble},
title = {{Description de la phras{\'{e}}ologie transdisciplinaire des {\'{e}}crits scientifiques et r{\'{e}}flexions didactiques pour l ' enseignement {\`{a}} des {\'{e}}tudiants non-natifs : Application aux marqueurs discursifs}},
type = {PhD Dissertation},
url = {https://tel.archives-ouvertes.fr/tel-01330952},
year = {2014}
}
@book{West1953,
address = {London},
author = {West, Michael},
publisher = {Longman},
title = {{A General Service List of English Words}},
year = {1953}
}
@manual{Wickham2019o,
annote = {R package version 1.2.2},
author = {Wickham, Hadley and Hester, Jim and Ooms, Jeroen},
title = {{xml2: Parse XML}},
url = {https://cran.r-project.org/package=xml2},
year = {2019}
}
@manual{RStudio2017,
annote = {R package version 0.3.6},
author = {RStudio and Inc.},
title = {{htmltools: Tools for HTML}},
url = {https://cran.r-project.org/package=htmltools},
year = {2017}
}
@article{Suchomel2012,
abstract = {Many researchers use texts from the web, an easy source of linguistic data in a great variety of languages. Building both large and good quality text corpora is the challenge we face nowadays. In this paper we describe how to deal with inefficient data downloading and how to focus crawling on text rich web domains. The idea has been successfully implemented in SpiderLing. We present efficiency figures from crawling texts in American Spanish, Czech, Japanese, Russian, Tajik Persian, Turkish and the sizes of the resulting corpora.},
author = {Suchomel, V{\'{i}}t and Pomik{\'{a}}lek, Jan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Suchomel, Pomik{\'{a}}lek/Suchomel, Pomik{\'{a}}lek{\_}2012{\_}Efficient Web Crawling for large Text Corpora.pdf:pdf},
journal = {Proceedings of the Seventh Web as Corpus Workshop},
keywords = {corpus,crawler,text corpus,web corpus,web crawling},
pages = {1--5},
title = {{Efficient Web Crawling for large Text Corpora}},
year = {2012}
}
@article{Nilsson1960,
abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
author = {Hallgren, Kevin A.},
doi = {10.1080/11035896009449194},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hallgren/Hallgren{\_}2012{\_}Computing Inter-Rater Reliability for Observational Data An Overview and Tutorial Kevin.pdf:pdf},
issn = {20000863},
journal = {Tutor Quant Methods Psychology},
keywords = {behavioral observation,coding,inter-rater agreement,intra-class correlation,kappa,reliability},
number = {1},
pages = {23--34},
title = {{Computing Inter-Rater Reliability for Observational Data: An Overview and Tutorial Kevin}},
volume = {8},
year = {2012}
}
@manual{Carr2019,
annote = {R package version 1.27.3},
author = {Carr, Dan and {ported by Nicholas Lewin-Koh} and Maechler, Martin and {contains copies of lattice functions written by Deepayan Sarkar}},
title = {{hexbin: Hexagonal Binning Routines}},
url = {https://cran.r-project.org/package=hexbin},
year = {2019}
}
@manual{Wickham2019,
annote = {R package version 2.1.0},
author = {Wickham, Hadley and Hester, Jim and Chang, Winston},
title = {{devtools: Tools to Make Developing R Packages Easier}},
url = {https://cran.r-project.org/package=devtools},
year = {2019}
}
@manual{Urbanek2015,
annote = {R package version 0.1-3},
author = {Urbanek, Simon},
title = {{base64enc: Tools for base64 encoding}},
url = {https://cran.r-project.org/package=base64enc},
year = {2015}
}
@manual{Wickham2019m,
annote = {R package version 1.5.1},
author = {Wickham, Hadley and Bryan, Jennifer},
title = {{usethis: Automate Package and Project Setup}},
url = {https://cran.r-project.org/package=usethis},
year = {2019}
}
@manual{Meyer2017,
annote = {R package version 1.4-4},
author = {Meyer, David and Zeileis, Achim and Hornik, Kurt},
title = {{vcd: Visualizing Categorical Data}},
year = {2017}
}
@article{Eddelbuettel2017,
author = {Eddelbuettel, Dirk and Balamuta, James Joseph},
doi = {10.7287/peerj.preprints.3188v1},
issn = {2167-9843},
journal = {PeerJ Preprints},
month = {aug},
pages = {e3188v1},
title = {{Extending extit{\{}R{\}} with extit{\{}C++{\}}: A Brief Introduction to extit{\{}Rcpp{\}}}},
url = {https://doi.org/10.7287/peerj.preprints.3188v1},
volume = {5},
year = {2017}
}
@incollection{Granger2008,
abstract = {Long regarded as a peripheral issue, phraseology is now taking centre stage in a wide range of fields. This recent explosion of interest undoubtedly has a great deal to do with the development of corpus linguistics research, which has both demonstrated the key role of phraseological expressions in language and provided researchers with automated methods of extraction and analysis. The aim of this volume is to take stock of current research in phraseology from a variety of perspectives: theoretical, descriptive, contrastive, cultural, lexicographic and computational. It contains overview chapters by leading experts in the field and a series of case studies focusing on a wide range of multiword units: collocations, similes, idioms, routine formulae and recurrent phrases. The volume is an invitation for experienced phraseologists to look at the field with different eyes and a useful introduction for the many researchers who are intrigued by phraseology but need help in finding their way in this rich but complex domain.},
address = {Amsterdam},
author = {Granger, Sylviane and Paquot, Magali},
booktitle = {Phraseology: An interdisciplinary perspective},
editor = {Granger, Sylviane and Meunier, Fanny},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Paquot/Granger, Paquot{\_}2008{\_}Disentangling the phraseological web.pdf:pdf},
isbn = {9027290113},
pages = {27--50},
publisher = {John Benjamins},
title = {{Disentangling the phraseological web}},
year = {2008}
}
@inproceedings{Romary2004,
address = {Geneva},
author = {Romary, L and Salmon-Alt, S and Francopoulo, G},
booktitle = {Workshop on Electronic Dictionaries (Coling)},
keywords = {morpholou},
mendeley-tags = {morpholou},
title = {{Standards going concrete : from LMF to Morphalou.}},
url = {https://hdl.handle.net/11403/morphalou/v3.1},
year = {2004}
}
@manual{Csardi2018,
annote = {R package version 2.0.2},
author = {Cs{\'{a}}rdi, G{\'{a}}bor},
title = {{pkgconfig: Private Configuration for 'R' Packages}},
url = {https://cran.r-project.org/package=pkgconfig},
year = {2018}
}
@manual{Barbera2018,
annote = {R package version 0.4.5},
author = {Barbera, Pablo},
title = {{streamR: Access to Twitter Streaming API via R}},
url = {https://cran.r-project.org/package=streamR},
year = {2018}
}
@manual{Bryan2019,
annote = {R package version 0.3.0},
author = {Bryan, Jennifer and Hester, Jim and Robinson, David and Wickham, Hadley},
title = {{reprex: Prepare Reproducible Example Code via the Clipboard}},
url = {https://cran.r-project.org/package=reprex},
year = {2019}
}
@manual{Bryan2016,
annote = {R package version 1.1.0},
author = {Bryan, Jennifer},
title = {{cellranger: Translate Spreadsheet Cell Ranges to Rows and Columns}},
url = {https://cran.r-project.org/package=cellranger},
year = {2016}
}
@article{Jarvis2013a,
abstract = {The range, variety, or diversity of words found in learners' language use is believed to reflect the complexity of their vocabulary knowledge as well as the level of their language proficiency. Many indices of lexical diversity have been proposed, most of which involve statistical relationships between types and tokens, and which ultimately reflect the rate of word repetition. These indices have generally been validated in accordance with how well they overcome sample-size effects and/or how well they predict language knowledge or behavior, rather than in accordance with how well they actually measure the construct of lexical diversity. In this article, I review developments that have taken place in lexical diversity research, and also describe obstacles that have prevented it from advancing further. I compare these developments with parallel research on biodiversity in the field of ecology, and show what language researchers can learn from ecology regarding the modeling and measurement of diversity as a multidimensional construct of compositional complexity.},
author = {Jarvis, Scott},
doi = {10.1111/j.1467-9922.2012.00739.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2013{\_}Capturing the Diversity in Lexical Diversity.pdf:pdf},
isbn = {1467-9922},
issn = {00238333},
journal = {Language Learning},
keywords = {Biodiversity,Ecological approaches,Human judgments,Lexical measures,Shannon's index,Simpson's index,Vocabulary acquisition,complexity,diversity},
mendeley-tags = {complexity,diversity},
number = {SUPPL. 1},
pages = {87--106},
title = {{Capturing the Diversity in Lexical Diversity}},
volume = {63},
year = {2013}
}
@article{Wood2003,
author = {Wood, S N},
journal = {Journal of the Royal Statistical Society (B)},
number = {1},
pages = {95--114},
title = {{Thin-plate regression splines}},
volume = {65},
year = {2003}
}
@article{Romer2017,
abstract = {This systematic review examined evidence regarding the effectiveness of interventions within the scope of occupational therapy practice to maintain, restore, and improve performance in leisure and social participation for older adults with low vision. We identified and reviewed 13 articles that met the inclusion criteria. Four themes related to interventions to improve leisure and social participation emerged from the literature review: using a problem-solving approach, delivering a combination of services, providing skills training, and making home visits and environmental adaptations. The strongest evidence supports using a problem-solving approach to improve leisure and social participation for older adults with low vision. Evidence was moderate supporting the delivery of a combination of services, either by one professional or through an interdisciplinary approach. Results for the effectiveness of skills training and home visits and home adaptations were mixed. Implications for practice, education, and research are discussed.},
author = {R{\"{o}}mer, Ute},
doi = {10.1177/0265532217711431},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/R{\"{o}}mer/R{\"{o}}mer{\_}2017{\_}Language assessment and the inseparability of lexis and grammar Focus on the construct of speaking.pdf:pdf},
isbn = {02729490},
issn = {14770946},
journal = {Language Testing},
keywords = {Assessment rubrics,corpus analysis,lexicogrammar,phraseology,speaking assessment,spoken corpora},
number = {4},
pages = {477--492},
title = {{Language assessment and the inseparability of lexis and grammar: Focus on the construct of speaking}},
volume = {34},
year = {2017}
}
@incollection{Pawley1983,
abstract = {Presents eight specially written chapters which provide a coherent survey of major issues in the study of language and communication, and which show how these are related to questions of practical concern in the learning and teaching of second and foreign languages. The issues discussed have been selected primarily for their relevance to applied linguistics, and there is a unifying interest in how language reflects the communicative functions it performs as well as in the process involved in using language for communication. Each chapter presents a self-contained survey of a central issue, is prefaced by an introduction linking the different perspectives, and is followed by discussion questions to aid effective use of the text in applied linguistics courses.},
address = {New York},
author = {Pawley, Andrew and Syder, Frances Hodgetts},
booktitle = {Language and communication},
editor = {Richards, Jack and Schmidt, RW},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Pawley, Syder/Pawley, Syder{\_}1983{\_}Two puzzles for linguistic theory nativelike selection and nativelike fluency.pdf:pdf},
isbn = {0 582 55034 3},
issn = {02707306},
keywords = {formulaic language},
mendeley-tags = {formulaic language},
pages = {191--226},
pmid = {1850100},
publisher = {Routledge},
title = {{Two puzzles for linguistic theory : nativelike selection and nativelike fluency}},
year = {1983}
}
@inproceedings{Abeille2004,
author = {Abeill{\'{e}}, Anne and Barrier, Nicolas},
booktitle = {LREC},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Abeill{\'{e}}, Barrier/Abeill{\'{e}}, Barrier{\_}2004{\_}Enriching a French treebank.pdf:pdf},
pages = {2233--2236},
title = {{Enriching a French treebank}},
year = {2004}
}
@misc{ngrampkg,
annote = {{\{}R{\}} package version 3.0.4},
author = {Schmidt, Drew and Heckendorf, Christian},
title = {{{\{}ngram{\}}: Fast n-Gram Tokenization}},
url = {https://cran.r-project.org/package=ngram},
year = {2017}
}
@phdthesis{Yan2017,
annote = {L1 Chinese Corpus of academic writing 
600k words
research reports, memoires},
author = {Yan, Rui},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Yan/Yan{\_}2017{\_}{\'{E}}tude des constructions verbales scientifiques dans une perspective didactique utilisation des corpus dans le diagnostic d.pdf:pdf},
school = {Universit{\'{e}} Grenoble Alpes},
title = {{{\'{E}}tude des constructions verbales scientifiques dans une perspective didactique : utilisation des corpus dans le diagnostic des besoins langagiers en FLE {\`{a}} l ' aide des techniques de TAL}},
type = {PhD Dissertation},
year = {2017}
}
@manual{Auguie2017,
annote = {R package version 2.3},
author = {Auguie, Baptiste},
title = {{gridExtra: Miscellaneous Functions for "Grid" Graphics}},
url = {https://cran.r-project.org/package=gridExtra},
year = {2017}
}
@manual{Xie2020,
annote = {R package version 0.20},
author = {Xie, Yihui},
title = {{bookdown: Authoring Books and Technical Documents with R Markdown}},
url = {https://github.com/rstudio/bookdown},
year = {2020}
}
@article{Solnyshkina,
author = {Solnyshkina, Marina and Ivanov, Vladimir and Solovyev, Valery},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Solnyshkina, Ivanov, Solovyev/Solnyshkina, Ivanov, Solovyev{\_}Unknown{\_}Characterizing Text Complexity with Core Vocabulary Distributional Patterns Corpus-based Approach.pdf:pdf},
keywords = {a corpus,bigram,distributional patterns,text complexity},
title = {{Characterizing Text Complexity with Core Vocabulary Distributional Patterns : Corpus-based Approach}}
}
@inproceedings{Hughes2019,
address = {Omskirk, UK},
author = {Hughes, Jennifer and Hardie, Andrew},
booktitle = {Symposium on Corpus Approaches to Lexicogrammar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hughes, Hardie/Hughes, Hardie{\_}2019{\_}Lexicogrammar and the brain , in theory and in practice.pdf:pdf},
month = {jun},
number = {June},
title = {{Lexicogrammar and the brain , in theory and in practice}},
year = {2019}
}
@article{Zeileis2008,
author = {Zeileis, Achim and Hothorn, Torsten and Hornik, Kurt},
journal = {Journal of Computational and Graphical Statistics},
number = {2},
pages = {492--514},
title = {{Model-Based Recursive Partitioning}},
volume = {17},
year = {2008}
}
@manual{Wickham2019d,
annote = {R package version 0.3.5},
author = {Wickham, Hadley},
title = {{rvest: Easily Harvest (Scrape) Web Pages}},
url = {https://cran.r-project.org/package=rvest},
year = {2019}
}
@manual{Wickham2019r,
annote = {R package version 1.4.2},
author = {Wickham, Hadley and Ruiz, Edgar},
title = {{dbplyr: A 'dplyr' Back End for Databases}},
url = {https://cran.r-project.org/package=dbplyr},
year = {2019}
}
@incollection{Gries2013,
address = {Cambridge},
author = {Gries, Stefan Th.},
booktitle = {The Cambridge Handbook of Learner Corpus Research},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research(2).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research(3).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research(4).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research(5).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research(6).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2013{\_}Statistics for learner corpus research(7).pdf:pdf},
keywords = {stats},
mendeley-tags = {stats},
pages = {159--182},
publisher = {Cambridge University Press},
title = {{Statistics for learner corpus research}},
year = {2013}
}
@manual{RCoreTeam2019,
address = {Vienna, Austria},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
title = {{R: A language and environment for statistical computing}},
url = {https://www.r-project.org/},
year = {2019}
}
@manual{Kassambara2019,
annote = {R package version 0.1.3},
author = {Kassambara, Alboukadel},
title = {{ggcorrplot: Visualization of a Correlation Matrix using 'ggplot2'}},
url = {https://cran.r-project.org/package=ggcorrplot},
year = {2019}
}
@article{Ortega2003,
abstract = {In this study I evaluate the cumulative evidence on the use of syntactic complexity measures as indices of college-level L2 writers' overall pro{\textregistered}ciency in the target language. Based on a synthesis of twenty-{\textregistered}ve studies, I arrive at several substantive {\textregistered}ndings. First, I conclude that the relationship between L2 pro{\textregistered}ciency and L2 writing syntactic complexity varied systematically across studies depending on whether a second or a foreign language learning context was investigated and whether pro{\textregistered}ciency was de{\textregistered}ned by programme level or by holistic rating. Second, aggregating available cross-sectional {\textregistered}ndings, I propose critical magnitudes for between-pro{\textregistered}ciency dierences in syntactic complexity for four measures. Finally, I interpret the limited longitudinal evidence to suggest that an observation period of roughly a year of college-level instruction is probably needed for substantial changes in the syntactic complexity of L2 writing to be observed. I conclude the paper by discussing implications of these {\textregistered}ndings for future primary research. Syntactic complexity (also called syntactic maturity or linguistic complexity) refers to the range of forms that surface in language production and the degree of sophistication of such forms. This construct is important in second language research because of the assumption that language development entails, among other processes, the growth of an L2 learner's syntactic repertoire and her or his ability to use that repertoire appropriately in a variety of situations. Length of production unit, amount of embedding, range of structural types, and sophistication of the particular structures deployed in production have all been the target of quanti{\textregistered}cations when characterizing syntactic complexity, resulting in a variety of global measures. Measures of syntactic complexity are important research tools not only in the {\textregistered}eld of second language acquisition but in a variety of language-related disciplines, and although concrete de{\textregistered}nitions and applications of the measures vary across {\textregistered}elds, the main purposes for use are very similar. In L2 writing research, speci{\textregistered}cally, syntactic complexity measures have been used to evaluate the eects of a pedagogical intervention on the development of grammar, writing ability, or both; to investigate task-related variation in L2 writing; and to assess dierences in L2 texts written by learners across Applied Linguistics 24/4: 492±518},
author = {Ortega, Lourdes},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ortega/Ortega{\_}2003{\_}Syntactic Complexity Measures and Their Relationship to L2 Proficiency A Research Synthesis of College Level L2 Writing.pdf:pdf},
journal = {Applied Linguistics},
number = {4},
pages = {492--518},
title = {{Syntactic Complexity Measures and Their Relationship to L2 Proficiency A Research Synthesis of College Level L2 Writing}},
volume = {24},
year = {2003}
}
@manual{Wickham2019e,
annote = {R package version 0.2.1},
author = {Wickham, Hadley},
title = {{assertthat: Easy Pre and Post Assertions}},
url = {https://cran.r-project.org/package=assertthat},
year = {2019}
}
@article{MacWhinney2020,
author = {MacWhinney, B},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/MacWhinney/MacWhinney{\_}2020{\_}The CHILDES Project Tools for Analyzing Talk–Electronic Edition Part 1 The CHAT Transcription Format.pdf:pdf},
title = {{The CHILDES Project Tools for Analyzing Talk–Electronic Edition Part 1: The CHAT Transcription Format}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.359.4451},
year = {2020}
}
@manual{Bates2019,
annote = {R package version 1.2-17},
author = {Bates, Douglas and Maechler, Martin},
title = {{Matrix: Sparse and Dense Matrix Classes and Methods}},
url = {https://cran.r-project.org/package=Matrix},
year = {2019}
}
@inproceedings{Granfeldt2007,
address = {Toulouse},
author = {Granfeldt, Jonas and Nugues, Pierre},
booktitle = {TALN},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granfeldt, Nugues/Granfeldt, Nugues{\_}2007{\_}{\'{E}}valuation des stades de d{\'{e}}veloppement en fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re.pdf:pdf},
month = {jun},
pages = {5--8},
title = {{{\'{E}}valuation des stades de d{\'{e}}veloppement en fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re}},
year = {2007}
}
@book{Hunston2000,
address = {Amsterdam},
author = {Hunston, Susan and Francis, Gill},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hunston, Francis/Hunston, Francis{\_}2000{\_}Pattern Grammar.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hunston, Francis/Hunston, Francis{\_}2000{\_}Pattern Grammar(2).pdf:pdf},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
publisher = {John Benjamins},
title = {{Pattern Grammar}},
year = {2000}
}
@manual{Gohel2020a,
annote = {R package version 0.2.5},
author = {Gohel, David},
title = {{rvg: R Graphics Devices for Vector Graphics Output}},
url = {https://cran.r-project.org/package=rvg},
year = {2020}
}
@article{Klee1992,
author = {Klee, T},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Klee/Klee{\_}1992{\_}Developmental and diagnostic characteristics of quantitative measures of children's language production.pdf:pdf},
journal = {Topics in Language Disorders},
keywords = {lexdiv{\_}NDW},
mendeley-tags = {lexdiv{\_}NDW},
pages = {28--41},
title = {{Developmental and diagnostic characteristics of quantitative measures of children's language production}},
volume = {12},
year = {1992}
}
@manual{Wickham2018a,
annote = {R package version 1.0.0},
author = {Wickham, Hadley},
title = {{scales: Scale Functions for Visualization}},
url = {https://cran.r-project.org/package=scales},
year = {2018}
}
@article{Lowie2017,
abstract = {Cet article esquisse l'id{\'{e}}e selon laquelle le d{\'{e}}veloppement d'une langue seconde serait un processus {\'{e}}mergent r{\'{e}}pondant aux caract{\'{e}}ristiques d'un syst{\`{e}}me complexe. L'acquisition langagi{\`{e}}re, dans une perspective {\'{e}}mergentiste, est d{\'{e}}finie comme un processus majoritairement individuel dans lequel des sous-syst{\`{e}}mes interagissent en red{\'{e}}finissant perp{\'{e}}tuellement le syst{\`{e}}me lui-m{\^{e}}me. L'interaction de ces sous-syst{\`{e}}mes provoque un certain degr{\'{e}} de variabilit{\'{e}} intra-individuelle qui est caract{\'{e}}ristique du processus d'apprentissage langagier : plus de variabilit{\'{e}} indique plus d'apprentissage. La principale implication, pour la recherche sur l'acquisition langagi{\`{e}}re, porte sur le fait que nous avons besoin de plus d'{\'{e}}tudes de cas longitudinales qui nous permettraient de tracer l'{\'{e}}volution du d{\'{e}}veloppement individuel au cours du temps. La principale implication pour l'enseignement est que nous devrions reconnaitre la variabilit{\'{e}} langagi{\`{e}}re de chaque individu et que l'enseignement des langues devrait prendra la forme d'un « coaching » (tutorat). Une autre implication serait que l'usage d'une langue, comme un moyen actif de communication, est une condition indispensable {\`{a}} l'apprentissage. La perspective {\'{e}}mergentiste offre un cadrage th{\'{e}}orique large qui peut nous permettre de comprendre la nature complexe du d{\'{e}}veloppement langagier.This paper outlines second language development as an emergent and complex dynamic process. Language acquisition from an emergent perspective is defined as a highly individual process in which subsystems continuously interact in shaping the ever-changing system. The interacting subsystems result in a degree of intra-individual variability that is characteristic for the process of language learning : more variability indicates more learning. The most important implication for research into language acquisition is that we need more longitudinal case studies that allow us to track individual development as it evolves over time. The most important implication for teaching is that we should acknowledge the variability in a learner's language and that language teaching should ideally take the form of individual coaching. Another implication is that using language as an active means of communication is an indispensable component of language learning. The emergentist perspective provides a wide-ranging theoretical framework that can help us understand the complex nature of second language development.},
author = {Lowie, Wander},
doi = {10.4000/rdlc.1140},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lowie/Lowie{\_}2017{\_}Emergentism wide ranging theoretical framework or just one more meta-theory.pdf:pdf},
issn = {1958-5772},
journal = {Recherches en didactique des langues et des cultures. Les cahiers de l'ACEDLE [En Ligne]},
keywords = {Dynamic Systems Theory,L2 acquisition,emergentism,teaching},
number = {1},
pages = {1--9},
title = {{Emergentism: wide ranging theoretical framework or just one more meta-theory?}},
url = {http://journals.openedition.org/rdlc/1140},
volume = {14},
year = {2017}
}
@manual{Hothorn2019a,
annote = {R package version 1.0-4},
author = {Hothorn, Torsten},
title = {{libcoin: Linear Test Statistics for Permutation Inference}},
url = {https://cran.r-project.org/package=libcoin},
year = {2019}
}
@article{Biber2019,
author = {Biber, Douglas},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Biber/Biber{\_}2019{\_}Text-linguistic approaches to register variation.pdf:pdf},
journal = {Register Studies},
number = {1},
pages = {42--75},
title = {{Text-linguistic approaches to register variation}},
volume = {1},
year = {2019}
}
@techreport{Jones1995,
author = {Jones, Glyn},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jones/Jones{\_}1995{\_}Compiling French word frequency lists for the VAT a feasibility study.pdf:pdf},
title = {{Compiling French word frequency lists for the VAT : a feasibility study}},
year = {1995}
}
@article{Crutchfield1989,
abstract = {Statistical mechanics is used to describe the observed information processing complexity of nonlinear dynamical systems. We introduce a measure of complexity distinct from and dual to the information theoretic entropies and dimensions. A technique is presented that directly reconstructs minimal equations of motion from the recursive structure of measurement sequences. Application to the period-doubling cascade demonstrates a form of superuniversality that refers only to the entropy and complexity of a data stream. {\textcopyright} 1989 The American Physical Society.},
author = {Crutchfield, James P. and Young, Karl},
doi = {10.1103/PhysRevLett.63.105},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crutchfield, Young/Crutchfield, Young{\_}1989{\_}Inferring statistical complexity.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
number = {2},
pages = {105--108},
title = {{Inferring statistical complexity}},
volume = {63},
year = {1989}
}
@manual{Muller2020a,
annote = {R package version 0.5.3},
author = {M{\"{u}}ller, Kirill},
title = {{hms: Pretty Time of Day}},
url = {https://cran.r-project.org/package=hms},
year = {2020}
}
@article{J.A.1960,
abstract = {CONSIDER Table 1. It represents in its formal characteristics a situation which arises in the clinical-social-personality areas of psychology, where it frequently occurs that the only useful level of measurement obtainable is nominal scaling (Stevens, 1951, pp. 25-26), i.e. placement in a set of k unordered categories. Because the categorizing of the units is a consequence of some complex judgment process performed by a {\&}dquo;two-legged meter{\&}dquo; (Stevens, 1958), it becomes important to determine the extent to which these judgments are reproducible, i.e., reliable. The procedure which suggests itself is that of having two (or more) judges independently categorize a sample of units and determine the degree, significance, and TABLE 1 11 n Agreement Matrix of Proportions},
author = {Cohen, Jacob},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cohen/Cohen{\_}1960{\_}A coefficient of agreement for nominal scales.pdf:pdf},
journal = {Educational And Psychological Measurement},
number = {1},
pages = {37--46},
title = {{A coefficient of agreement for nominal scales}},
volume = {20},
year = {1960}
}
@inproceedings{Marneffe2014,
address = {Reykjavik},
author = {Marneffe, Marie-catherine De and Dozat, Timothy and Silveira, Natalia and Haverinen, Katri and Ginter, Filip and Nivre, Joakim and Manning, Christopher D},
booktitle = {Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014)},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Marneffe et al/Marneffe et al.{\_}2014{\_}Universal Stanford Dependencies A cross-linguistic typology.pdf:pdf},
keywords = {dependency grammar,grammatical taxonomy,stanford dependencies},
publisher = {European Language Resources Association (ELRA)},
title = {{Universal Stanford Dependencies : A cross-linguistic typology}},
year = {2014}
}
@manual{Henry2020a,
annote = {R package version 0.3.4},
author = {Henry, Lionel and Wickham, Hadley},
title = {{purrr: Functional Programming Tools}},
url = {https://cran.r-project.org/package=purrr},
year = {2020}
}
@article{Hothorn2006b,
author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
journal = {Journal of Computational and Graphical Statistics},
number = {3},
pages = {651--674},
title = {{Unbiased Recursive Partitioning: A Conditional Inference Framework}},
volume = {15},
year = {2006}
}
@manual{Bates2015a,
annote = {R package version 0.4-1},
author = {Bates, Douglas and Maechler, Martin},
title = {{MatrixModels: Modelling with Sparse And Dense Matrices}},
url = {https://cran.r-project.org/package=MatrixModels},
year = {2015}
}
@article{Ellis2006a,
abstract = {This paper outlines current cognitive perspectives on second language acquisi- tion (SLA). The Associative-Cognitive CREED holds that SLA is governed by the same principles of associative and cognitive learning that underpin the rest of human knowledge. The major principles of the framework are that SLA is Con- struction-based, Rational, Exemplar-driven, Emergent, and Dialectic. Language learning involves the acquisition of constructions that map linguistic form and function. Competence and performance both emerge from the dynamic system that is the frequency-tuned conspiracy of memorized exemplars of use of these constructions, with competence being the integrated sum of prior usage and performance being its dynamic contextualized activation. The system is rational in that it optimally reflects prior first language (L1) usage. The L1 tunes the ways in which learners attend to language. Learned-attention transfers to L2 and it is this L1 entrenchment that limits the endstate of usage-based SLA. But these limitations can be overcome by recruiting learner consciousness, putting them into a dialectic tension between the conflicting forces of their current stable states of interlanguage and the evidence of explicit form-focused feedback, either linguistic, pragmatic, or metalinguistic, that allows socially scaffolded develop- ment. The paper directs the reader to recent review articles in these key areas and weighs the implications of this framework.},
author = {Ellis, Nick C},
doi = {10.1075/aila.19.08ell},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis/Ellis{\_}2006{\_}Cognitive perspectives on SLA The Associative-Cognitive CREED.pdf:pdf},
issn = {1570-5595},
journal = {AILA Review},
pages = {100--121},
title = {{Cognitive perspectives on SLA: The Associative-Cognitive CREED}},
volume = {19},
year = {2006}
}
@book{Ellis2009,
address = {Boston, MA},
editor = {Ellis, Nick C. and Larsen-Freeman, Diane},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Unknown/Unknown{\_}2009{\_}Language as a Complex Adaptive System.pdf:pdf},
publisher = {Wiley-Blackwell},
title = {{Language as a Complex Adaptive System}},
year = {2009}
}
@article{Allaw2019,
author = {Allaw, Elissa and McDonough, Kim},
doi = {10.1016/j.system.2019.06.008},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Allaw, McDonough/Allaw, McDonough{\_}2019{\_}The effect of task sequencing on second language written lexical complexity, accuracy, and fluency.pdf:pdf},
issn = {0346251X},
journal = {System (to appear)},
publisher = {Elsevier Ltd},
title = {{The effect of task sequencing on second language written lexical complexity, accuracy, and fluency}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0346251X1830798X},
year = {2019}
}
@article{Myles1998,
abstract = {This article investigates the role in learning of rote-learned formulas or chunks. We examined data from a longitudinal study of 16 child beginner classroom learners of French for occurrences of three chunks, against which we first tried out definitional criteria. We then tracked these forms for 2 years to chart their breakdown and explore their contribution to the development of a creative language capacity. Our data showed that most of the learners not only gradually “unpacked” their early chunks, but also used parts of them productively in the generation of new utterances. These findings demonstrated that rote-learning of formulas and the construction of rules are not independent processes, but interact and actively feed into one another.},
author = {Myles, Florence and Hooper, Janet and Mitchell, Rosamond},
doi = {10.1111/0023-8333.00045},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Myles, Hooper, Mitchell/Myles, Hooper, Mitchell{\_}1998{\_}Rote or rule Exploring the role of formulaic language in classroom foreign language learning.pdf:pdf},
isbn = {1467-9922},
issn = {1467-9922},
journal = {Language Learning},
number = {3},
pages = {323--363},
pmid = {21135132},
title = {{Rote or rule? Exploring the role of formulaic language in classroom foreign language learning}},
volume = {48},
year = {1998}
}
@article{McWhorter2001,
abstract = {It is often stated that all languages are equal in terms of complexity. This paper introduces a metric of complexity, determined by degree of overt signalling of various phonetic, morphological, syntactic, and semantic distinctions beyond communicative necessity. By this metric, a subset of creole languages display less overall grammatical complexity than older languages, by virtue of the fact that they were born as pidgins, and thus stripped of almost all features unnec- essary to communication, and since then have not existed as natural languages for a long enough time for diachronic drift to create the weight of “ornament” that encrusts older languages. It is demonstrated that this complexity differ- ential remains robust even when creoles are compared with older languages lacking inflection, contra claims by theoretical syntacticians that the typology of creoles is largely a manifestation of parameter settings resulting from low inflection. The overall aim is to bolster a general paradigm arguing that creole languages are delineable synchronically as well as sociohistorically.},
annote = {mapping this onto l2 french development (schylter)?},
author = {McWhorter, John H.},
doi = {10.1515/lity.2001.001},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/McWhorter/McWhorter{\_}2001{\_}The worlds simplest grammars are creole grammars.pdf:pdf},
isbn = {1430-0532},
issn = {14300532},
journal = {Linguistic Typology},
keywords = {Analytic-synthetic,Complexity,Creole,Derivation,Diachrony,Gender,Grammaticalization,Inflection,Lahu,Maori,Markedness,Noun class,Phoneme inventory,Pidgin,Saramaccan,Semantic transparency,Tone,Tsez,theorySLA},
mendeley-tags = {theorySLA},
pages = {125--166},
title = {{The worlds simplest grammars are creole grammars}},
volume = {5},
year = {2001}
}
@manual{Rinker2018c,
address = {Buffalo, New York},
annote = {version 0.9.3},
author = {Rinker, Tyler W},
title = {{{\{}textclean{\}}: Text Cleaning Tools}},
url = {https://github.com/trinker/textclean},
year = {2018}
}
@manual{Gordon2019,
annote = {R package version 1.13.1},
author = {Gordon, Max and Gragg, Stephen and Konings, Peter},
title = {{htmlTable: Advanced Tables for Markdown/HTML}},
url = {https://cran.r-project.org/package=htmlTable},
year = {2019}
}
@manual{Adler2019,
annote = {R package version 0.100.26},
author = {Adler, Daniel and Murdoch, Duncan and Others},
title = {{rgl: 3D Visualization Using OpenGL}},
url = {https://cran.r-project.org/package=rgl},
year = {2019}
}
@incollection{Miller1991,
address = {Austin},
author = {Miller, J.F.},
booktitle = {Research in child language disorders: A decade of progress},
editor = {Miller, J.},
keywords = {lexdiv{\_}NDW},
mendeley-tags = {lexdiv{\_}NDW},
pages = {211--220},
publisher = {Pro-Ed},
title = {{Quantifying productive language disorders}},
year = {1991}
}
@manual{Rinker2017,
address = {Buffalo, New York},
annote = {0.7.2},
author = {Rinker, Tyler W},
organization = {University at Buffalo/SUNY},
title = {{{\{}qdapRegex{\}}: Regular Expression Removal, Extraction, and Replacement Tools}},
url = {http://github.com/trinker/qdapRegex},
year = {2017}
}
@techreport{Nugues2006a,
abstract = {The importance of computer learner corpora for research in both second language acquisition and foreign language teaching is rapidly increasing. Computer learner corpora can provide us with data to describe the learner's interlanguage system at different points of its development and they can be used to create pedagogical tools. In this paper, we first present a new computer learner corpora in French. We then describe an analyzer called Direkt Profil, that we have developed using this corpus. The system carries out a sentence analysis based on developmental sequences, i.e. local morphosyntactic phenomena linked to a development in the acquisition of French as a foreign language. We present a brief introduction to developmental sequences and some examples in French. In the final section, we introduce and evaluate a method to optimize the definition and detection of learner profiles using machine-learning techniques.},
author = {Nugues, J and Persson, P and Thulin, E and {\AA}gren, J and Schlyter, M},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Nugues et al/Nugues et al.{\_}2006{\_}CEFLE and Direkt Profil a new computer learner corpus in French L2 and a system for grammatical profiling.pdf:pdf},
keywords = {Granfeldt, Jonas,Nugues, Pierre,Persson, Emil,Schlyter, Suzanne,Thulin, Jonas,{\AA}gren, Malin},
pages = {565--570},
publisher = {ELRA},
title = {{CEFLE and Direkt Profil: a new computer learner corpus in French L2 and a system for grammatical profiling}},
year = {2006}
}
@manual{Rudis2018,
annote = {R package version 0.7.0},
author = {Rudis, Bob and Lohmann, Niels and Bandyopadhyay, Deepak and Kettner, Lutz},
title = {{ndjson: Wicked-Fast Streaming 'JSON' ('ndjson') Reader}},
url = {https://cran.r-project.org/package=ndjson},
year = {2018}
}
@phdthesis{Huang2018a,
author = {Huang, Yan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Huang/Huang{\_}2018{\_}Automatic syntactic analysis of learner English.pdf:pdf},
school = {University of Cambridge},
title = {{Automatic syntactic analysis of learner English}},
type = {PhD Dissertation},
year = {2018}
}
@article{Paquot,
author = {Paquot, Magali and Biber, Douglas and Larsson, Tove},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot, Biber, Larsson/Paquot, Biber, Larsson{\_}Unknown{\_}SUBMITTED!! On the importance of register in learner writing A multi-dimensional approach.pdf:pdf},
journal = {International Journal of Learner Corpus Research},
keywords = {argumentative essays,learner corpus research,multi-dimensional analysis,register,research papers,scientific articles},
pages = {?},
title = {{SUBMITTED!! On the importance of register in learner writing: A multi-dimensional approach}}
}
@misc{Kyle2019,
author = {Kyle, Kristopher and Crossley, Scott A.},
keywords = {taaled},
mendeley-tags = {taaled},
title = {{TAALED: Tool for the Automatic Analysis of Lexical Diversity (v.1.3.1)}},
year = {2019}
}
@incollection{Welcomme2013,
address = {Lublin},
author = {Welcomme, Aurelie},
booktitle = {La complexité en langue et son acquisition},
editor = {Paprocka-Piotrowska, U. and Martinot, C. and Gerolimich, S.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Welcomme/Welcomme{\_}2013{\_}Jonction interpropositionnelle et complexit{\'{e}} syntaxique dans les r{\'{e}}cits d'apprenants n{\'{e}}erlandophones et locuteurs nati.pdf:pdf},
keywords = {complexity},
mendeley-tags = {complexity},
pages = {261--284},
publisher = {Towarzystwo Naukowe Kul Katolicki Uniwersytet Jana Pawla II},
title = {{Jonction interpropositionnelle et complexit{\'{e}} syntaxique dans les r{\'{e}}cits d'apprenants n{\'{e}}erlandophones et locuteurs natifs du fran{\c{c}}ais [Clausal linking and syntactic complexity in the writing of Dutch learners and French native speakers]}},
year = {2013}
}
@incollection{Bartning2018,
address = {Cambridge},
author = {Bartning, Inge and Lundell, Fanny Forsberg},
booktitle = {High-Level Language Proficiency in Second Language and Multilingual Contexts},
doi = {10.1017/9781316809686.003},
editor = {Hyltenstam, Kenneth and Bartning, Inge and Fant, Lars},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Lundell/Bartning, Lundell{\_}2018{\_}The Last Barriers in High-Level L2 Speech Morphosyntax in Focus.pdf:pdf},
isbn = {9781316809686},
pages = {50--72},
publisher = {Cambridge University Press},
title = {{The Last Barriers in High-Level L2 Speech: Morphosyntax in Focus}},
year = {2018}
}
@phdthesis{Joris2018,
address = {Gent},
author = {Joris, Ellen},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Joris/Joris{\_}2018{\_}Analyse de la production {\'{e}}crite en FLE chez les {\'{e}}tudiants en linguistique appliqu{\'{e}}e.pdf:pdf},
school = {Universiteit Gent},
title = {{Analyse de la production {\'{e}}crite en FLE chez les {\'{e}}tudiants en linguistique appliqu{\'{e}}e}},
type = {MA Thesis},
year = {2018}
}
@manual{Wand2015,
annote = {R package version 2.23-15},
author = {Wand, Matt},
title = {{KernSmooth: Functions for Kernel Smoothing Supporting Wand {\&} Jones (1995)}},
url = {https://cran.r-project.org/package=KernSmooth},
year = {2015}
}
@book{Wood2017,
author = {Wood, S N},
edition = {2},
publisher = {Chapman and Hall/CRC},
title = {{Generalized Additive Models: An Introduction with R}},
year = {2017}
}
@incollection{Wulff2011,
abstract = {Adopting the perspective of Ellis's (2007) Associative-Cognitive CREED, this chapter proposes a measure of accuracy in learner production that is based on conditional probabilities. More specifically, we develop a definition of accuracy that involves 'the proficient selection of constructions in their preferred constructional context in a particular target genre'. Comparing this approach to previous work on linguistic units larger than the word, we discuss how this definition (i) does away with a strict separation of lexis and grammar, shifting the focus to interactions between constructions; (ii) embraces various aspects of accuracy (phonology, morphology, lexis, etc.) instead of being restricted to target-like vocabulary choice alone; and (iii) reflects our understanding of native-like proficiency as a gradual, probabilistic phenomenon that transcends a native-nonnative speaker divide. We then exemplify this measure in two small case studies using lexico-grammatical association patterns from L1 and L2 corpora and discuss implications of the theoretical perspective and the empirical measure for task design.},
address = {Amsterdam},
annote = {Accuracy = selection of a construction in the preferred context within a particular target variety and genre (p. 70)

- will increase proportionally to the extent that learners succeed in mking the right generalizations regarding which form is mapped onto which function (p. 81)

- depends on: frequency in the input, amount of attn/processing/degree to which form-function mappings are recognizable, salient, relevant and reliable 

acccuracy -- using the right combinations with the right words, complexity -- the factors that affect the ability to map them correctly ({\textless} freq, {\textless} salient, {\textless}transparent)},
author = {Wulff, Stefanie and Gries, Stefan Th.},
booktitle = {Second Language Task Complexity. Researching the Cognition Hypothesis of language learning and performance},
editor = {{Peter Robinson}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wulff, Gries/Wulff, Gries{\_}2011{\_}Corpus-driven methods for assessing accuracy in learner production.pdf:pdf},
keywords = {complexity},
mendeley-tags = {complexity},
pages = {61--87},
publisher = {John Benjamins},
title = {{Corpus-driven methods for assessing accuracy in learner production}},
year = {2011}
}
@manual{Gohel2020,
annote = {R package version 0.2.0},
author = {Gohel, David and Ross, Noam},
title = {{officedown: Enhanced 'R Markdown' Format for 'Word' and 'PowerPoint'}},
url = {https://cran.r-project.org/package=officedown},
year = {2020}
}
@article{Kraif2016,
author = {Kraif, Olivier},
doi = {10.15122/isbn.978-2-406-06281-3.p.0091},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kraif/Kraif{\_}2016{\_}Le lexicoscope un outil d 'extraction des s{\'{e}}quences phras{\'{e}}ologiques bas{\'{e}} sur des corpus arbor{\'{e}}s.pdf:pdf},
isbn = {9782406062813},
journal = {Cahiers de lexicologie},
number = {108},
pages = {91--106},
title = {{Le lexicoscope : un outil d 'extraction des s{\'{e}}quences phras{\'{e}}ologiques bas{\'{e}} sur des corpus arbor{\'{e}}s}},
volume = {1},
year = {2016}
}
@article{Treffers-Daller2018a,
abstract = {This study contributes to ongoing discussions on how measures of lexical diversity (LD) can help discriminate between essays from second language learners of English, whose work has been assessed as belonging to levels B1 to C2 of the Common European Framework of Reference (CEFR). The focus is, in particular, on how different operationalizations of what constitutes a 'different word' (type) impact on the LD measures themselves and on their ability to discriminate between CEFR levels. The results show that basic measures of LD, such as the number of different words, the TTR (Templin 1957), and the Index of Guiraud (Guiraud 1954) explain more variance in the CEFR levels than sophisticated measures, such as D (Malvern et al. 2004), HD-D (McCarthy and Jarvis 2007), and MTLD (McCarthy 2005) provided text length is kept constant across texts. A simple count of different words (defined as lemma's and not as word families) was the best predictor of CEFR levels and explained 22 per cent of the variance in overall scores on the Pearson Test of English Academic in essays written by 176 test takers.},
author = {Treffers-Daller, Jeanine and Parslow, Patrick and Williams, Shirley},
doi = {10.1093/applin/amw009},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Treffers-Daller, Parslow, Williams/Treffers-Daller, Parslow, Williams{\_}2018{\_}Back to Basics How Measures of Lexical Diversity Can Help Discriminate between CEFR Levels.pdf:pdf},
issn = {1477450X},
journal = {Applied Linguistics},
number = {3},
pages = {302--327},
title = {{Back to Basics: How Measures of Lexical Diversity Can Help Discriminate between CEFR Levels}},
volume = {39},
year = {2018}
}
@article{Genuer2010,
abstract = {This paper proposes, focusing on random forests, the increasingly used statistical method for classification and regression problems introduced by Leo Breiman in 2001, to investigate two classical issues of variable selection. The first one is to find important variables for interpretation and the second one is more restrictive and try to design a good prediction model. The main contribution is twofold: to provide some insights about the behavior of the variable importance index based on random forests and to propose a strategy involving a ranking of explanatory variables using the random forests score of importance and a stepwise ascending variable introduction strategy},
author = {Genuer, Robin and Poggi, Jean-Michel and Tuleau-Malot, Christine},
doi = {10.1093/jofore/fvz013},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Genuer, Poggi, Tuleau-Malot/Genuer, Poggi, Tuleau-Malot{\_}2010{\_}Variable selection using Random Forests.pdf:pdf},
issn = {0022-1201},
journal = {Pattern Recognition Letters},
keywords = {2010 msc,62g08,62g09,62h30,Classification,Random forests,Regression,Variab,acer saccharum,classification,forest management,great lakes states,hard-,heartwood,high dimensional data,is an economically important,kets as hard maple,known to lumber mar-,random forests,regression,sugar maple,sugar maple is,tree value,variable importance,variable selection,wood discoloration,wood species in the},
number = {14},
pages = {2225--2236},
title = {{Variable selection using Random Forests}},
url = {https://academic.oup.com/jof/article/117/3/256/5477054},
volume = {31},
year = {2010}
}
@article{Wickham2011a,
author = {Wickham, Hadley},
journal = {The R Journal},
pages = {5--10},
title = {{testthat: Get Started with Testing}},
url = {https://journal.r-project.org/archive/2011-1/RJournal{\_}2011-1{\_}Wickham.pdf},
volume = {3},
year = {2011}
}
@techreport{Nivre2010,
author = {Nivre, J and Hall, Johan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Nivre, Hall/Nivre, Hall{\_}2010{\_}A quick guide to MaltParser optimization.pdf:pdf},
issn = {1309-3878},
title = {{A quick guide to MaltParser optimization}},
url = {ofile/Joakim{\_}Nivre/publication/265022743{\_}A{\_}Quick{\_}Guide{\_}to{\_}MaltParser{\_}Optimization/links/54ba2f010cf253b50e2ad0e0/A-Quick-Guide-to-MaltParser-Optimization.pdf},
year = {2010}
}
@incollection{Tidball2007,
address = {Cambridge},
author = {Tidball, Fran{\c{c}}oise and Treffers-Daller, Jeanine},
booktitle = {Modelling and Assessing Vocabulary Knowledge},
editor = {Daller, Helmut and Milton, James and Treffers-Daller, Jeanine},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Tidball, Treffers-Daller/Tidball, Treffers-Daller{\_}2007{\_}Exploring measures of vocabulary richness in semi-spontaneous French speech.pdf:pdf},
pages = {133--149},
publisher = {Cambridge University Press},
title = {{Exploring measures of vocabulary richness in semi-spontaneous French speech}},
year = {2007}
}
@incollection{Granfeldt2007a,
address = {Brussels},
annote = {lexical complexity was higher in writing than in speech
‣ gen measure of gramm complexity does not reveal any differences between writing and speaking

◦ vocab diversity higher in writing than speaking 
◦ ratio clauses per t unit lower in writing 
◦ grammatical profiles of written production do not gen include more advanced structures than profiles of oral production 
◦ individual differences},
author = {Granfeldt, Jonas},
booktitle = {Complexity, Accuracy and Fluency in Second Language Use, Learning {\&} Teaching},
editor = {van Daele, Siska and Housen, Alex and Kuiken, Folke and Pierrard, Michel and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granfeldt/Granfeldt{\_}2007{\_}Speaking and Writing in French L2 Exploring Effects on Fluency, Complexity and Accuracy.pdf:pdf},
pages = {87--98},
publisher = {Koninklijk Vlaamse Academie Van Belgie Voor Wetenschappen en Kunsten},
title = {{Speaking and Writing in French L2: Exploring Effects on Fluency, Complexity and Accuracy}},
year = {2007}
}
@article{Labeau2005,
author = {Labeau, Emmanuelle},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Labeau/Labeau{\_}2005{\_}Line or Circle The Process of Past Tenses Acquisition by Advanced Learners of French.pdf:pdf},
pages = {1264--1275},
title = {{Line or Circle ? The Process of Past Tenses Acquisition by Advanced Learners of French}},
year = {2005}
}
@manual{Wickham2018b,
annote = {R package version 0.5.0},
author = {Wickham, Charlotte},
title = {{munsell: Utilities for Using Munsell Colours}},
url = {https://cran.r-project.org/package=munsell},
year = {2018}
}
@inproceedings{Paquot2018a,
address = {Atlanta},
author = {Paquot, Magali and Brezina, Vaclav and Gablasova, Dana and Naets, Hubert},
booktitle = {14th Annual Association for Corpus Linguistics (AACL) Conference},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot et al/Paquot et al.{\_}2018{\_}Relational co-occurances as an index of oral proficiency in the Trinity Lancaster Learner Corpus.pdf:pdf},
title = {{Relational co-occurances as an index of oral proficiency in the Trinity Lancaster Learner Corpus}},
year = {2018}
}
@article{Bartning2004,
abstract = {Nous proposons ici des stades de d'adultes su{\'{e}}dophones, formul{\'{e}}s comme profils grammaticaux d'apprenants {\`{a}} des niveaux diff{\'{e}}rents. Cette proposition se fonde sur les r{\'{e}}sultats empiriques des travaux men{\'{e}}s au sein de deux projets diff{\'{e}}rents sur l'acquisition du francais L2 des apprenants su{\'{e}}dophones. {\`{A}} partir d'itin{\'{e}}raires acquistionnels nous proposons six stades, qui s'{\'{e}}tendent des d{\'{e}}buts de l'acquisition jusqu'{\`{a}} la production d'apprenants quasi-natifs. Ces itin{\'{e}}raires, et les stades que nous essayons d'en d{\'{e}}duire, refl{\`{e}}tent l'acquisition du francais de l'apprenant su{\'{e}}dophone, dans des situations orales spontan{\'{e}}s o{\`{u}} elle/il doit avoir recours {\`{a}} ses connaissances automatiques. Le cadre de cette {\'{e}}tude et donc descriptif et empirique. Un objectif ult{\'{e}}rieur est de servir de base {\`{a}} une {\'{e}}valuation du niveau grammatical d'un certain apprenant {\`{a}} un moment donn{\'{e}}.},
author = {Bartning, Inge and Schlyter, Suzanne},
doi = {10.1017/S0959269504001802},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Schlyter/Bartning, Schlyter{\_}2004{\_}Itin{\'{e}}raires acquisitionnels et stades de d{\'{e}}veloppement en fran{\c{c}}ais L2 Acquisitional routes and stages of deve.pdf:pdf},
issn = {0959-2695},
journal = {Journal of French Language Studies},
pages = {281--299},
title = {{Itin{\'{e}}raires acquisitionnels et stades de d{\'{e}}veloppement en fran{\c{c}}ais L2 [Acquisitional routes and stages of development in L2 French]}},
volume = {14},
year = {2004}
}
@article{Hancock2007,
abstract = {Le propos de l'{\'{e}}tude descriptive pr{\'{e}}sent{\'{e}}e dans cet article est de trouver des caract{\'{e}}ristiques du discours de l'apprenant avanc{\'{e}} en fran{\c{c}}ais L2. {\`{A}} cette fin, nous comparerons la production orale des apprenants avec celle des locuteurs natifs de fran{\c{c}}ais. Un trait du fran{\c{c}}ais parl{\'{e}} “spontan{\'{e}}” (L1) est la dissociation d'un certain nombre de constituants discursifs du rh{\`{e}}me, parmi ceux-ci des marqueurs du point de vue et des adverbes modalisateurs. Ces {\'{e}}l{\'{e}}ments devraient aussi {\^{e}}tre pr{\'{e}}sents dans le discours d'un apprenant avanc{\'{e}} de fran{\c{c}}ais. La question est ici de savoir de quelle fa{\c{c}}on la pr{\'{e}}sence et le placement d'un nombre d'{\'{e}}l{\'{e}}ments modaux dans la cha{\^{i}}ne parl{\'{e}}e diff{\`{e}}rent entre les deux groupes de locuteurs. Pour les marqueurs du point de vue, nos r{\'{e}}sultats indiquent que les apprenants en emploient moins fr{\'{e}}quemment, tandis que la plupart des adverbes modalisateurs sont aussi fr{\'{e}}quents, mais que leur placement diff{\`{e}}re de celui des locuteurs natifs. {\textcopyright} 2007, Cambridge University Press. Tous les droits sont r{\'{e}}serv{\'{e}}s.},
author = {Hancock, Victorine},
doi = {10.1017/S0959269506002638},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hancock/Hancock{\_}2007{\_}Quelques {\'{e}}l{\'{e}}ments modaux dissoci{\'{e}}s dans le paragraphe oral dans des interviews en fran{\c{c}}ais L2 et L1.pdf:pdf},
issn = {14740079},
journal = {Journal of French Language Studies},
number = {1},
pages = {21--47},
title = {{Quelques {\'{e}}l{\'{e}}ments modaux dissoci{\'{e}}s dans le paragraphe oral dans des interviews en fran{\c{c}}ais L2 et L1}},
volume = {17},
year = {2007}
}
@article{Benevento2011,
abstract = {Much of second language (L2) class time, particularly in school and university classes, is devoted to the teaching of writing, and written assignments form an important component of assessed work. We assume that learners' L2 writing develops over time, in response to instruction, feedback, and practice. However, to date there has been very little research to show whether all skills involved in producing a well-structured and grammatically accurate text develop uniformly and respond equally to pedagogy. Our longitudinal study explored development in writing among a group of secondary school learners of French (n= 15), in their final year of high school. Data for the study were three in-class essays written by the students at regular intervals over a period of six months. The essays were analysed for global quality as well as for grammatical accuracy and syntactic complexity using several quantitative and qualitative measures. Results showed improvements at the discourse level and in linguistic complexity, but there were no significant improvements in accuracy and certain frequent errors persisted. Results also showed that students continued to rely on prefabricated chunks learned in class, but the ability to use such chunks creatively improved over time. The research and pedagogical implications of these findings are discussed. {\textcopyright} 2011 Elsevier Ltd.},
author = {Benevento, Cathleen and Storch, Neomy},
doi = {10.1016/j.asw.2011.02.001},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Benevento, Storch/Benevento, Storch{\_}2011{\_}Investigating writing development in secondary school learners of French.pdf:pdf},
issn = {10752935},
journal = {Assessing Writing},
keywords = {French L2,L2 writing development,Measures of writing,Use of memorised chunks},
number = {2},
pages = {97--110},
publisher = {Elsevier Inc.},
title = {{Investigating writing development in secondary school learners of French}},
url = {http://dx.doi.org/10.1016/j.asw.2011.02.001},
volume = {16},
year = {2011}
}
@article{Zeileis2006a,
author = {Zeileis, Achim},
journal = {Computational Statistics {\&} Data Analysis},
pages = {2987--3008},
title = {{Implementing a Class of Structural Change Tests: An Econometric Computing Approach}},
volume = {50},
year = {2006}
}
@phdthesis{Hocsman2010,
annote = {L1 Arabic corpus (as in Chavez 2007)},
author = {Hocsman, Ana},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hocsman/Hocsman{\_}2010{\_}La d{\'{e}}marcation dans les {\'{e}}crits scientifiques Possibles classements notionnels des collocations transdisciplinaires.pdf:pdf},
school = {Universit{\'{e}} Stenhal Grenoble 3},
title = {{La d{\'{e}}marcation dans les {\'{e}}crits scientifiques Possibles classements notionnels des collocations transdisciplinaires comme aide {\`{a}} l'{\'{e}}crit universitaire aupr{\`{e}}s des {\'{e}}tudiants {\'{e}}trangers}},
type = {Master Thesis},
year = {2010}
}
@misc{Kolmogorov1965,
abstract = {There are two common approaches to the quantitative definition of "information": combinatorial and probabilistic. The author briefly describes the major features of these approaches and introduces a new algorithmic approach that uses the theory of recursive functions.},
author = {Kolmogorov, A. N.},
booktitle = {IEEE Transactions on Information Theory},
doi = {10.1080/00207166808803030},
issn = {0032-9460},
title = {{Three approaches to the definition of the concept of quantity of information}},
year = {1965}
}
@inproceedings{Kitaev2018,
abstract = {We demonstrate that replacing an LSTM encoder with a self-attentive architecture can lead to improvements to a state-of-the-art discriminative constituency parser. The use of attention makes explicit the manner in which information is propagated between different locations in the sentence, which we use to both analyze our model and propose potential improvements. For example, we find that separating positional and content information in the encoder can lead to improved parsing accuracy. Additionally, we evaluate different approaches for lexical representation. Our parser achieves new state-of-the-art results for single models trained on the Penn Treebank: 93.55 F1 without the use of any external data, and 95.13 F1 when using pre-trained word representations. Our parser also outperforms the previous best-published accuracy figures on 8 of the 9 languages in the SPMRL dataset.},
address = {Melbourne},
archivePrefix = {arXiv},
arxivId = {1805.01052},
author = {Kitaev, Nikita and Klein, Dan},
booktitle = {ACL},
doi = {10.1093/jmedent/24.6.609},
eprint = {1805.01052},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kitaev, Klein/Kitaev, Klein{\_}2018{\_}Constituency Parsing with a Self-Attentive Encoder.pdf:pdf},
isbn = {0022-2585},
issn = {00222585},
pmid = {3694625},
title = {{Constituency Parsing with a Self-Attentive Encoder}},
url = {http://arxiv.org/abs/1805.01052},
year = {2018}
}
@article{Jiang2019,
author = {Jiang, Jingyang and Bi, Peng and Liu, Haitao},
doi = {10.1016/j.jslw.2019.100666},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jiang, Bi, Liu/Jiang, Bi, Liu{\_}2019{\_}Journal of Second Language Writing Syntactic complexity development in the writings of EFL learners Insights from a.pdf:pdf},
issn = {1060-3743},
journal = {Journal of Second Language Writing},
keywords = {Beginner and intermediate learner,Dependency syntactic annotation,L2 English writing,Syntactic complexity,syntactic complexity},
publisher = {Elsevier},
title = {{Journal of Second Language Writing Syntactic complexity development in the writings of EFL learners : Insights from a dependency syntactically-annotated corpus}},
url = {https://doi.org/10.1016/j.jslw.2019.100666},
volume = {46},
year = {2019}
}
@manual{Wickham2020a,
annote = {R package version 2.3.1},
author = {Wickham, Hadley and Miller, Evan},
title = {{haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files}},
url = {https://cran.r-project.org/package=haven},
year = {2020}
}
@manual{Xie2019c,
annote = {R package version 1.24},
author = {Xie, Yihui},
title = {{knitr: A General-Purpose Package for Dynamic Report Generation in R}},
url = {https://yihui.name/knitr/},
year = {2019}
}
@article{Huang2018,
abstract = {{\textless}p{\textgreater}Current syntactic annotation of large-scale learner corpora mainly resorts to “standard parsers” trained on native language data. Understanding how these parsers perform on learner data is important for downstream research and application related to learner language. This study evaluates the performance of multiple standard probabilistic parsers on learner English. Our contributions are three-fold. Firstly, we demonstrate that the common practice of constructing a gold standard – by manually correcting the pre-annotation of a single parser – can introduce bias to parser evaluation. We propose an alternative annotation method which can control for the annotation bias. Secondly, we quantify the influence of learner errors on parsing errors, and identify the learner errors that impact on parsing most. Finally, we compare the performance of the parsers on learner English and native English. Our results have useful implications on how to select a standard parser for learner English.{\textless}/p{\textgreater}},
author = {Huang, Yan and Murakami, Akira and Alexopoulou, Theodora and Korhonen, Anna},
doi = {10.1075/ijcl.16080.hua},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Huang et al/Huang et al.{\_}2018{\_}Dependency parsing of learner English.pdf:pdf},
isbn = {8089565956},
issn = {1384-6655},
journal = {International Journal of Corpus Linguistics},
keywords = {annotation bias,dependency parsing,learner english,parsing accuracy},
number = {1},
pages = {28--54},
title = {{Dependency parsing of learner English}},
url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.16080.hua},
volume = {23},
year = {2018}
}
@book{Wickham2016,
author = {Wickham, Hadley},
isbn = {978-3-319-24277-4},
publisher = {Springer-Verlag New York},
title = {{ggplot2: Elegant Graphics for Data Analysis}},
url = {https://ggplot2.tidyverse.org},
year = {2016}
}
@incollection{Polio2011,
address = {London},
author = {Polio, Charlene},
booktitle = {The Routledge Handbook of Second Language Acquisition},
editor = {Gass, Susan M. and Mackey, Alison},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Polio/Polio{\_}2011{\_}The acquisition of second language writing.pdf:pdf},
pages = {319--334},
publisher = {Routledge},
title = {{The acquisition of second language writing}},
year = {2011}
}
@manual{Chang2012,
annote = {R package version 1.0},
author = {Chang, Winston},
title = {{extrafontdb: Package for holding the database for the extrafont package}},
url = {https://cran.r-project.org/package=extrafontdb},
year = {2012}
}
@misc{Gregoire2018,
author = {Gr{\'{e}}goire},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gr{\'{e}}goire/Gr{\'{e}}goire{\_}2018{\_}POS Taggers for French Petite {\'{e}}tude de POS taggers pour le fran{\c{c}}ais.pdf:pdf},
pages = {10--11},
title = {{POS Taggers for French: Petite {\'{e}}tude de POS taggers pour le fran{\c{c}}ais}},
url = {http://french-postaggers.tiddlyspot.com/},
year = {2018}
}
@article{checkmate,
author = {Lang, Michel},
journal = {The R Journal},
number = {1},
pages = {437--445},
title = {{{\{}checkmate{\}}: Fast Argument Checks for Defensive R Programming}},
url = {https://journal.r-project.org/archive/2017/RJ-2017-028/index.html},
volume = {9},
year = {2017}
}
@article{Myles1999,
abstract = {This paper explores the relationship between formulaic language and creative construction in SLA by examining the production of interroga- tives in an extensive naturalistic corpus of L2 French produced by early classroom learners. The paper first analyzes the production and breakdown of such formulaic language over time, before exploring the development of more creative structures. The interaction between the two processes “rote learning of formulas and creative construc- tion” is then investigated. This interaction is shown to be a dynamic two-way process, with learners being driven forward in the develop- ment of their L2 system by their attempts to resolve the tension be- tween structurally complex but communicatively rich formulas on the one hand, and structurally simple but communicatively inadequate creative structures on the other hand.},
author = {Myles, Florence and Mitchell, Rosamond and Hooper, Janet},
doi = {10.1017/S0272263199001023},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Myles, Mitchell, Hooper/Myles, Mitchell, Hooper{\_}1999{\_}Interrogative chunks in French L2 A basis for creative construction.pdf:pdf},
isbn = {0272-2631},
issn = {0272-2631},
journal = {Studies in Second Language Acquisition},
pages = {49--80},
title = {{Interrogative chunks in French L2: A basis for creative construction}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:INTERROGATIVE+CHUNKS+IN+FRENCH:+L2+A+Basis+for+Creative+Construction?{\#}1},
volume = {21},
year = {1999}
}
@article{Gala2014,
abstract = {Analyser la complexit{\{}{\'{e}}{\}} lexicale est une t{\{}{\^{a}}{\}}che qui, depuis toujours, a principalement retenu l'attention de psycholinguistes et d'enseignants de langues. Plus r{\{}{\'{e}}{\}}cemment, cette probl{\{}{\'{e}}{\}}matique a fait l'objet d'un int{\{}{\'{e}}{\}}r{\{}{\^{e}}{\}}t grandissant dans le domaine du traitement automatique des langues (TAL) et, en particulier, en simplification automatique de textes. L'objectif de cette t{\{}{\^{a}}{\}}che est d'identifier des termes et des structures difficiles {\{}{\`{a}}{\}} comprendre par un public cible et de proposer des outils de simplification automatis{\{}{\'{e}}{\}}e de ces contenus. Cet article aborde la question lexicale en identifiant un ensemble de pr{\{}{\'{e}}{\}}dicteurs de la complexit{\{}{\'{e}}{\}} lexicale et en {\{}{\'{e}}{\}}valuant leur efficacit{\{}{\'{e}}{\}} via une analyse corr{\{}{\'{e}}{\}}lationnelle. Les meilleures de ces variables ont {\{}{\'{e}}{\}}t{\{}{\'{e}}{\}} int{\{}{\'{e}}{\}}gr{\{}{\'{e}}{\}}es dans un mod{\{}{\`{e}}{\}}le capable de pr{\{}{\'{e}}{\}}dire la difficult{\{}{\'{e}}{\}} lexicale dans un contexte d'apprentissage du fran{\{}{\c{c}}{\}}ais.},
author = {Gala, N{\'{u}}ria and Fran{\c{c}}ois, Thomas and Bernhard, Delphine and Fairon, C{\'{e}}drick},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gala et al/Gala et al.{\_}2014{\_}Un mod{\`{e}}le pour pr{\'{e}}dire la complexit{\'{e}} lexicale et graduer les mots Mots-cl{\'{e}}s Keywords.pdf:pdf},
journal = {Traitement Automatique des Langues Naturelles},
number = {1},
pages = {91--102},
title = {{Un mod{\`{e}}le pour pr{\'{e}}dire la complexit{\'{e}} lexicale et graduer les mots Mots-cl{\'{e}}s : Keywords :}},
volume = {2},
year = {2014}
}
@manual{Michalke2017,
annote = {(Version 0.1-2)},
author = {Michalke, Meik},
title = {{sylly.fr: Language Support for 'sylly' Package: French}},
url = {http://reaktanz.de/?c=hacking{\&}s=koRpus},
year = {2017}
}
@article{Arvidsson,
author = {Arvidsson, Klara},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Arvidsson/Arvidsson{\_}Unknown{\_}Learning multiword expressions in a second language during study abroad – the role of individual differences.pdf:pdf},
journal = {IN PRESS},
title = {{Learning multiword expressions in a second language during study abroad – the role of individual differences}}
}
@article{Allaw2019a,
abstract = {Learner corpora provide researchers with a rich pool of resources that can complement experimental studies. The purpose of the present paper is to provide task complexity researchers, for the first time, with further insight regarding interactive effects of task complexity, task type, task modality, and L1 background on linguistic and propositional complexity. Analyzing 720 intermediate-level (B1) written texts that were extracted from open access online language learning platform, the EF-Cambridge Open Language Database (EFCAMDAT) revealed that there was a significant interaction effect among task design features (task complexity, task type, and L1 background) that influenced linguistic and propositional complexity of written texts. This suggests that task complexity does not function in isolation of other task design features such as task type and L1 background.},
author = {Allaw, Elissa},
doi = {10.1515/iral-2018-0294},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Allaw/Allaw{\_}2019{\_}A learner corpus analysis Effects of task complexity, task type, and L1 {\&} L2 similarity on propositional and linguistic compl.pdf:pdf},
issn = {16134141},
journal = {International Review of Applied Linguistics in Language Teaching},
keywords = {L1 background,linguistic complexity,propositional complexity,task complexity,task type},
number = {[Advance of publication]},
pages = {1--36},
title = {{A learner corpus analysis: Effects of task complexity, task type, and L1 {\&} L2 similarity on propositional and linguistic complexity}},
year = {2019}
}
@manual{Hester2019,
annote = {R package version 2.1.0},
author = {Hester, Jim and Cs{\'{a}}rdi, G{\'{a}}bor and Wickham, Hadley and Chang, Winston and Morgan, Martin and Tenenbaum, Dan},
title = {{remotes: R Package Installation from Remote Repositories, Including 'GitHub'}},
url = {https://cran.r-project.org/package=remotes},
year = {2019}
}
@article{Crossley2017,
abstract = {• Background: Researchers have been working towards better understanding differences in professional disciplinary writing (e.g., Ewer {\&} Latorre, 1969; Hu {\&} Cao, 2015; Hyland, 2002; Hyland {\&} Tse, 2007) for decades. Recently, research has taken important steps towards understanding disciplinary variation in student writing. Much of this research is corpus-based and focuses on lexico-grammatical features in student writing as captured in the British Academic Written English (BAWE) corpus and the Michigan Corpus of Upper-level Student Papers (MICUSP). The present study extends this work by analyzing lexical and cohesion differences among disciplines in MICUSP. Critically, we analyze not only linguistic differences in macro-disciplines (science and engineering), but also in micro-disciplines within these macro-disciplines (biology, physics, industrial engineering, and mechanical engineering). • Literature Review: Hardy and R{\"{o}}mer (2013) used a multidimensional analysis to investigate linguistic differences across four macro-disciplines represented in MICUSP. Durrant (2014, in press) analyzed vocabulary in texts produced by student writers in the BAWE corpus by discipline and level (year) and disciplinary differences in lexical bundles. Ward (2007) examined lexical differences within micro-disciplines of a single discipline. • Research Questions: The research questions that guide this study are as follows: 1. Are there significant lexical and cohesive differences between science and engineering student writing? 2. Are there significant lexical and cohesive differences between micro-disciplines within science and engineering student writing? • Research Methodology: To address the research questions, student-produced science and engineering texts from MICUSP were analyzed with regard to lexical sophistication and textual features of cohesion. Specifically, 22 indices of lexical sophistication calculated by the Tool for the Automatic Analysis of Lexical Sophistication (TAALES; Kyle {\&} Crossley, 2015) and 38 cohesion indices calculated by the Tool for the Automatic Analysis of Cohesion (TAACO; Crossley, Kyle, {\&} McNamara, 2016) were used. These features were then compared both across science and engineering texts (addressing Research Question 1) and across micro-disciplines within science and engineering (biology and physics, industrial and mechanical engineering) using discriminate function analyses (DFA). • Results: The DFAs revealed significant linguistic differences, not only between student writing in the two macro-disciplines but also between the micro-disciplines. Differences in classification accuracy based on students' years of study hovered at about 10{\%}. An analysis of accuracies of classification by paper type found they were similar for larger and smaller sample sizes, providing some indication that paper type was not a confounding variable in classification accuracy. • Discussion: The findings provide strong support that macro-disciplinary and micro-disciplinary differences exist in student writing in these MICUSP samples and that these differences are likely not related to student level or paper type. These findings have important implications for understanding disciplinary differences. First, they confirm previous research that found the vocabulary used by different macro-disciplines to be “strikingly diverse” (Durrant, 2015), but they also show a remarkable diversity of cohesion features. The findings suggest that the common understanding of the STEM disciplines as “close” bears reconsideration in linguistic terms. Second, the lexical and cohesion differences between micro-disciplines are large enough and consistent enough to suggest that each micro-discipline can be thought of as containing a unique linguistic profile of features. Third, the differences discerned in the NLP analysis are evident at least as early as the final year of undergraduate study, suggesting that students at this level already have a solid understanding of the conventions of the disciplines of which they are aspiring to be members. Moreover, the differences are relatively homogeneous across levels, which confirms findings by Durrant (2015) but, importantly, extends these findings to include cohesion markers. • Conclusions: The findings from this study provide evidence that macro-disciplinary and micro-disciplinary differences at the linguistic level exist in student writing, not only in lexical use but also in text cohesion. A number of pedagogical applications of writing analytics are proposed based on the reported findings from TAALES and TAACO. Further studies using different corpora (e.g., BAWE) or purpose assembled corpora are suggested to address limitations in the size and range of text types found within MICUSP. This study also points the way toward studies of disciplinary differences using NLP approaches that capture data which goes beyond the lexical and cohesive features of text, including the use of part-of-speech tags, syntactic parsing, indices related to syntactic complexity and similarity, rhetorical features, or more advanced cohesion metrics (latent semantic analysis, latent Dirichlet allocation, Word2Vec approaches).},
author = {Crossley, Scott A. and Russell, David and Kyle, Kristopher and R{\"{o}}mer, Ute},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley et al/Crossley et al.{\_}2017{\_}Applying natural language processing tools to a student academic writing corpus How large are disciplinary differen.pdf:pdf},
journal = {Journal of Writing Analytics},
pages = {48--81},
title = {{Applying natural language processing tools to a student academic writing corpus: How large are disciplinary differences across science and engineering fields?}},
url = {https://journals.colostate.edu/analytics/article/view/2},
volume = {1},
year = {2017}
}
@incollection{Crossley2013,
abstract = {Language researchers and practitioners often adopt tools and techniques without testing whether they really work as they should. This is understandable because most scholars do not have the time or expertise to properly evaluate the usefulness of all instruments, measures, and methods they need. It is therefore critical to have problem solvers in the field who gain the necessary expertise and take the time to scrutinize existing methods, identify problems, and offer new solutions. This volume represents the work of scholars who have done this; it is a collection of the latest advances, developments, and innovations regarding the modeling and measurement of learners' vocabulary growth curves, current levels of vocabulary knowledge and lexical proficiency, and the patterns of lexical diversity found in their language production. Several of the contributors also address the complex but important relationship between automated indices and human judgments of learners' lexical patterns and abilities.},
address = {Amsterdam},
author = {Crossley, Scott A. and Salsbury, Tom and McNamara, Danielle S.},
booktitle = {Vocabulary Knowledge : Human Ratings and Automated Measures},
doi = {10.1075/sibil.47.06ch4},
editor = {Jarvis, Scott and Daller, Michael},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley, Salsbury, McNamara/Crossley, Salsbury, McNamara{\_}2013{\_}Validating lexical measures using human scores of lexical proficiency.pdf:pdf},
pages = {105--134},
publisher = {John Benjamins},
title = {{Validating lexical measures using human scores of lexical proficiency}},
year = {2013}
}
@techreport{Gelman,
author = {Gelman, Andrew and Loken, Eric},
doi = {10.7135/upo9781843313649.011},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gelman, Loken/Gelman, Loken{\_}Unknown{\_}The garden of forking paths Why multiple comparisons can be a problem, even when there is no “fishing expe.pdf:pdf},
issn = {10867058},
title = {{The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time}}
}
@article{Bates2015,
author = {Bates, Douglas and M{\"{a}}chler, Martin and Bolker, Ben and Walker, Steve},
doi = {10.18637/jss.v067.i01},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--48},
title = {{Fitting Linear Mixed-Effects Models Using {\{}lme4{\}}}},
volume = {67},
year = {2015}
}
@article{Benzitoun2016,
author = {Benzitoun, Christophe and Debaisieux, Jeanne-Marie and Deulofeu, Henri-Jos{\'{e}}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Benzitoun, Debaisieux, Deulofeu/Benzitoun, Debaisieux, Deulofeu{\_}2016{\_}Le projet ORF{\'{E}}O un corpus d'{\'{e}}tude pour le fran{\c{c}}ais contemporain.pdf:pdf},
journal = {Corpus},
title = {{Le projet ORF{\'{E}}O : un corpus d'{\'{e}}tude pour le fran{\c{c}}ais contemporain}},
volume = {15},
year = {2016}
}
@article{Hothorn2008,
author = {Hothorn, Torsten and Bretz, Frank and Westfall, Peter},
journal = {Biometrical Journal},
number = {3},
pages = {346--363},
title = {{Simultaneous Inference in General Parametric Models}},
volume = {50},
year = {2008}
}
@article{Scrucca2004,
author = {Scrucca, Luca},
journal = {R News},
pages = {11--17},
title = {{qcc: an R package for quality control charting and statistical process control}},
url = {https://cran.r-project.org/doc/Rnews/},
volume = {4/1},
year = {2004}
}
@phdthesis{Chavez2008,
annote = {L1 Arabic corpus 300k words 
- rapports de stage, memoires et these 
- sciences appliquees, exactes, humaines 

Mrou{\'{e}} et Bard (2007) -- ref missing from bibliography},
author = {Chavez, Ingrid},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Chavez/Chavez{\_}2008{\_}La d{\'{e}}marcation dans les {\'{e}}crits scientifiques Les collocations transdisciplinaires comme aide {\`{a}} l'{\'{e}}crit universitai.pdf:pdf},
pages = {1--81},
school = {Universit{\'{e}} Stendhal Grenoble 3},
title = {{La d{\'{e}}marcation dans les {\'{e}}crits scientifiques : Les collocations transdisciplinaires comme aide {\`{a}} l'{\'{e}}crit universitaire aupr{\`{e}}s des {\'{e}}tudiants {\'{e}}trangers}},
type = {Master Thesis},
year = {2008}
}
@book{python,
address = {Scotts Valley, CA},
author = {{Van Rossum}, G. and Drake, F. L},
publisher = {CreateSpace},
title = {{Python 3 Reference Manual}},
year = {2009}
}
@inproceedings{Catherine2015,
address = {Lyon},
author = {Catherine, Anne},
booktitle = {ICODOC},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Catherine/Catherine{\_}2015{\_}Prosodie , discours et linguistique sur corpus . De quelques pratiques m{\'{e}}thodologiques De quelques int{\'{e}}r{\^{e}}ts de recherc.pdf:pdf},
month = {may},
title = {{Prosodie , discours et linguistique sur corpus . De quelques pratiques m{\'{e}}thodologiques De quelques int{\'{e}}r{\^{e}}ts de recherche}},
year = {2015}
}
@manual{Gohel2020d,
annote = {R package version 0.5.10},
author = {Gohel, David},
title = {{flextable: Functions for Tabular Reporting}},
url = {https://cran.r-project.org/package=flextable},
year = {2020}
}
@article{Bartning2015a,
abstract = {This article examines linguistic complexity in the noun phrase in spoken L1 and L2 French. Research on linguistic complexity in L2 has often concentrated on syntactic complexity, subordination in particular. In this study, we focus on syntactic complexity at the phrasal level, i.e. in the noun phrase, following the assumption put forward by Norris and Ortega (2009: 564) that internal NP complexity provides an important measure of very advanced learners. The present study examines pre- and post-modification in the noun phrase in the oral production of very advanced non-native speakers (NNS) and native speakers (NS) elicited through an on-line retelling of a clip from Modern Times. The results confirm our main hypothesis, that there are differences between NS and NNS: NS use more complex NPs, NPs with a higher mean number of words and more NPs with multiple modifiers.},
author = {Bartning, Inge and Arvidsson, Klara and {Forsberg Lundell}, Fanny},
doi = {10.1075/lia.6.2.01bar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Arvidsson, Forsberg Lundell/Bartning, Arvidsson, Forsberg Lundell{\_}2015{\_}Complexity at the phrasal level in spoken L1 and very advanced L2 French.pdf:pdf},
issn = {1879-7865},
journal = {Language, Interaction and Acquisition},
keywords = {advanced l2 french,high level proficiency,linguistic,noun phrase,on-line spoken production,syntactic complexity},
number = {2},
pages = {181--201},
title = {{Complexity at the phrasal level in spoken L1 and very advanced L2 French}},
volume = {6},
year = {2015}
}
@techreport{Dirdal2016,
address = {Oslo},
author = {Dirdal, Hildegunn},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dirdal/Dirdal{\_}2016{\_}Development of L2 writing complexity Clause types , L1 influence and individual differences.pdf:pdf},
institution = {University of Oslow},
title = {{Development of L2 writing complexity : Clause types , L1 influence and individual differences}},
url = {https://www.hf.uio.no/ilos/english/research/projects/idiomaticity/events/dirdal{\_}2019.html},
year = {2016}
}
@article{Zeileis2007,
author = {Zeileis, Achim and Meyer, David and Hornik, Kurt},
journal = {Journal of Computational and Graphical Statistics},
number = {3},
pages = {507--525},
title = {{Residual-based Shadings for Visualizing (Conditional) Independence}},
volume = {16},
year = {2007}
}
@book{Malvern2004,
address = {Basingstoke},
author = {Malvern, D and Richards, B and Chipere, N and Puran, P},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Malvern et al/Malvern et al.{\_}2004{\_}Lexical diversity and language development quantitative and assessment.pdf:pdf},
isbn = {2003070656},
pages = {30--32},
publisher = {Palgrave Macmilan},
title = {{Lexical diversity and language development: quantitative and assessment}},
year = {2004}
}
@manual{Vu2011,
annote = {R package version 0.55},
author = {Vu, Vincent Q},
title = {{ggbiplot: A ggplot2 based biplot}},
url = {http://github.com/vqv/ggbiplot},
year = {2011}
}
@manual{Michalke2018b,
annote = {(Version 0.1-5)},
author = {Michalke, Meik},
title = {{sylly: Hyphenation and Syllable Counting for Text Analysis}},
url = {https://reaktanz.de/?c=hacking{\&}s=sylly},
year = {2018}
}
@manual{Wickham2019g,
annote = {R package version 0.14},
author = {Wickham, Hadley and Xie, Yihui},
title = {{evaluate: Parsing and Evaluation Tools that Provide More Details than the Default}},
url = {https://cran.r-project.org/package=evaluate},
year = {2019}
}
@article{Arvidsson2016,
author = {Arvidsson, Klara},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Arvidsson/Arvidsson{\_}2016{\_}R{\'{e}}seaux sociaux et d{\'{e}}veloppement linguistique – Une {\'{e}}tude de cas en fran{\c{c}}ais L2.pdf:pdf},
journal = {IN PRESS},
title = {{R{\'{e}}seaux sociaux et d{\'{e}}veloppement linguistique – Une {\'{e}}tude de cas en fran{\c{c}}ais L2}},
year = {2016}
}
@inproceedings{Housen2006,
address = {Paris},
author = {Housen, Alex and Kemps, Nancy and Pierrard, Michel},
booktitle = {Actes du colloque international "Recherches en acquisition et en didactique des langues étrangères et secondes"},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Housen, Kemps, Pierrard/Housen, Kemps, Pierrard{\_}2006{\_}Le d{\'{e}}veloppement de la morphologie verbale chez les apprenants avanc{\'{e}}s de FLE apports et limites du conte.pdf:pdf},
issn = {0771-6524},
keywords = {linguistics,sociology},
month = {sep},
pages = {273--293},
title = {{Le d{\'{e}}veloppement de la morphologie verbale chez les apprenants avanc{\'{e}}s de FLE: apports et limites du contexte instructionnel}},
year = {2006}
}
@article{Jakubicek2013,
abstract = {Masaryk University (Brno, Czech Republic)},
author = {Jakub{\'{i}}{\v{c}}ek, Milo{\v{s}} and Kilgarriff, Adam and Kov{\'{a}}ř, Vojt{\v{e}}ch and Rychl{\'{y}}, Pavel and Suchomel, V{\'{i}}t},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jakub{\'{i}}{\v{c}}ek et al/Jakub{\'{i}}{\v{c}}ek et al.{\_}2013{\_}The TenTen Corpus Family.pdf:pdf},
journal = {7th International Corpus Linguistics Conference},
pages = {125--127},
title = {{The TenTen Corpus Family}},
url = {https://www.sketchengine.co.uk/wp-content/uploads/The{\_}TenTen{\_}Corpus{\_}2013.pdf{\%}5Cnhttp://ucrel.lancs.ac.uk/cl2013/doc/CL2013-ABSTRACT-BOOK.pdf},
year = {2013}
}
@book{IMBS1971,
address = {Nancy},
author = {IMBS, Paul},
publisher = {CNRS-Didier},
title = {{Dictionnaire des fr{\'{e}}quences: Vocabulaire litt{\'{e}}raire des XIXe et XXe si{\`{e}}cles. I - Table alphab{\'{e}}tique}},
year = {1971}
}
@manual{Hothorn2018,
annote = {R package version 0.2-22},
author = {Hothorn, Torsten and Leisch, Friedrich and Zeileis, Achim},
title = {{modeltools: Tools and Classes for Statistical Models}},
url = {https://cran.r-project.org/package=modeltools},
year = {2018}
}
@article{Francois2014,
abstract = {In this paper we present FLELex, the first graded lexicon for French as a foreign language (FFL) that reports word frequencies by difficulty level (according to the CEFR scale). It has been obtained from a tagged corpus of 777, 000 words from available textbooks and simplified readers intended for FFL learners. Our goal is to freely provide this resource to the community to be used for a variety of purposes going from the assessment of the lexical difficulty of a text, to the selection of simpler words within text simplification systems, and also as a dictionary in assistive tools for writing.},
author = {Fran{\c{c}}ois, T. and Gala, N. and Watrin, P. and Fairon, C.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Fran{\c{c}}ois et al/Fran{\c{c}}ois et al.{\_}2014{\_}FLELex A graded lexical resource for French foreign learners(2).pdf:pdf},
isbn = {9782951740884},
journal = {Proceedings of the 9th International Conference on Language Resources and Evaluation, LREC 2014},
keywords = {CALL,FFL vocabulary learning,Graded lexicon},
number = {1},
pages = {3766--3773},
title = {{FLELex: A graded lexical resource for French foreign learners}},
year = {2014}
}
@inproceedings{Straka2016,
abstract = {Automatic natural language processing of large texts often presents recurring challenges in multiple languages: even for most advanced tasks, the texts are first processed by basic processing steps-from tokenization to parsing. We present an extremely simple-to-use tool consisting of one binary and one model (per language), which performs these tasks for multiple languages without the need for any other external data. UDPipe, a pipeline processing CoNLL-U-formatted files, performs tokenization, morphological analysis, part-of-speech tagging, lemmatization and dependency parsing for nearly all treebanks of Universal Dependencies 1.2 (namely, the whole pipeline is currently available for 32 out of 37 treebanks). In addition, the pipeline is easily trainable with training data in CoNLL-U format (and in some cases also with additional raw corpora) and requires minimal linguistic knowledge on the users' part. The training code is also released.},
author = {Straka, Milan and Haji{\v{c}}, Jan and Strakov{\'{a}}, Jana},
booktitle = {LREC},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Straka, Haji{\v{c}}, Strakov{\'{a}}/Straka, Haji{\v{c}}, Strakov{\'{a}}{\_}2016{\_}UDPipe Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, P.pdf:pdf},
keywords = {()},
title = {{UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing}},
url = {http://hdl.handle.net/11234/1-1548},
year = {2016}
}
@manual{Rinker2018a,
address = {Buffalo, New York},
annote = {version 1.2.1},
author = {Rinker, Tyler W},
title = {{{\{}lexicon{\}}: Lexicon Data}},
url = {http://github.com/trinker/lexicon},
year = {2018}
}
@manual{Champely2020,
annote = {R package version 1.3-0},
author = {Champely, Stephane},
title = {{pwr: Basic Functions for Power Analysis}},
url = {https://cran.r-project.org/package=pwr},
year = {2020}
}
@article{Monteiro2018,
author = {Monteiro, K{\'{a}}tia R. and Crossley, Scott A. and Kyle, Kristopher},
doi = {10.1093/applin/amy056},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Monteiro, Crossley, Kyle/Monteiro, Crossley, Kyle{\_}2018{\_}In Search of New Benchmarks Using L2 Lexical Frequency and Contextual Diversity Indices to Assess Second.pdf:pdf},
journal = {Applied Linguistics},
pages = {1--22},
title = {{In Search of New Benchmarks : Using L2 Lexical Frequency and Contextual Diversity Indices to Assess Second Language Writing}},
year = {2018}
}
@book{Fagyal2006,
address = {Cambridge},
author = {Fagyal, Zsuzsanna and Kibbee, Douglas and Jenkins, Fred},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Fagyal, Kibbee, Jenkins/Fagyal, Kibbee, Jenkins{\_}2006{\_}French A linguistic introduction.pdf:pdf},
isbn = {9780521821445},
publisher = {Cambridge University Press},
title = {{French: A linguistic introduction}},
year = {2006}
}
@manual{Ripley2019,
annote = {R package version 1.0-40},
author = {Ripley, Brian},
title = {{tree: Classification and Regression Trees}},
url = {https://cran.r-project.org/package=tree},
year = {2019}
}
@article{Ming2019,
author = {Ming, Huei Lin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ming/Ming{\_}2019{\_}Correlations of English Writing Complexity, Accuracy, Fluency and test Scores A case study of standardized writing test sample.pdf:pdf},
journal = {The Journal of Teaching English for Specific and Academic Purposes},
keywords = {accuracy,and fluency,efl writing,lacm,model,the limited attentional capacity,writing complexity},
number = {2},
pages = {199--210},
title = {{Correlations of English Writing Complexity, Accuracy, Fluency and test Scores: A case study of standardized writing test samples}},
volume = {7},
year = {2019}
}
@article{Ooms2014,
author = {Ooms, Jeroen},
journal = {arXiv:1403.2805 [stat.CO]},
title = {{The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects}},
url = {https://arxiv.org/abs/1403.2805},
year = {2014}
}
@manual{Wickham2019q,
annote = {R package version 0.8.3},
author = {Wickham, Hadley and Fran{\c{c}}ois, Romain and Henry, Lionel and M{\"{u}}ller, Kirill},
title = {{dplyr: A Grammar of Data Manipulation}},
url = {https://cran.r-project.org/package=dplyr},
year = {2019}
}
@article{Wood2016,
author = {Wood, S N and N. and Pya and S"afken, B},
journal = {Journal of the American Statistical Association},
pages = {1548--1575},
title = {{Smoothing parameter and model selection for general smooth models (with discussion)}},
volume = {111},
year = {2016}
}
@article{Eddelbuettel2011,
author = {Eddelbuettel, Dirk and Fran{\c{c}}ois, Romain},
doi = {10.18637/jss.v040.i08},
journal = {Journal of Statistical Software},
number = {8},
pages = {1--18},
title = {{{\{}Rcpp{\}}: Seamless {\{}R{\}} and {\{}C++{\}} Integration}},
url = {http://www.jstatsoft.org/v40/i08/},
volume = {40},
year = {2011}
}
@incollection{Bulte2020,
author = {Bult{\'{e}}, Bram and Housen, Alex},
booktitle = {Complex Dynamic Systems Theory and L2 Writing Development},
chapter = {9},
doi = {10.1075/lllt.54.09bul},
editor = {Fogal, Gary G. and Verspoor, Marjolijn H.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}}, Housen/Bult{\'{e}}, Housen{\_}2020{\_}A critical appraisal of the CDST approach to investigating linguistic complexity in L2 writing development.pdf:pdf},
pages = {207--238},
publisher = {John Benjamins},
title = {{A critical appraisal of the CDST approach to investigating linguistic complexity in L2 writing development}},
year = {2020}
}
@article{Brezina2019,
author = {Brezina, Vaclav and Pallotti, Gabriele},
doi = {10.1177/0267658316643125},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Brezina, Pallotti/Brezina, Pallotti{\_}2019{\_}Morphological complexity in written L2 texts.pdf:pdf},
journal = {Second Language Research [Special Issue on Linguistic Complexity]},
number = {1},
pages = {99--119},
title = {{Morphological complexity in written L2 texts}},
volume = {35},
year = {2019}
}
@techreport{Biber2013,
abstract = {One of the major innovations of the TOEFL iBT{\textregistered} test is the incorporation of integrated tasks complementing the independent tasks to which examinees respond. In addition, examinees must produce discourse in both modes (speech and writing). The validity argument for the TOEFL iBT includes the claim that examinees vary their discourse in accordance with these considerations as they become more proficient in their academic language skills (the explanation inference). To provide evidence in support of this warrant, we undertake a comprehensive lexico-grammatical description of the discourse produced in response to integrated versus independent tasks, across the spoken and written modes, by test takers from different score levels. Discourse descriptions at several linguistic levels are provided, including vocabulary profiles, collocational patterns, the use of extended lexical bundles, distinctive lexico- grammatical features, and a multidimensional (MD) analysis that describes the overall patterns of linguistic variation. In sum, we undertake a comprehensive linguistic analysis of the discourse of TOEFL iBT responses, interpreting observed linguistic patterns of variation relative to three parameters that are relevant in the TOEFL iBT context: mode, task type, and score level of test takers. Key},
author = {Biber, Douglas and Gray, Bethany},
booktitle = {Toefl iBT{\textregistered} Research Report (TOEFL iBT-19)},
doi = {10.1002/j.2333-8504.2013.tb02311.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Biber, Gray/Biber, Gray{\_}2013{\_}Discourse Characteristics of Writing and Speaking Task Types on the Toefl iBT {\textregistered} Test a Lexico-Grammatical Analysis.pdf:pdf},
institution = {Educational Testing Service},
issn = {2330-8516},
keywords = {grammatical variation,multi-dimensional analysis,proficiency levels,spoken/written differences,task variation,vocabulary},
title = {{Discourse Characteristics of Writing and Speaking Task Types on the Toefl iBT {\textregistered} Test: a Lexico-Grammatical Analysis}},
year = {2013}
}
@manual{Lang2019a,
annote = {R package version 3.98-1.20},
author = {Lang, Duncan Temple and {the CRAN Team}},
title = {{XML: Tools for Parsing and Generating XML Within R and S-Plus}},
url = {https://cran.r-project.org/package=XML},
year = {2019}
}
@manual{Muller2019,
annote = {R package version 1.4.2},
author = {M{\"{u}}ller, Kirill and Wickham, Hadley},
title = {{pillar: Coloured Formatting for Columns}},
url = {https://cran.r-project.org/package=pillar},
year = {2019}
}
@article{Stengers2011,
abstract = {This paper investigates the extent to which productive use of formulaic sequences by intermediate students of two typologically different languages, i.e., English and Spanish, is associated with their oral proficiency in these languages. Previous research (e.g., Boers et al. 2006) has shown that appropriate use of formulaic sequences helps learners of English come across as fluent and idiomatic speakers. The evidence from the present study, which was conducted with the participation of Dutch-speaking students of English and Spanish, confirms that finding, as oral proficiency assessments based on re-tell tasks correlated positively with the number of formulaic sequences the students used in these tasks. The correlations were strongest in the English language samples, however. It seems that the greater incidence of morphological-inflectional errors in our participants' spoken Spanish dampens the contribution that using formulaic sequences tends to make to their oral proficiency (as perceived by our assessors). The findings are discussed with reference to typological differences between L1 and L2.},
author = {Stengers, Helene and Boers, Frank and Housen, Alex and Eyckmans, June},
doi = {10.1515/iral.2011.017},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Stengers et al/Stengers et al.{\_}2011{\_}Formulaic sequences and L2 oral proficiency Does the type of target language influence the association.pdf:pdf},
isbn = {0019-042X},
issn = {0019042X},
journal = {International Review of Applied Linguistics in Language Teaching},
pages = {321--343},
title = {{Formulaic sequences and L2 oral proficiency: Does the type of target language influence the association?}},
volume = {49},
year = {2011}
}
@article{Tidball2008,
abstract = {In this paper we study different aspects of lexical richness in narratives of British learners of French. In particular we focus on different ways of measuring lexical sophistication. We compare the power of three different operationalisations of the Advanced Guiraud (AG) (Daller, van Hout and Treffers-Daller, 2003): one based on teacher judgement, one on 'le fran{\c{c}}ais fondamental I er degr{\'{e}}' and one on frequency of lexical items. The results show that teacher judgement is a highly reliable tool for assessing lexical sophistication. The AG based on teacher judgements is better able to discriminate between the groups than the other operationalisations. It also works better than Vocabprofil (the French version of Laufer and Nation's (1995) Lexical Frequency Profile). {\textcopyright} Cambridge University Press 2008.},
author = {Tidball, Fran{\c{c}}oise and Treffers-Daller, Jeanine},
doi = {10.1017/S0959269508003463},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Tidball, Treffers-Daller/Tidball, Treffers-Daller{\_}2008{\_}Analysing lexical richness in French learner language What frequency lists and teacher judgements can tell.pdf:pdf},
isbn = {0959269508003},
issn = {09592695},
journal = {Journal of French Language Studies},
number = {3},
pages = {299--313},
title = {{Analysing lexical richness in French learner language: What frequency lists and teacher judgements can tell us about basic and advanced words}},
volume = {18},
year = {2008}
}
@manual{Fox2018a,
annote = {R package version 3.0-2},
author = {Fox, John and Weisberg, Sanford and Price, Brad},
title = {{carData: Companion to Applied Regression Data Sets}},
url = {https://cran.r-project.org/package=carData},
year = {2018}
}
@article{Mcmanus,
author = {Mcmanus, Kevin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mcmanus/Mcmanus{\_}Unknown{\_}Relationships between social networds and language development during study abroad.pdf:pdf},
journal = {Language Culture and Curriculum (IN PRESS)},
title = {{Relationships between social networds and language development during study abroad}}
}
@article{Kyle2018,
abstract = {{\textcopyright} 2018 by The Modern Language Journal. Syntactic complexity is an important measure of second language (L2) writing proficiency (Larsen-Freeman, 1978; Lu, 2011). Large-grained indices such as the mean length of T-unit (MLTU) have been used with the most consistency in L2 writing studies (Ortega, 2003). Recently, indices such as MLTU have been criticized, both for the difficulty in interpretation (e.g., Norris  {\&}  Ortega, 2009) and for a potentially misplaced focus on clausal subordination (e.g., Biber, Gray,  {\&}  Poonpon, 2011). In this article, we attempt to address both of these criticisms by using traditional indices of syntactic complexity (e.g., MLTU), fine-grained indices of clausal complexity, and fine-grained indices of phrasal complexity to predict holistic scores of writing quality. In 4 studies, we used indices of each index type to predict holistic writing quality scores in independent essays on the Test of English as a Foreign Language (TOEFL). We then used all index types in a combined analysis to predict a holistic writing score. The results indicated that fine-grained indices of phrasal complexity were better predictors of writing quality than either traditional or fine-grained clausal indices, though a single fine-grained index of clausal complexity contributed to the combined model. These results provide some support for Biber et al.'s (2011) claims regarding complexity and academic L2 writing proficiency.},
author = {Kyle, Kristopher and Crossley, Scott A.},
doi = {10.1111/modl.12468},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kyle, Crossley/Kyle, Crossley{\_}2018{\_}Measuring Syntactic Complexity in L2 Writing Using Fine-Grained Clausal and Phrasal Indices.pdf:pdf},
isbn = {0072881380},
issn = {15404781},
journal = {Modern Language Journal},
keywords = {L2 writing,assessment,natural language processing,syntactic complexity},
number = {2},
pages = {333--349},
title = {{Measuring Syntactic Complexity in L2 Writing Using Fine-Grained Clausal and Phrasal Indices}},
volume = {102},
year = {2018}
}
@manual{Nielsen2016,
annote = {R package version 1.1-4},
author = {Nielsen, Hans Bruun and Mortensen, Stig Bousgaard},
title = {{ucminf: General-Purpose Unconstrained Non-Linear Optimization}},
url = {https://cran.r-project.org/package=ucminf},
year = {2016}
}
@phdthesis{Cavalla2016,
author = {Cavalla, Cristelle},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cavalla/Cavalla{\_}2016{\_}Les apprentissages lexicaux des unit{\'{e}}s linguistiques {\`{a}} l'enseignement du FLE.pdf:pdf},
school = {Universit{\'{e}} Grenoble Alpes},
title = {{Les apprentissages lexicaux : des unit{\'{e}}s linguistiques {\`{a}} l'enseignement du FLE}},
type = {Compl{\'{e}}ment au dossier de candidature en vue de l'obtention de l'habilitation {\`{a}} diriger des recherches},
year = {2016}
}
@article{Lu2011,
abstract = {This article reports results of a corpus-based evaluation of 14 syntactic complexity measures as objective indices of college-level English as a second language (ESL) writers' language development. I analyzed large-scale ESL writing data from the Written English Corpus of Chinese Learners (Wen, Wang, {\&} Liang, 2005) using a computational system designed to automate syntactic complexity measurement with 14 measures that have been proposed in second language writing development studies (Lu, 2010). This analysis allows us to investigate the impact of sampling condition on the relationship between syntactic complexity and language development, to identify measures that significantly differentiate between developmental levels, to determine the magnitude at which between-level differences in each measure reach statistical significance, to assess the pattern of development associated with each measure, and to examine the strength of the relationship between different pairs of measures. This research provides ESL teachers and researchers with useful insights into how these measures can be used effectively as indices of college-level ESL writers' language development.},
author = {Lu, Xiaofei},
doi = {10.5054/tq.2011.240859},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lu/Lu{\_}2011{\_}A corpus-based evaluation of syntactic complexity measures as indices of college-level ESL writers' language development.pdf:pdf},
issn = {00398322},
journal = {TESOL Quarterly},
number = {1},
pages = {36--62},
title = {{A corpus-based evaluation of syntactic complexity measures as indices of college-level ESL writers' language development}},
volume = {45},
year = {2011}
}
@article{Crutchfield1994,
abstract = {Defining structure and detecting the emergence of complexity in nature are inherently subjective, though essential, scientific activities. Despite the difficulties, these problems can be analyzed in terms of how model-building observers infer from measurements the computational capabilities embedded in nonlinear processes. An observers notion of what is ordered, what is random, and what is complex in its environment depends directly on its computational resources: the amount of raw measurement data, of memory, and of time available for estimation and inference. The discovery of structure in an environment depends more critically and subtlely, though, on how those resources are organized. The descriptive power of the observers chosen (or implicit) computational model class, for example, can be an overwhelming determinant in finding regularity in data.},
author = {Crutchfield, James P},
doi = {10.1016/0167-2789(94)90273-9},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crutchfield/Crutchfield{\_}1994{\_}The Calculi of Emergence.pdf:pdf},
isbn = {0167-2789},
issn = {01672789},
journal = {Innovation},
number = {April 1993},
pages = {11--54},
pmid = {308},
title = {{The Calculi of Emergence}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0167278994902739},
volume = {75},
year = {1994}
}
@manual{HarrellJr2019,
annote = {R package version 4.2-0},
author = {{Harrell Jr}, Frank E},
title = {{Hmisc: Harrell Miscellaneous}},
url = {https://cran.r-project.org/package=Hmisc},
year = {2019}
}
@manual{Wickham2019c,
annote = {R package version 1.0.5},
author = {Wickham, Hadley and Hester, Jim},
title = {{pkgbuild: Find Tools Needed to Build R Packages}},
url = {https://cran.r-project.org/package=pkgbuild},
year = {2019}
}
@manual{Ahlmann-Eltze2019,
annote = {R package version 0.6.0},
author = {Ahlmann-Eltze, Constantin},
title = {{ggsignif: Significance Brackets for 'ggplot2'}},
url = {https://cran.r-project.org/package=ggsignif},
year = {2019}
}
@incollection{Xie2014,
annote = {ISBN 978-1466561595},
author = {Xie, Yihui},
booktitle = {Implementing Reproducible Computational Research},
editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D},
publisher = {Chapman and Hall/CRC},
title = {{knitr: A Comprehensive Tool for Reproducible Research in {\{}R{\}}}},
url = {http://www.crcpress.com/product/isbn/9781466561595},
year = {2014}
}
@article{Wood2011,
author = {Wood, S N},
journal = {Journal of the Royal Statistical Society (B)},
number = {1},
pages = {3--36},
title = {{Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models}},
volume = {73},
year = {2011}
}
@phdthesis{Francois2011,
author = {Fran{\c{c}}ois, Thomas},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Fran{\c{c}}ois/Fran{\c{c}}ois{\_}2011{\_}Les apports du traitement automatique du langage {\`{a}} la lisibilit{\'{e}} du fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re(2).pdf:pdf},
keywords = {complexity},
mendeley-tags = {complexity},
school = {Universit{\'{e}} catholique de Louvain},
title = {{Les apports du traitement automatique du langage {\`{a}} la lisibilit{\'{e}} du fran{\c{c}}ais langue {\'{e}}trang{\`{e}}re}},
year = {2011}
}
@article{Larsen-Freeman2006,
abstract = {Seeing language as a complex, dynamic system and language use/acquisition as dynamic adaptedness ('a make-do' solution) to a specific context proves a useful way of understanding change in progress, such as that which occurs with a developing L2 system. This emergentist shift of perspective provides another way of understanding previously observed characteristics of learner language, that is that its development is not discrete and stage-like but more like the waxing and waning of patterns; that, from a target-language perspective, certain aspects of the behavior are progressive, others, regressive; that change can be gradual and it can be sudden; and that the latter notably heralds the emergence of a new order qualitatively different and novel from earlier organizations. In addition, when group data are disaggregated, it is clear that there are many paths to development. By closely examining the oral and written production of five Chinese learners of English, the emergence of complexity, fluency, and accuracy can be seen, not as the unfolding of some prearranged plan, but rather as the system adapting to a changing context, in which the language resources of each individual are uniquely transformed through use. {\textcopyright} Oxford University Press 2006.},
author = {Larsen-Freeman, Diane},
doi = {10.1093/applin/aml029},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Larsen-Freeman/Larsen-Freeman{\_}2006{\_}The emergence of complexity, fluency, and accuracy in the oral and written production of five Chinese learners of en.pdf:pdf},
issn = {01426001},
journal = {Applied Linguistics},
number = {4},
pages = {590--619},
title = {{The emergence of complexity, fluency, and accuracy in the oral and written production of five Chinese learners of english}},
volume = {27},
year = {2006}
}
@article{Matthey2004,
abstract = {0. IntroductionFries, Lado et Weinreich ont ouvert la voie aux travaux en RAL par leurs recherches sur le bilinguisme et la comparaison de langues dans les ann{\'{e}}es cinquante, (Selinker 1992). Les recherches sur l'acquisition des langues secondes/{\'{e}}trang{\`{e}}res (dor{\'{e}}navant L2) telles qu'elles se sont organis{\'{e}}es depuis une quarantaine d'ann{\'{e}}es trouvent leur origine, cependant, dans le rejet des th{\'{e}}ories b{\'{e}}havioristes de l'apprentissage verbal en psychologie et en linguistique ; le c{\'{e}}l{\`{e}}bre compte ren...},
author = {Matthey, Marinette and V{\'{e}}ronique, Georges Daniel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Matthey, V{\'{e}}ronique/Matthey, V{\'{e}}ronique{\_}2004{\_}Trois approches de l'acquisition des langues {\'{e}}trang{\`{e}}res enjeux et perspectives.pdf:pdf},
issn = {1243-969X},
journal = {Acquisition et interaction en langue {\'{e}}trang{\`{e}}re [En ligne]},
number = {21},
pages = {203--223},
title = {{Trois approches de l'acquisition des langues {\'{e}}trang{\`{e}}res : enjeux et perspectives}},
url = {http://journals.openedition.org/aile/4549},
year = {2004}
}
@article{Ellis1987,
abstract = {Examines style shifting in the use of three past tense morphemes by 17 intermediate learners of English as a second language. Style shifting is explored within a single discourse mode--narrative--according to the amount of time made available. Data were collected under three conditions: (1) planned writing; (2) planned speech; and (3) unplanned speech. (LMO)},
author = {Ellis, Rod},
doi = {10.1017/S0272263100006483},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis/Ellis{\_}1987{\_}Interlanguage variability in narrative discourse Style shifting in the use of the past tense.pdf:pdf},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
pages = {1--20},
title = {{Interlanguage variability in narrative discourse: Style shifting in the use of the past tense}},
volume = {9},
year = {1987}
}
@manual{Ooms2019b,
annote = {R package version 3.3},
author = {Ooms, Jeroen},
title = {{sys: Powerful and Reliable Tools for Running System Commands in R}},
url = {https://cran.r-project.org/package=sys},
year = {2019}
}
@incollection{Wilks2007,
address = {Cambridge},
author = {Wilks, Clarissa and Meara, Paul},
booktitle = {Modelling and Assessing Vocabulary Knowledge},
editor = {Daller, Helmut and Milton, James and Treffers-Daller, Jeanine},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wilks, Meara/Wilks, Meara{\_}2007{\_}Implementing graph theory approaches to the exploration of density and structure in L1 and L2 word association network.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wilks, Meara/Wilks, Meara{\_}2007{\_}Implementing graph theory approaches to the exploration of density and structure in L1 and L2 word association network.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wilks, Meara/Wilks, Meara{\_}2007{\_}Implementing graph theory approaches to the exploration of density and structure in L1 and L2 word association netw(3).pdf:pdf},
pages = {167--181},
publisher = {Cambridge University Press},
title = {{Implementing graph theory approaches to the exploration of density and structure in L1 and L2 word association networks}},
year = {2007}
}
@article{Sing2005,
author = {Sing, T and Sander, O and Beerenwinkel, N and Lengauer, T},
journal = {Bioinformatics},
number = {20},
pages = {7881},
title = {{ROCR: visualizing classifier performance in R}},
url = {http://rocr.bioinf.mpi-sb.mpg.de},
volume = {21},
year = {2005}
}
@incollection{Tonkyn2012,
abstract = {This paper reports a case study of the nature and extent of progress in speaking skills made by a group of upper intermediate instructed learners, and also assessors' perceptions of that progress. Initial and final interview data were analysed using several measures of Grammatical and Lexical Complexity, Language Accuracy and Fluency. These interview excerpts were also rated by four International English Language Testing System (IELTS) test assessors. Results concerning performance changes and the relationship between objective measures and the assessors' ratings are reported.The results suggest that all subjects improved with regard to one or more of the four performance features examined, though gains on subjective ratings were mostly low. Certain objective indices appeared sensitive to short-term gains and differences in adjacent proficiency bands. These indices included three general Complexity metrics, a general and specific Accuracy measure, and three temporal Fluency measures. Implications for oral rating are discussed.},
address = {Amsterdam},
author = {Tonkyn, Alan Paul},
booktitle = {Dimensions of L2 Performance and Proficiency : Complexity, Accuracy and Fluency in SLA},
doi = {10.1075/lllt.32.10ton},
editor = {Housen, Alex and Kuiken, Folkert and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Tonkyn/Tonkyn{\_}2012{\_}Measuring and perceiving changes in oral complexity, accuracy and fluency.pdf:pdf},
pages = {221--244},
publisher = {John Benjamins},
title = {{Measuring and perceiving changes in oral complexity, accuracy and fluency}},
year = {2012}
}
@manual{Chang2018a,
annote = {R package version 1.3.7},
author = {Chang, Winston and Weeks, Andrew and Siegert, Frank M and Heath, Mark and Henlick, Thomas and Babkin, Sergey and Uyar, Turgut and Hepas, Rihardas and Tamas, Szalay and Vromans, Johan and Titera, Petr and Wang, Lei and Xiangyang, Chen and Petkovic, Zvezdan and Rigel and Hetherington, I Lee},
title = {{Rttf2pt1: 'ttf2pt1' Program}},
url = {https://cran.r-project.org/package=Rttf2pt1},
year = {2018}
}
@manual{Yan2016,
annote = {R package version 1.1.1},
author = {Yan, Yachen},
title = {{MLmetrics: Machine Learning Evaluation Metrics}},
url = {https://cran.r-project.org/package=MLmetrics},
year = {2016}
}
@manual{RSpecialInterestGrouponDatabasesR-SIG-DB2018,
annote = {R package version 1.0.0},
author = {{R Special Interest Group on Databases (R-SIG-DB)} and Wickham, Hadley and M{\"{u}}ller, Kirill},
title = {{DBI: R Database Interface}},
url = {https://cran.r-project.org/package=DBI},
year = {2018}
}
@book{Skehan1998,
address = {Oxford},
author = {Skehan, Peter},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Skehan/Skehan{\_}1998{\_}A Cognitive Approach to Language Learning.pdf:pdf},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
publisher = {Oxford University Press},
title = {{A Cognitive Approach to Language Learning}},
year = {1998}
}
@phdthesis{Conway2005,
author = {Conway, {\AA}sa},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Conway/Conway{\_}2005{\_}Le paragraphe oral en fran{\c{c}}ais L1, en su{\'{e}}dois L1 et en fran{\c{c}}ais L2 {\'{e}}tude syntaxique, prosodique et discursive.pdf:pdf},
school = {(Unpublished Doctoral Dissertation). Lund University},
title = {{Le paragraphe oral en fran{\c{c}}ais L1, en su{\'{e}}dois L1 et en fran{\c{c}}ais L2 : {\'{e}}tude syntaxique, prosodique et discursive}},
year = {2005}
}
@manual{Barton2019,
annote = {R package version 1.43.6},
author = {Barto{\'{n}}, Kamil},
title = {{MuMIn: Multi-Model Inference}},
url = {https://cran.r-project.org/package=MuMIn},
year = {2019}
}
@manual{Ooms2019c,
annote = {R package version 1.1},
author = {Ooms, Jeroen},
title = {{askpass: Safe Password Entry for R, Git, and SSH}},
url = {https://cran.r-project.org/package=askpass},
year = {2019}
}
@article{Bernard2017,
author = {Bernard, Marion and Chanclu, Ana{\"{i}}s and Lafontaine, Fanny and Marcia, Marie and Monnin, Chlo{\'{e}} and Poiret, Rafa{\"{e}}l},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bernard et al/Bernard et al.{\_}2017{\_}Guide d ' annotation syntaxique du corpus Orfeo(2).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bernard et al/Bernard et al.{\_}2017{\_}Guide d ' annotation syntaxique du corpus Orfeo.pdf:pdf},
pages = {1--34},
title = {{Guide d ' annotation syntaxique du corpus Orfeo}},
year = {2017}
}
@article{Bulte2014,
abstract = {This study aims to ascertain the nature and extent of the development of English L2 writing proficiency of 45 adult ESL learners over the time of an intensive short-term academic English language programme by means of quantitative measures targeting different components of the lexical and syntactic complexity of the learners' writing performance, and to compare the scores on these measures with subjective ratings of learners' overall writing quality. Results reveal several linguistic complexity measures that can adequately and validly capture changes in L2 writing in short-term ESL courses, though these do not include "popular" measures such as subordination ratios and lexical richness/diversity measures. Results also suggest that different subcomponents of syntactic and lexical complexity in L2 writing develop at a different pace, underlining the importance of calculating a sufficiently wide range of judiciously selected complexity measures in order to get a comprehensive picture of L2 writing development. Interestingly, the set of progress-sensitive complexity measures identified in this study does not coincide with the set of complexity measures that best predict subjective perceptions of writing quality.},
author = {Bult{\'{e}}, Bram and Housen, Alex},
doi = {10.1016/j.jslw.2014.09.005},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}}, Housen/Bult{\'{e}}, Housen{\_}2014{\_}Conceptualizing and measuring short-term changes in L2 writing complexity.pdf:pdf},
issn = {10603743},
journal = {Journal of Second Language Writing},
keywords = {L2 writing development,L2 writing proficiency,Lexical complexity,Syntactic complexity},
pages = {42--65},
title = {{Conceptualizing and measuring short-term changes in L2 writing complexity}},
volume = {26},
year = {2014}
}
@book{Bivand2013,
author = {Bivand, Roger S and Pebesma, Edzer and Gomez-Rubio, Virgilio},
publisher = {Springer, NY},
title = {{Applied spatial data analysis with {\{}R{\}}, Second edition}},
url = {http://www.asdar-book.org/},
year = {2013}
}
@misc{Hunt1965,
address = {Champaign, IL},
author = {Hunt, Kellogg},
booktitle = {NCTE Research Report No. 3},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hunt/Hunt{\_}1965{\_}Grammatical structures written at three grade levels.pdf:pdf},
institution = {NCTE},
title = {{Grammatical structures written at three grade levels}},
year = {1965}
}
@incollection{Abeille2003,
abstract = {We present a treebank project for French. We have annotated a newspaper cor- pus of 1 Million words with part of speech, inflection, compounds, lemmas and constituency. We describe the tagging and parsing phases of the project, and for each, the automatic tools, the guidelines and the validation process. We then present some uses of the corpus as well as some directions for future work},
address = {Dordrecht},
author = {Abeill{\'{e}}, Anne and Cl{\'{e}}ment, Lionel and Toussenel, Fran{\c{c}}ois},
booktitle = {Treebanks. Text, Speech and Language Technology},
doi = {10.1007/978-94-010-0201-1_10},
editor = {Abeill{\'{e}}, A.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Abeill{\'{e}}, Cl{\'{e}}ment, Toussenel/Abeill{\'{e}}, Cl{\'{e}}ment, Toussenel{\_}2003{\_}Building a Treebank for French.pdf:pdf},
isbn = {978-1-4020-1335-5},
pages = {165--187},
publisher = {Springer},
title = {{Building a Treebank for French}},
url = {http://www.springerlink.com/index/10.1007/978-94-010-0201-1{\_}10},
volume = {20},
year = {2003}
}
@inproceedings{Tutin2010,
address = {Louvain-la-Neuve},
author = {Tutin, Agn{\`{e}}s},
booktitle = {eLexicography in the 21st Century: New challenges, new applications; Proceedings of eLex 2009},
editor = {Granger, Sylviane and Paquot, Magali},
month = {oct},
pages = {313--324},
publisher = {UCL Presses Universitaires de Louvain},
title = {{Showing phraseology in context: onomasiological access to lexico-grammatical patterns in corpora of French scientific writings}},
year = {2010}
}
@book{Verspoor2011,
address = {Amsterdam},
editor = {Verspoor, Marjolijn and de Bot, Kees and Lowie, Wander},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Unknown/Unknown{\_}2011{\_}A Dynamic Approach to Second Language Development.pdf:pdf},
publisher = {John Benjamins},
title = {{A Dynamic Approach to Second Language Development}},
year = {2011}
}
@article{Housen2018,
author = {Housen, Alex and {De Clercq}, Bastien and Kuiken, Folkert and Veder, Ineke},
doi = {10.1177/0267658318809765},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Housen et al/Housen et al.{\_}2018{\_}Multiple approaches to complexity in second language research Special issue on linguistic complexity.pdf:pdf},
issn = {0267-6583},
journal = {Second Language Research},
pages = {1--19},
title = {{Multiple approaches to complexity in second language research [Special issue on linguistic complexity]}},
url = {http://journals.sagepub.com/doi/10.1177/0267658318809765},
year = {2018}
}
@incollection{Gunnarsson2012,
address = {Amsterdam},
author = {Gunnarsson, Cecilia},
booktitle = {Dimensions of L2 Performance and Proficiency: Complexity, Accuracy and Fluency in SLA},
editor = {Housen, Alex and Vedder, Ineke and Kuiken, Folkert},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gunnarsson/Gunnarsson{\_}2012{\_}The development of complexity, accuracy and fluency in the written production of L2 French.pdf:pdf},
publisher = {John Benjamins},
title = {{The development of complexity, accuracy and fluency in the written production of L2 French}},
volume = {247-276},
year = {2012}
}
@misc{Team2018,
address = {Boston, MA},
author = {{RStudio Team}},
title = {{RStudio: Integrated Development Environment for R}},
url = {http://www.rstudio.com/},
year = {2018}
}
@manual{rtweet-package,
annote = {R package version 0.6.9},
author = {Kearney, Michael W},
title = {{rtweet: Collecting Twitter Data}},
url = {https://cran.r-project.org/package=rtweet},
year = {2019}
}
@article{Ellis2009b,
author = {Ellis, Nick C and Larsen-Freeman, Diane},
doi = {10.1111/j.1467-9922.2009.00537.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, Larsen-Freeman/Ellis, Larsen-Freeman{\_}2009{\_}Constructing a Second Language Analyses and Computational Simulations of the Emergence of Linguistic Construc.pdf:pdf},
issn = {00238333},
journal = {Language Learning},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
month = {dec},
number = {1},
pages = {90--125},
title = {{Constructing a Second Language: Analyses and Computational Simulations of the Emergence of Linguistic Constructions From Usage}},
url = {http://doi.wiley.com/10.1111/j.1467-9922.2009.00537.x},
volume = {59},
year = {2009}
}
@article{Skehan1991,
abstract = {This article is broadly concerned with the differences between individual language learners. In terms of particular content areas of Individual Differences (ID) research, it surveys developments in foreign language aptitude, motivation, learner strategies, and learner styles. A brief review of earlier research on aptitude is presented, followed by discussions of more contemporary work on the origin of aptitude, namely, as a residue of first language learning ability, and on the existence of evidence for “learner types.” Motivation research is reviewed partly with regard to Robert Gardner's research, and then in terms of a wider framework for the functioning of motivation within an educational context. The review of learner strategies research emphasizes current attempts to develop taxonomies of such strategies, and to investigate their theoretical basis and their trainability. Finally, learner styles research, drawing on field independence theory, is discussed, and links are made with the research on aptitude. The article finishes with sections on conceptual and methodological issues in ID research. {\textcopyright} 1991, Cambridge University Press. All rights reserved.},
author = {Skehan, Peter},
doi = {10.1017/S0272263100009979},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Skehan/Skehan{\_}1991{\_}Individual Differences In Second Language Learning.pdf:pdf},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
number = {2},
pages = {275--298},
title = {{Individual Differences In Second Language Learning}},
volume = {13},
year = {1991}
}
@manual{WinstonChang2014,
annote = {R package version 0.17},
author = {{Winston Chang}},
title = {{extrafont: Tools for using fonts}},
url = {https://cran.r-project.org/package=extrafont},
year = {2014}
}
@article{Kyle2018a,
author = {Kyle, Kristopher and Crossley, Scott A. and Berger, C},
journal = {Behavior Research Methods},
keywords = {taales},
mendeley-tags = {taales},
pages = {1030--1046},
title = {{The tool for the analysis of lexical sophistication (TAALES): Version 2.0}},
volume = {50},
year = {2018}
}
@manual{Falissard2012,
annote = {R package version 1.1},
author = {Falissard, Bruno},
title = {{psy: Various procedures used in psychometry}},
url = {https://cran.r-project.org/package=psy},
year = {2012}
}
@article{Granger2014,
abstract = {Abstract Phraseological competence, the use of (semi-)prefabricated expressions in language, is a major component of second language acquisition. Recent research focused on lexical bundles, i.e. recurrent contiguous strings of words, has highlighted quantitative and qualitative differences between native and non-native speaker use of these strings. Few studies, however, have investigated the development of phraseological competence as a function of degree of proficiency in L2. Relying on a methodology used by Durrant and Schmitt (2009: IRAL 47, 157-177) to compare native and non-native speakers, the present study identifies significant differences in the way in which intermediate and advanced learners use collocations. In particular, the intermediate learners tend to overuse high frequency collocations (such as hard work) and underuse lower-frequency, but strongly associated, collocations (such as immortal souls). The concluding section addresses the limits of the study and points to possible applications in foreign language teaching and automated scoring.},
annote = {Same as Durrant and Schmitt (2009)
- Pre-modifier (N) + Noun
- Pre-modifier (Adj) + Noun
New:
- Adjective + Adverb
- All bigrams},
author = {Granger, Sylviane and Bestgen, Yves},
doi = {10.1515/iral-2014-0011},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Bestgen/Granger, Bestgen{\_}2014{\_}The use of collocations by intermediate vs. advanced non-native writers A bigram-based study.pdf:pdf},
isbn = {1613-4141},
issn = {16134141},
journal = {International Review of Applied Linguistics in Language Teaching},
keywords = {Association scores,Bigram,Collocation,L2 learner corpus,Phraseology,Proficiency level,stats},
mendeley-tags = {stats},
number = {3},
pages = {229--252},
title = {{The use of collocations by intermediate vs. advanced non-native writers: A bigram-based study}},
volume = {52},
year = {2014}
}
@article{Robert2012,
author = {Robert, Christelle and Dorot, Delphine and Mathey, St{\'{e}}phanie},
doi = {10.4074/s0003503312002035},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Robert, Dorot, Mathey/Robert, Dorot, Mathey{\_}2012{\_}Du campus au jardin estimations de fr{\'{e}}quence subjective aupr{\`{e}}s d'adultes jeunes et {\^{a}}g{\'{e}}s pour 660 mots.pdf:pdf},
issn = {0003-5033},
journal = {L'Ann{\'{e}}e psychologique},
number = {02},
pages = {227--246},
title = {{Du campus au jardin : estimations de fr{\'{e}}quence subjective aupr{\`{e}}s d'adultes jeunes et {\^{a}}g{\'{e}}s pour 660 mots de la langue fran{\c{c}}aise}},
volume = {112},
year = {2012}
}
@incollection{ForsbergLundell2014a,
address = {Amsterdam},
author = {{Forsberg Lundell}, Fanny and Lindqvist, Christina},
booktitle = {The Acquisition of French as a Second Language: New developmental perspectives},
editor = {Lindqvist, Christina and Bardel, Camilla},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Forsberg Lundell, Lindqvist/Forsberg Lundell, Lindqvist{\_}2014{\_}Vocabulary aspects of advanced L2 French Do lexical formulaic sequences and lexical richness develop at.pdf:pdf},
pages = {75--94},
publisher = {John Benjamins},
title = {{Vocabulary aspects of advanced L2 French: Do lexical formulaic sequences and lexical richness develop at the same rate?}},
year = {2014}
}
@article{Crossley2011,
abstract = {This study explores how second language (L2) texts written by learners at various proficiency levels can be classified using computational indices that characterize lexical competence. For this study, 100 writing samples taken from 100 L2 learners were analyzed using lexical indices reported by the computational tool Coh-Metrix. The L2 writing samples were categorized into beginning, intermediate, and advanced groupings based on the TOEFL and ACT ESL Compass scores of the writer. A discriminant function analysis was used to predict the level categorization of the texts using lexical indices related to breadth of lexical knowledge (word frequency, lexical diversity), depth of lexical knowledge (hypernymy, polysemy, semantic co-referentiality, and word meaningfulness), and access to core lexical items (word concreteness, familiarity, and imagability). The strongest predictors of an individual's proficiency level were word agability, word frequency, lexical diversity, and word familiarity. In total, the indices correctly classified 70{\%} of the texts based on proficiency level in both a training and a test set. The authors argue for the applicability of a statistical model as a method to investigate lexical competence across language levels, as a method to assess L2 lexical development, and as a method to classify L2 proficiency. {\textcopyright} The Author(s) 2011.},
author = {Crossley, Scott A. and Salsbury, Tom and McNamara, Danielle S.},
doi = {10.1177/0265532211419331},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley, Salsbury, McNamara/Crossley, Salsbury, McNamara{\_}2011{\_}Predicting the proficiency level of language learners using lexical indices.pdf:pdf},
issn = {02655322},
journal = {Language Testing},
keywords = {frequency,language proficiency,lexical competence,lexical diversity,second language acquisition,word familiarity,word imagability},
number = {2},
pages = {243--263},
title = {{Predicting the proficiency level of language learners using lexical indices}},
volume = {29},
year = {2011}
}
@article{Michel2011,
author = {Michel, Jean-baptiste and Shen, Yuan Kui and Aiden, Aviva Presser and Veres, Adrian and Grey, Matthew K. and Team, The Google Books and Pickett, Joseph P. and Hoiberg, Dale and Clancy, Dan and Norvig, Peter and Orwant, Jon and Pinker, Steven and Nowak, Martin A. and Aiden, Erez Lieberman},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Michel et al/Michel et al.{\_}2011{\_}Quantitative analysis using millions of digitized books.pdf:pdf},
journal = {Science},
number = {January},
pages = {176----182},
title = {{Quantitative analysis using millions of digitized books}},
volume = {331},
year = {2011}
}
@inproceedings{Granfeldt2005,
abstract = {Direkt Profil is an automatic analyzer of texts written in French as a second language. Its objective is to produce an evaluation of the developmental stage of students under the form of a grammatical learner profile. Direkt Profil carries out a sentence analysis based on developmental sequences, i.e. local morphosyntactic phenomena linked to a development in the acquisition of French. The paper presents the corpus that we use to develop the system and briefly, the developmental sequences. Then, it describes the annotation that we have defined, the parser, and the user interface. We conclude by the results obtained so far: on the test corpus the systems obtains a recall of 83{\%} and a precision of 83{\%}.},
address = {Ann Arbor},
annote = {created for L2 written French... adaptations for oral data?

mapping of developmental phenomena onto CEFR levels?

4 layers of annotation:
- tokens
- prefabs
- chunk annotation (phenomena to identify)
- structures typical of acq stage

available here: 
http://www.rom.lu.se:8080/profil

**why did it analyze the learner texts better than the NS group},
author = {Granfeldt, Jonas and Nugues, Pierre and Persson, Emil and Persson, Lisa and Kostadinov, Fabian and {\AA}gren, Malin and Schlyter, Suzanne},
booktitle = {Proceedings of the 2nd Workshop on Building Educational Applications Using NLP},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granfeldt et al/Granfeldt et al.{\_}2005{\_}Direkt Profil A System for Evaluating Texts of Second Language Learners of French Based on Developmental Sequences.pdf:pdf},
month = {jun},
pages = {53--60},
publisher = {Association for Computational Linguistics},
title = {{Direkt Profil: A System for Evaluating Texts of Second Language Learners of French Based on Developmental Sequences}},
year = {2005}
}
@article{Prodeau1998,
author = {Prodeau, Mireille},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Prodeau/Prodeau{\_}1998{\_}La syntaxe dans le discours instructionnel en LE maintien de la r{\'{e}}f{\'{e}}rence dans le domaine des entit{\'{e}}s.pdf:pdf},
journal = {Acquisition et interaction en langue {\'{e}}trang{\`{e}}re [En ligne]},
pages = {95--145},
title = {{La syntaxe dans le discours instructionnel en LE : maintien de la r{\'{e}}f{\'{e}}rence dans le domaine des entit{\'{e}}s}},
volume = {11},
year = {1998}
}
@book{Xie2015,
address = {Boca Raton, Florida},
annote = {ISBN 978-1498716963},
author = {Xie, Yihui},
edition = {2nd},
publisher = {Chapman and Hall/CRC},
title = {{Dynamic Documents with {\{}R{\}} and knitr}},
url = {https://yihui.name/knitr/},
year = {2015}
}
@article{Lu2012,
author = {Lu, Xiaofei},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lu/Lu{\_}2012{\_}The Relationship of Lexical Richness to the Quality of ESL Learners' Oral Narratives.pdf:pdf},
journal = {The Modern Language Journal},
number = {2},
pages = {190--206},
title = {{The Relationship of Lexical Richness to the Quality of ESL Learners' Oral Narratives}},
volume = {96},
year = {2012}
}
@article{Lisson2018,
abstract = {This article presents a corpus-based evaluation of 13 lexical diversity metrics as measures of longitudinal progression in written productions of learners of French as third language $\backslash$(L3$\backslash$). Our case study $\backslash$(24 learners, 3 productions per learner in the course of 3 months$\backslash$) deals with a semi-longitudinal corpus, where each of the productions is supposed to be more complex than the previous one. Random forests $\backslash$(Breiman, 2001; Hothorn et al., 2019$\backslash$) are used in order to see whether lexical diversity metric scores capture enough vocabulary diversity progression to predict the production wave. We report that lexical diversity metrics capture lexical progression through the three productions of each student. In particular, two metrics appear to be the most informative for lexical progression: Herdan's C and Yule's K.},
author = {Liss{\'{o}}n, Paula and Ballier, Nicolas},
doi = {10.4000/discours.9950},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Liss{\'{o}}n, Ballier/Liss{\'{o}}n, Ballier{\_}2018{\_}Investigating Lexical Progression through Lexical Diversity Metrics in a Corpus of French L3.pdf:pdf},
issn = {1963-1723},
journal = {Discours [Online]},
keywords = {L3 French,learner corpora,lexical diversity},
title = {{Investigating Lexical Progression through Lexical Diversity Metrics in a Corpus of French L3}},
volume = {23},
year = {2018}
}
@inproceedings{Francois2011a,
abstract = {This study aims to assess the usefulness of multi-word expressions (MWEs) as features for a readability formula that predicts the difficulty of texts for French as a foreign language. Using a MWE extractor combining a statistical approach with a linguistic filter, we define 11 predictors. These take into account the density and the probability of MWEs, but also their internal structure. Our experiments show that the predictive power of these 11 variables is low and that a simple approach based on the average probability of n-grams is more effective.},
address = {Hissar},
author = {Fran{\c{c}}ois, Thomas and Watrin, Patrick},
booktitle = {Proceedings of Recent Advances in Natural Language Processing},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Fran{\c{c}}ois, Watrin/Fran{\c{c}}ois, Watrin{\_}2011{\_}On the contribution of MWE-based features to a readability formula for French as a foreign language.pdf:pdf},
issn = {13138502},
pages = {441--447},
title = {{On the contribution of MWE-based features to a readability formula for French as a foreign language}},
year = {2011}
}
@unpublished{spacy2,
annote = {To appear},
author = {Honnibal, Matthew and Montani, Ines},
title = {{spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing}},
year = {2017}
}
@incollection{Ragheb2011,
abstract = {It is becoming more common to use corpora of second language learner data in order to $\backslash$nsupport research on various second language acquisition (SLA) topics (eg, R{\"{o}}mer, 2009; $\backslash$nWulff et al., 2009), but there has been little use of corpus annotation. For many questions in $\backslash$nSLA research, using a corpus is simple and in no need of annotation: one can search a $\backslash$ncorpus for specific words to find relevant examples. For example, if one wants to examine $\backslash$nhow modal verbs are used by L2 learners (cf., eg, Aijmer, 2002), one can search for those ...},
address = {Somerville, MA},
author = {Ragheb, Marwa and Dickinson, Markus},
booktitle = {Selected Proceedings of the 2010 Second Language Research Forum: Reconsidering SLA Research, Dimensions, and Directions},
editor = {Granena, Gisela and Koeth, Joel and Lee-Ellis, Sunyoung and Lukyanchenko, Anna and Botana, Goretti Prieto and Rhoades, Elizabeth},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ragheb, Dickinson/Ragheb, Dickinson{\_}2011{\_}Avoiding the comparative fallacy in the annotation of learner corpora.pdf:pdf},
number = {June},
pages = {114--124},
publisher = {Cascadilla Proceedings Project},
title = {{Avoiding the comparative fallacy in the annotation of learner corpora}},
url = {http://www.lingref.com/cpp/slrf/2010/paper2620.pdf},
year = {2011}
}
@article{Meyer2006,
author = {Meyer, David and Zeileis, Achim and Hornik, Kurt},
journal = {Journal of Statistical Software},
number = {3},
pages = {1--48},
title = {{The Strucplot Framework: Visualizing Multi-Way Contingency Tables with vcd}},
url = {http://www.jstatsoft.org/v17/i03/},
volume = {17},
year = {2006}
}
@manual{Wickham2019k,
annote = {R package version 0.0.3},
author = {Wickham, Hadley},
title = {{dtplyr: Data Table Back-End for 'dplyr'}},
url = {https://cran.r-project.org/package=dtplyr},
year = {2019}
}
@book{Hoey2012,
abstract = {Lexical Priming proposes a radical new theory of the lexicon, which amounts to a completely new theory of language based on how words are used in the real world. Here they are not confined to the definitions given to them in dictionaries but instead interact with other words in common patterns of use. Using concrete statistical evidence from a corpus of newspaper English, but also referring to travel writing and literary text, the author argues that words are 'primed' for use through our experience with them, so that everything we know about a word is a product of our encounters with it. This knowledge explains how speakers of a language succeed in being fluent, creative and natural.},
address = {London},
author = {Hoey, Michael},
booktitle = {Lexical Priming: A New Theory of Words and Language},
doi = {10.4324/9780203327630},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hoey/Hoey{\_}2012{\_}Lexical priming A new theory of words and language.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hoey/Hoey{\_}2012{\_}Lexical priming A new theory of words and language(2).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hoey/Hoey{\_}2012{\_}Lexical priming A new theory of words and language(3).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hoey/Hoey{\_}2012{\_}Lexical priming A new theory of words and language(4).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hoey/Hoey{\_}2012{\_}Lexical priming A new theory of words and language(5).pdf:pdf},
isbn = {9780203327630},
issn = {01550640},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
pmid = {13676958},
publisher = {Routledge},
title = {{Lexical priming: A new theory of words and language}},
year = {2012}
}
@manual{Azzalini2016,
author = {Azzalini, Adelchi and Genz, Alan},
title = {{The {\{}R{\}} package $\backslash$texttt{\{}mnormt{\}}: The multivariate normal and {\$}t{\$} distributions (version 1.5-5)}},
url = {http://azzalini.stat.unipd.it/SW/Pkg-mnormt},
year = {2016}
}
@manual{Dragulescu2018,
annote = {R package version 0.6.1},
author = {Dragulescu, Adrian A and Arendt, Cole},
title = {{xlsx: Read, Write, Format Excel 2007 and Excel 97/2000/XP/2003 Files}},
url = {https://cran.r-project.org/package=xlsx},
year = {2018}
}
@manual{FromJedWing2019,
annote = {R package version 6.0-84},
author = {Wing, Jed and Kuhn, Max and Weston, Steve and Williams, Andre and Keefer, Chris and Engelhardt, Allan and Cooper, Tony and Mayer, Zachary and Kenkel, Brenton and Team, the R Core and Benesty, Michael and Lescarbeau, Reynald and Ziem, Andrew and Scrucca, Luca and Tang, Yuan and Candan, Can and Hunt., Tyler},
title = {{caret: Classification and Regression Training}},
url = {https://cran.r-project.org/package=caret},
year = {2019}
}
@article{Beguelin1998,
author = {B{\'{e}}guelin, Marie-Jos{\'{e}}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/B{\'{e}}guelin/B{\'{e}}guelin{\_}1998{\_}Le rapport {\'{e}}crit-oral. Tendances dissimilatrices, tendances assimilatrices.pdf:pdf},
journal = {Cahiers de linguistique fran{\c{c}}aise},
pages = {229--253},
title = {{Le rapport {\'{e}}crit-oral. Tendances dissimilatrices, tendances assimilatrices}},
volume = {20},
year = {1998}
}
@article{Garner2016,
abstract = {Findings from corpus-based and psycholinguistic research have highlighted the importance of acquiring productive knowledge of English phraseology for L2 learners. Many studies exploring this facet of language learning have investigated the use of predominantly fixed multi-word sequences by advanced learners in academic settings and compared their use against that of native-speaking writers. More recent studies have attempted to explore the differences between learners' use of multi-word sequences across proficiency levels. The current study aims to add to this growing body of literature. It examines the use of phrase-frames by L1 German learners of English as a Foreign Language at five different proficiency levels represented in the EF-Cambridge Open Language Database (EFCAMDAT). The most frequent phrase-frames in each level are analyzed according to both quantitative and qualitative characteristics. The results revealed that, at higher proficiency levels, p-frames in learner texts are more variable, less predictable, and more functionally complex.},
author = {Garner, James R.},
doi = {10.1075/ijlcr.2.1.02gar},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Garner/Garner{\_}2016{\_}A phrase-frame approach to investigating phraseology in learner writing across proficiency levels.pdf:pdf},
isbn = {1528-0020},
issn = {2215-1478},
journal = {International Journal of Learner Corpus Research},
keywords = {German EFL learners,L2 phraseology,german efl learners,l2 phraseology,phrase-frames,usage-based,usage-based SLA},
number = {1},
pages = {31--68},
title = {{A phrase-frame approach to investigating phraseology in learner writing across proficiency levels}},
url = {http://www.jbe-platform.com/content/journals/10.1075/ijlcr.2.1.02gar},
volume = {2},
year = {2016}
}
@manual{Cheng2018a,
annote = {R package version 1.0.1},
author = {Cheng, Joe},
title = {{promises: Abstractions for Promise-Based Asynchronous Programming}},
url = {https://cran.r-project.org/package=promises},
year = {2018}
}
@incollection{Takavoli2014,
address = {Amsterdam},
author = {Takavoli, Parveneh},
booktitle = {Task-Based Language Learning : Insights from and for L2 Writing},
editor = {Byrnes, Heidi and Manch{\'{o}}n, Rosa M.},
pages = {217--236},
publisher = {John Benjamins},
title = {{Storyline complexity and syntactic complexity in writing and speaking tasks}},
year = {2014}
}
@article{Laufer1994,
author = {Laufer, Batia},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Laufer/Laufer{\_}1994{\_}The Lexical Profile of Second Language Writing Does It Change Over Time.pdf:pdf},
journal = {RELG Journal},
pages = {21--33},
title = {{The Lexical Profile of Second Language Writing: Does It Change Over Time}},
volume = {25},
year = {1994}
}
@manual{Wickham2019s,
annote = {R package version 0.1.5},
author = {Wickham, Hadley},
title = {{modelr: Modelling Functions that Work with the Pipe}},
url = {https://cran.r-project.org/package=modelr},
year = {2019}
}
@inproceedings{Berard2014,
address = {Berlin},
author = {B{\'{e}}rard, Lolita},
booktitle = {4{\`{e}}me Congr{\`{e}}s Mondial de Lin- guistique Fran{\c{c}}aise},
doi = {10.1051/shsconf/20140801336},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/B{\'{e}}rard/B{\'{e}}rard{\_}2014{\_}D{\'{e}}pendances {\`{a}} longue distance et genres textuels.pdf:pdf},
month = {jul},
title = {{D{\'{e}}pendances {\`{a}} longue distance et genres textuels}},
year = {2014}
}
@article{Church1990,
abstract = {The term word association is used in a very particular sense in the$\backslash$npsycholinguistic literature. {\{}(Generally{\}} speaking, subjects respond$\backslash$nquicker than normal to the word nurse if it follows a highly associated$\backslash$nword such as doctor. ) We will extend the term to provide the basis$\backslash$nfor a statistical description of a variety of interesting linguistic$\backslash$nphenomena, ranging from semantic relations of the doctor/nurse type$\backslash$n(content word/content word) to lexico-syntactic co-occurrence constraints$\backslash$nbetween verbs and prepositions (content word/function word). This$\backslash$npaper will propose an objective measure based on the information$\backslash$ntheoretic notion of mutual information, for estimating word association$\backslash$nnorms from computer readable corpora. {\{}(The{\}} standard method of obtaining$\backslash$nword association norms, testing a few thousand subjects on a few$\backslash$nhundred words, is both costly and unreliable.) The proposed measure,$\backslash$nthe association ratio, estimates word association norms directly$\backslash$nfrom computer readable corpora, making it possible to estimate norms$\backslash$nfor tens of thousands of words.},
author = {Church, Kenneth Ward and Hanks, Patrick},
doi = {10.3115/981623.981633},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Church, Hanks/Church, Hanks{\_}1990{\_}Word association norms, mutual information, and lexicography.pdf:pdf},
pages = {22--29},
title = {{Word association norms, mutual information, and lexicography}},
volume = {16},
year = {1990}
}
@manual{ngramguide,
annote = {{\{}R{\}} Vignette},
author = {Schmidt, Drew and Heckendorf, Christian},
title = {{Guide to the ngram Package: Fast n-gram Tokenization}},
url = {https://cran.r-project.org/package=ngram},
year = {2017}
}
@article{Lisson2018a,
author = {Liss{\'{o}}n, Paula and Trujillo-Gonz{\'{a}}lez, Ver{\'{o}}nica},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Liss{\'{o}}n, Trujillo-Gonz{\'{a}}lez/Liss{\'{o}}n, Trujillo-Gonz{\'{a}}lez{\_}2018{\_}D{\'{e}}tection des transferts interlangues chez des apprenants universitaires de fran{\c{c}}ais troisi{\`{e}}me langu.pdf:pdf},
journal = {Synergies Espagne},
pages = {55--70},
title = {{D{\'{e}}tection des transferts interlangues chez des apprenants universitaires de fran{\c{c}}ais troisi{\`{e}}me langue}},
volume = {11},
year = {2018}
}
@book{Gries2016,
address = {London},
author = {Gries, Stefan Th.},
publisher = {Routledge},
title = {{Quantitative Corpus Linguistics with R: A Practical Introduction}},
year = {2016}
}
@manual{Warnes2019,
annote = {R package version 3.0.1.1},
author = {Warnes, Gregory R and Bolker, Ben and Bonebakker, Lodewijk and Gentleman, Robert and Liaw, Wolfgang Huber Andy and Lumley, Thomas and Maechler, Martin and Magnusson, Arni and Moeller, Steffen and Schwartz, Marc and Venables, Bill},
title = {{gplots: Various R Programming Tools for Plotting Data}},
url = {https://cran.r-project.org/package=gplots},
year = {2019}
}
@article{Benazzo2002,
annote = {Les apprenants observ{\'{e}}s par Benazzo et al. (2004) se distinguent des locuteurs natifs, notamment, par le fait qu'ils n'emploient pas de moyens contrastifs du type tandis que ou alors que. (from Veronique 2017)},
author = {Benazzo, Sandra},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Benazzo/Benazzo{\_}2002{\_}Communicative potential vs. structural constraints Explanatory factors for the acquisition of scope particles.pdf:pdf},
journal = {EUROSLA Yearbook},
number = {1},
pages = {187--204},
title = {{Communicative potential vs. structural constraints: Explanatory factors for the acquisition of scope particles}},
volume = {2},
year = {2002}
}
@phdthesis{Agren2008,
author = {{\AA}gren, Malin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/{\AA}gren/{\AA}gren{\_}2008{\_}{\`{A}} La Recherche De La Morphologie Silencieuse.pdf:pdf},
school = {Lund University},
title = {{{\`{A}} La Recherche De La Morphologie Silencieuse}},
type = {Doctoral dissertation},
year = {2008}
}
@incollection{Bulte2012,
abstract = {This chapter takes a critical look at complexity in L2 research. We demonstrate several problems in the L2 literature in terms of how complexity has been defined and operationalised as a construct. In the first part of the chapter we try to unravel its highly complex, multidimensional nature by presenting a taxonomic model that identifies major types, dimensions and components of L2 complexity, each of which can be independently analysed or measured. The second part evaluates how complexity has been measured in empirical SLA research. Using the taxonomy of L2 complexity from part 1 as a framework, we inventory the measures of L2 complexity that have been used in a sample of forty recent L2 studies. Next we discuss the construct validity of several widely used measures of grammatical complexity by identifying their underlying logic as well as the methodological and practical challenges that their computation presents.},
address = {Amsterdam},
author = {Bult{\'{e}}, Bram and Housen, Alex},
booktitle = {Dimensions of L2 performance and proficiency: Complexity, accuracy and fluency in SLA},
doi = {10.1075/lllt.32.02bul},
editor = {Housen, Alex and Vedder, Ineke and Kuiken, Folkert},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}}, Housen/Bult{\'{e}}, Housen{\_}2012{\_}Defining and operationalising L2 complexity.pdf:pdf},
isbn = {902727326X},
issn = {902727326X},
pages = {21--46},
pmid = {22537503},
publisher = {John Benjamins},
title = {{Defining and operationalising L2 complexity}},
url = {https://benjamins.com/catalog/lllt.32.02bul},
year = {2012}
}
@manual{Analytics2019,
annote = {R package version 1.0.12},
author = {Analytics, Revolution and Weston, Steve},
title = {{iterators: Provides Iterator Construct}},
url = {https://cran.r-project.org/package=iterators},
year = {2019}
}
@article{Skehan1996,
abstract = {This paper examines recent proposals for task-based approaches to instruc-tion It reviews relevant research, before going on to examine a number of potential problems with task-based teaching, such as a potential focus away from form and towards lexis It renews recent developments in cognitive psychology which support a dual-mode perspective for language processing, and then proposes the goals of accuracy, complexity-restructuring, and fluency as the most relevant for task-based instruction In the final section, the paper proposes a framework for the implementation of task-based instruction which draws upon relevant theory and research, and which organizes the methods by which such instruction could be put into practice in such a way as to minimize problems, and maximize the probability that all three above goals can be achieved INTRODUCTION},
author = {Skehan, Peter},
doi = {10.4324/9781315629766-3},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Skehan/Skehan{\_}1996{\_}A Framework for the Implementation of Task-Based Instruction.pdf:pdf},
journal = {Second Language Task-Based Performance},
number = {1},
pages = {13--34},
title = {{A Framework for the Implementation of Task-Based Instruction}},
volume = {17},
year = {1996}
}
@article{Weissberg2000,
abstract = {The acquisition of English morpho-syntactic elements was studied in five adult L2 learners, all native speakers of Spanish, while they were enrolled in a pre-university intensive English program. Data were elicited through a variety of paired oral and written tasks over a three and a half month semester. Samples were analyzed to determine whether speech or writing served as the primary source of morpho-syntactic innovation. The five subjects demonstrated notable differences in their patterns of language development across both modalities. In general, however, writing appeared to be the preferred medium for the emergence of new morphosyntactic forms and for the development of grammatical accuracy. {\textcopyright} 1999 Elsevier Science Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Weissberg, Bob},
doi = {10.1016/S0959-4752(99)00017-1},
eprint = {arXiv:1011.1669v3},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Weissberg/Weissberg{\_}2000{\_}Developmental relationships in the acquisition of English syntax Writing vs. speech.pdf:pdf},
isbn = {1505646464},
issn = {09594752},
journal = {Learning and Instruction},
keywords = {Adult second language acquistion,English as a second or foreign language,Second language writing},
pages = {37--53},
pmid = {25246403},
title = {{Developmental relationships in the acquisition of English syntax: Writing vs. speech}},
volume = {10},
year = {2000}
}
@article{Gerber2017a,
author = {Gerber, Florian and Moesinger, Kaspar and Furrer, Reinhard},
doi = {10.1016/j.cageo.2016.11.015},
issn = {0098-3004},
journal = {Computer {\&} Geoscience},
pages = {109--119},
title = {{Extending {\{}R{\}} packages to support 64-bit compiled code: An illustration with spam64 and {\{}GIMMS{\}} {\{}NDVI3g{\}} data}},
volume = {104},
year = {2017}
}
@misc{DeCock,
author = {{De Cock}, Sylvie and Gilquin, Ga{\"{e}}tanelle and Granger, Sylviane},
title = {{Transcription guidelines}},
url = {https://uclouvain.be/en/research-institutes/ilc/cecl/transcription-guidelines.html},
urldate = {2019-05-27}
}
@manual{Gagolewski2019,
author = {Gagolewski, Marek},
title = {{R package stringi: Character string processing facilities}},
url = {http://www.gagolewski.com/software/stringi/},
year = {2019}
}
@book{Bartning2010,
editor = {Bartning, Inge and Martin, Maisa and Vedder, Ineke},
publisher = {European Second Language Association},
title = {{Communicative proficiency and linguistic development : Intersections between SLA and language testing}},
year = {2010}
}
@article{Edmonds2018,
author = {Edmonds, Amanda and Gudmestad, Aarnes},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Edmonds, Gudmestad/Edmonds, Gudmestad{\_}2018{\_}Gender marking in written L2 French.pdf:pdf},
journal = {2Study Abroad Research in Second Language Acquisition and International Education},
number = {1},
pages = {58--83},
title = {{Gender marking in written L2 French}},
volume = {3},
year = {2018}
}
@misc{Halliday1989,
address = {Oxford},
author = {Halliday, M.A.K.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Halliday/Halliday{\_}1989{\_}Spoken and written language.pdf:pdf},
publisher = {Oxford University Press},
title = {{Spoken and written language}},
year = {1989}
}
@book{Fox2019b,
address = {Thousand Oaks {\{}CA{\}}},
author = {Fox, John and Weisberg, Sanford},
edition = {Third},
publisher = {Sage},
title = {{An {\{}R{\}} Companion to Applied Regression}},
url = {https://socialsciences.mcmaster.ca/jfox/Books/Companion/},
year = {2019}
}
@article{Ovtcharov2006,
abstract = {This investigation tests the common intuition that a more fluent second language speaker uses richer vocabulary during oral interaction. It also assesses the capacity of a method called Lexical Frequency Profile (LFP) to distinguish between levels of lexical richness in oral interaction. Two groups of adult Anglophones learning French as a second language (N = 48) were drawn from a pool of civil servants who had obtained a level of French language proficiency required for their positions with the federal government of Canada. The groups were formed based on scores they obtained in the oral interaction section of their proficiency test. These interactions were recorded and transcribed, and the LFP method was used to convert alphabetic into numeric data in order to conduct statistical tests. These showed a significant lexical difference between the productions of the two groups, hence confirming the intuition of lexical difference. {\textcopyright} 2006 The Canadian Modern Language Review/La Revue canadienne des langues vivantes.},
author = {Ovtcharov, Valentin and Cobb, Tom and Halter, Randall},
doi = {10.3138/cmlr.63.1.107},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ovtcharov, Cobb, Halter/Ovtcharov, Cobb, Halter{\_}2006{\_}La richesse lexicale des productions orales Mesure fiable du niveau de comp{\'{e}}tence langagi{\`{e}}re.pdf:pdf},
issn = {00084506},
journal = {Canadian Modern Language Review},
number = {1},
pages = {107--125},
title = {{La richesse lexicale des productions orales: Mesure fiable du niveau de comp{\'{e}}tence langagi{\`{e}}re}},
volume = {63},
year = {2006}
}
@article{Heine2015,
abstract = {and Keywords Linguistic phenomena at all levels display properties of continua and show markedly gradient behavior. While categorical approaches have focused on the endpoints of},
author = {Heine, Bernd and Narrog, Heiko and Bod, Rens},
doi = {10.1093/oxfordhb/9780199677078.013.0025},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Heine, Narrog, Bod/Heine, Narrog, Bod{\_}2015{\_}Probabilistic Linguistics.pdf:pdf},
isbn = {9780199677078},
journal = {The Oxford Handbook of Linguistic Analysis},
keywords = {acquisition,alternations,constructions,data-oriented parsing,frequency,gradience,grammaticality judg,ments,probability model,productive units,universal grammar},
number = {April},
pages = {1--28},
title = {{Probabilistic Linguistics}},
year = {2015}
}
@article{Garner2018a,
abstract = {{\textcopyright} 2018 Walter de Gruyter GmbH, Berlin/Boston 2018. Acommon approach to analyzing phraseological knowledge in first language (L1) and second language (L2) learners is to employ raw frequency data. Several studies have also analyzed n-gram use on the basis of statistical association scores. Results from n-gram studies have found significant differences between L1 and L2 writers and between intermediate and advanced L2 writers in terms of their bigram use. The current study expands on this research by investigating the connection between bigram and trigram association measures and human judgments of L2 writing quality. Using multiple statistical association indices, it examines bigram and trigram use by beginner and intermediate L1 Korean learners of English in English placement test essays. Results of a logistic regression indicated that intermediate writers employed a greater number of strongly associated academic bigrams and spoken trigrams. These findings have important implications for understanding lexical development in L2 writers and notions of writing proficiency.},
author = {Garner, James and Crossley, Scott A. and Kyle, Kristopher},
doi = {10.1515/iral-2017-0089},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Garner, Crossley, Kyle/Garner, Crossley, Kyle{\_}2018{\_}Beginning and intermediate L2 writer's use of N-grams An association measures study.pdf:pdf},
issn = {16134141},
journal = {IRAL - International Review of Applied Linguistics in Language Teaching},
keywords = {L2 writing proficiency,Learner corpus research,N-gram analysis,association measures},
title = {{Beginning and intermediate L2 writer's use of N-grams: An association measures study}},
year = {2018}
}
@article{Baroni2009,
abstract = {This article introduces ukWaC, deWaC and itWaC, three very large corpora of English, German, and Italian built by web crawling, and describes the methodology and tools used in their construction. The corpora contain more than a billion words each, and are thus among the largest resources for the respective languages. The paper also provides an evaluation of their suitability for linguistic research, focusing on ukWaC and itWaC. A comparison in terms of lexical coverage with existing resources for the languages of interest produces encouraging results. Qualitative evaluation of ukWaC vs. the British National Corpus was also conducted, so as to highlight differences in corpus composition (text types and subject matters). The article concludes with practical information about format and availability of corpora and tools.},
author = {Baroni, Marco and Bernardini, Silvia and Ferraresi, Adriano and Zanchetta, Eros},
doi = {10.1007/s10579-009-9081-4},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Baroni et al/Baroni et al.{\_}2009{\_}The waCky wide web A collection of very large linguistically processed web-crawled corpora.pdf:pdf},
isbn = {1057900990},
issn = {1574020X},
journal = {Language Resources and Evaluation},
keywords = {Annotated corpora,Corpus construction,English,General-purpose linguistic resources,German,Italian,WaCky!,Web as corpus},
number = {3},
pages = {209--226},
title = {{The waCky wide web: A collection of very large linguistically processed web-crawled corpora}},
volume = {43},
year = {2009}
}
@manual{Plate2016,
annote = {R package version 1.4-5},
author = {Plate, Tony and Heiberger, Richard},
title = {{abind: Combine Multidimensional Arrays}},
url = {https://cran.r-project.org/package=abind},
year = {2016}
}
@article{Kormos2012,
abstract = {The study reported in this paper investigated the relationship between components of aptitude and the fluency, lexical variety, syntactic complexity, and accuracy of performance in two types of written and spoken narrative tasks. We also addressed the question of how narrative performance varies in tasks of different cognitive complexity in the written and spoken modes. Our findings indicate a complex interaction between aptitude components and task performance under different conditions. The components of aptitude that seemed to be most strongly related to the complexity and accuracy of production were inductive ability and grammatical sensitivity. The results also show that in writing the participants used more varied vocabulary than in speech, but their performance was similar in terms of syntactic complexity. [ABSTRACT FROM AUTHOR]},
author = {Kormos, Judit and Trebits, Anna},
doi = {10.1111/j.1467-9922.2012.00695.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kormos, Trebits/Kormos, Trebits{\_}2012{\_}The Role of Task Complexity, Modality, and Aptitude in Narrative Task Performance.pdf:pdf},
isbn = {1467-9922},
issn = {00238333},
journal = {Language Learning},
keywords = {Aptitude,Individual differences,Second language writing,Speech production,Written and spoken tasks},
number = {2},
pages = {439--472},
title = {{The Role of Task Complexity, Modality, and Aptitude in Narrative Task Performance}},
volume = {62},
year = {2012}
}
@article{David2008,
author = {David, Annabelle},
doi = {10.1017/S0959269508003475},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/David/David{\_}2008{\_}A developmental perspective on productive lexical knowledge in L2 oral interlanguage 1.pdf:pdf},
isbn = {0959269508003},
journal = {French Language Studies},
pages = {315--331},
title = {{A developmental perspective on productive lexical knowledge in L2 oral interlanguage 1}},
volume = {18},
year = {2008}
}
@incollection{Crossley2018,
author = {Crossley, Scott A. and Kyle, Kristopher},
booktitle = {The Palgrave Handbook of Applied Linguistics Research Methodology},
doi = {10.1057/978-1-137-59900-1},
editor = {Phakiti, Aek and {De Costa}, Peter and Plonsky, Luke and Starfield, Sue},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley, Kyle/Crossley, Kyle{\_}2018{\_}Analyzing Spoken and Written Discourse A Role for Natural Language Processing Tools.pdf:pdf},
isbn = {9781137599001},
pages = {567--594},
publisher = {Springer},
title = {{Analyzing Spoken and Written Discourse: A Role for Natural Language Processing Tools}},
year = {2018}
}
@manual{Bivand2019,
annote = {R package version 0.9-5},
author = {Bivand, Roger and Lewin-Koh, Nicholas},
title = {{maptools: Tools for Handling Spatial Objects}},
url = {https://cran.r-project.org/package=maptools},
year = {2019}
}
@article{Modern2020,
author = {Modern, The and Journal, Language},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Modern, Journal/Modern, Journal{\_}2020{\_}Continuing to Explore the Multidimensional Nature of Lexical Sophistication The Case of Oral Proficiency Title Co.pdf:pdf},
keywords = {the modern language journal},
number = {January},
title = {{Continuing to Explore the Multidimensional Nature of Lexical Sophistication : The Case of Oral Proficiency Title : Continuing to Explore the Multidimensional Nature of Lexical Sophistication : The Case of Oral Proficiency Interviews RUNNING HEAD : MULTIDI}},
year = {2020}
}
@incollection{Lesterhuis2017,
address = {Hershey, PA},
author = {Lesterhuis, Marije and Verhavert, San and Coertjens, Liesje and Donche, Vincent and {De Maeyer}, Sven},
booktitle = {Innovative Practices for Higher Education Assessement and Measurement},
editor = {Ion, G. and Cano, E.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lesterhuis et al/Lesterhuis et al.{\_}2017{\_}Comparative Judgement as a Promising Alternative to Score Competences.pdf:pdf},
publisher = {IGI Global},
title = {{Comparative Judgement as a Promising Alternative to Score Competences}},
year = {2017}
}
@article{Johnson2017,
abstract = {This study, a research synthesis and quantitative meta-analysis, contributes to recent L2 writing research on task complexity and its impact on the syntactic complexity, accuracy, lexical complexity, and fluency (CALF) of written L2 production. Through a systematic analysis of task-based L2 writing research from 1998 to the present, the study aimed to better understand (a) how task complexity has been manipulated in previous research, (b) the range of metrics used in previous research to quantify L2 written CALF, and (c) the specific effects of task complexity manipulation on L2 written CALF. The results of the research synthesis indicate that a handful of task complexity features have received a great deal of attention compared to other, less studied task complexity features. Further, the results of the research synthesis suggest that many studies rely on relatively few metrics of CALF, often focusing on metrics of syntactic complexity associated with complex forms more typical of oral language production (Biber, 1988; Biber {\&} Conrad, 2009; Biber {\&} Gray, 2010; Biber, Gray, {\&} Poonpon, 2011, 2013). The results of the quantitative meta-analysis indicate significant effects of increased resource-directing and resource-dispersing features of task complexity on the CALF of written L2 production. The results offer no clear support for the cognition hypothesis (Robinson, 2001, 2003, 2005, 2011), but rather suggest that features of task complexity may promote attention to the formulation and monitoring systems of the writing process (Kellogg, 1996; Kellogg, Whiteford, Turner, Cahill, {\&} Mertens, 2013).},
author = {Johnson, Mark D.},
doi = {10.1016/j.jslw.2017.06.001},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Johnson/Johnson{\_}2017{\_}Cognitive task complexity and L2 written syntactic complexity, accuracy, lexical complexity, and fluency A research synthes.pdf:pdf},
issn = {10603743},
journal = {Journal of Second Language Writing},
keywords = {Accuracy,Cognition hypothesis,Cognitive task complexity,Fluency,Lexical complexity,Limited attentional capacity model,Syntactic complexity,Written production},
number = {June},
pages = {13--38},
publisher = {Elsevier},
title = {{Cognitive task complexity and L2 written syntactic complexity, accuracy, lexical complexity, and fluency: A research synthesis and meta-analysis}},
url = {http://dx.doi.org/10.1016/j.jslw.2017.06.001},
volume = {37},
year = {2017}
}
@manual{Kuhn2019,
annote = {R package version 0.1.6},
author = {Kuhn, Max and Wickham, Hadley},
title = {{recipes: Preprocessing Tools to Create Design Matrices}},
url = {https://cran.r-project.org/package=recipes},
year = {2019}
}
@phdthesis{Dupont2019,
author = {Dupont, Ma{\"{i}}t{\'{e}}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dupont/Dupont{\_}2019{\_}Conjunctive Markers of Contrast in English and French From Syntax to Lexis and Discourse.pdf:pdf},
school = {Universit{\'{e}} catholique de Louvain},
title = {{Conjunctive Markers of Contrast in English and French: From Syntax to Lexis and Discourse}},
type = {Doctoral Dissertation},
year = {2019}
}
@manual{Fox2019a,
annote = {R package version 1.2-3},
author = {Fox, John and Venables, Bill and Damico, Anthony and Salverda, Anne Pier},
title = {{english: Translate Integers into English}},
url = {https://cran.r-project.org/package=english},
year = {2019}
}
@misc{Christensen2019,
annote = {R package version 2019.4-25. http://www.cran.r-project.org/package=ordinal/},
author = {Christensen, R H B},
title = {{ordinal---Regression Models for Ordinal Data}},
year = {2019}
}
@article{Carifo2007,
abstract = {A recent article by Jamieson in Medical Education outlined some of the (alleged) abuses of “Likert scales” with suggestions about how researchers can overcome some of the (alleged) methodological pitfalls and limitations[1]. However, many of the ideas advanced in the Jamison article, as well as a great many of articles it cited, and similar recent articles in medical, health, psychology, and educational journals and books, are themselves common misunderstandings, misconceptions, conceptual errors, persistent myths and “urban legends” about “Likert scales” and their characteristics and qualities that have been propagated and perpetuated across six decades, for a variety of different reasons. This article identifies, analyses and traces many of these aforementioned problems and presents the arguments, counter arguments and empirical evidence that show these many persistent claims and myths about “Likert scales” to be factually incorrect and untrue. Many studies have shown that Likert Scales (as opposed to single Likert response format items) produce interval data and that the F-test is very robust to violations of the interval data assumption and moderate skewing and may be used to analyze “Likert data” (even if it is ordinal), but not on an item-by-item “shotgun” basis, which is simply a current research and analysis practice that must stop. After sixty years, it is more than time to dispel these particular research myths and urban legends as well as the various damage and problems they cause, and put them to bed and out of their misery once and for all},
author = {Carifio, James and Perla, Rocco},
doi = {10.1016/0006-8993(93)90283-S},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Carifio, Perla/Carifio, Perla{\_}2007{\_}Ten Common Misunderstandings, Misconceptions, Persistent Myths and Urban Legends about Likert Scales and Likert Resp.pdf:pdf},
issn = {00068993},
journal = {Journal of Social Sciences},
keywords = {Likert,formats,measurement,psychological,scales},
number = {3},
pages = {106--116},
pmid = {8402188},
title = {{Ten Common Misunderstandings, Misconceptions, Persistent Myths and Urban Legends about Likert Scales and Likert Response Formats and their Antidotes}},
volume = {3},
year = {2007}
}
@manual{Csardi2019a,
annote = {R package version 3.3.1},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and Chang, Winston},
title = {{callr: Call R from R}},
url = {https://cran.r-project.org/package=callr},
year = {2019}
}
@incollection{Ortega2012,
address = {Berlin},
author = {Ortega, Lourdes},
booktitle = {Linguistic complexity: Second language acquisition, indigenization, contact},
editor = {Szmrecsanyi, B. and Kortmann, B.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ortega/Ortega{\_}2012{\_}Interlanguage complexity A construct in search of theoretical renewal.pdf:pdf},
keywords = {complexity},
mendeley-tags = {complexity},
pages = {127--155},
publisher = {de Gruyter},
title = {{Interlanguage complexity: A construct in search of theoretical renewal}},
year = {2012}
}
@article{Ellis2004,
abstract = {Building on previous studies of the effects of planning on second language (L2) learners' oral narratives and drawing on Kellog's (1996) model of writing, this article reports a study of the effects of three types of planning conditions (pretask planning, unpressured on-line planning, and no planning) on 42 Chinese learners' written narratives elicited by means of a picture composition. The results show that, whereas pretask planning resulted in greater fluency (syllables per minute, p {\textless} .01) and greater syntactic variety (number of different verb forms, p {\textless} .01), the opportunity to engage in unpressured on-line planning assisted greater accuracy (error-free clauses, p {\textless} .05). It is proposed that the two types of planning impact on different aspects of L2 writing processes, with pretask planning promoting formulation and unpressured on-line planning providing better opportunities for monitoring. Writers in the no-planning condition were faced with the need to formulate, execute, and monitor under pressure, with negative consequences for the fluency, complexity, and accuracy of the written product in comparison to the planning groups. a},
author = {Ellis, Rod and Yuan, Fangyuan},
doi = {10.1017/S0272263104261034},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, Yuan/Ellis, Yuan{\_}2004{\_}The effects of planning on fluency, complexity, and accuracy in second language narrative writing.pdf:pdf},
isbn = {0272-2631},
issn = {0272-2631},
journal = {Studies in Second Language Acquisition},
keywords = {complexity},
mendeley-tags = {complexity},
number = {1},
pages = {59--84},
pmid = {1},
title = {{The effects of planning on fluency, complexity, and accuracy in second language narrative writing.}},
volume = {26},
year = {2004}
}
@article{Gries2008,
abstract = {In order to adjust observed frequencies of occurrence, previous studies have suggested a variety of measures of dispersion and adjusted frequencies. In a previous study, I reviewed many of these measures and suggested an alternative measure, DP (for 'deviation of proportions'), which I argued to be conceptually simpler and more versatile than many competing measures. However, despite the relevance of dispersion for virtually all corpus-linguistic work, it is still a very much under-researched topic: to the best of my knowledge, there is not a single study investigating how different measures compare to each other when applied to large datasets, nor is there any work that attempts to determine how different measures match up with the kind of psycholinguistic data that dispersions and adjusted frequencies are supposed to represent. This article takes exploratory steps in both of these directions.},
author = {Gries, Stefan Th.},
doi = {10.1163/9789042028012_014},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2008{\_}Dispersions and adjusted frequencies in corpora further explorations.pdf:pdf},
journal = {International Journal of Corpus Linguistics},
pages = {403--437},
title = {{Dispersions and adjusted frequencies in corpora: further explorations}},
volume = {13},
year = {2008}
}
@inproceedings{Nugues2006,
abstract = {The importance of computer learner corpora for research in both second language acquisition and foreign language teaching is rapidly increasing. Computer learner corpora can provide us with data to describe the learner's interlanguage system at different points of its development and they can be used to create pedagogical tools. In this paper, we first present a new computer learner corpora in French. We then describe an analyzer called Direkt Profil, that we have developed using this corpus. The system carries out a sentence analysis based on developmental sequences, i.e. local morphosyntactic phenomena linked to a development in the acquisition of French as a foreign language. We present a brief introduction to developmental sequences and some examples in French. In the final section, we introduce and evaluate a method to optimize the definition and detection of learner profiles using machine-learning techniques.},
annote = {5 layers:
- tokens
- prefabs
- chunk annotation
- tag elements
- acq stage counter},
author = {Nugues, J and Persson, P and Thulin, E and {\AA}gren, J and Schlyter, M},
booktitle = {Proceedings of the 5th International Conference on Language Resources and Evaluation},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Nugues et al/Nugues et al.{\_}2006{\_}CEFLE and Direkt Profil a new computer learner corpus in French L2 and a system for grammatical profiling.pdf:pdf},
keywords = {Granfeldt, Jonas,Nugues, Pierre,Persson, Emil,Schlyter, Suzanne,Thulin, Jonas,{\AA}gren, Malin},
pages = {565--570},
publisher = {ELRA},
title = {{CEFLE and Direkt Profil: a new computer learner corpus in French L2 and a system for grammatical profiling}},
year = {2006}
}
@article{VanDaal2019,
abstract = {Recently, comparative judgement has been introduced as an alternative method for scoring essays. Although this method is promising in terms of obtaining reliable scores, empirical evidence concerning its validity is lacking. The current study examines implications resulting from two critical assumptions underpinning the use of comparative judgement, namely: its holistic characteristic and how the final rank order reflects the shared consensus on what makes for a good essay. Judges' justifications that underpin their decisions are qualitatively analysed to obtain insight into the dimensions of academic writing they take into account. The results show that most arguments are directly related to the competence description. However, judges also use their expertise in order to judge the quality of essays. Additionally, judges differ in terms of how they conceptualise writing quality, and regarding the extent to which they tap into their own expertise. Finally, this study explores diverging conceptualisation of misfitting judges.},
author = {van Daal, Tine and Lesterhuis, Marije and Coertjens, Liesje and Donche, Vincent and {De Maeyer}, Sven},
doi = {10.1080/0969594X.2016.1253542},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/van Daal et al/van Daal et al.{\_}2019{\_}Validity of comparative judgement to assess academic writing examining implications of its holistic character and b.pdf:pdf},
issn = {1465329X},
journal = {Assessment in Education: Principles, Policy and Practice},
keywords = {Comparative judgement,academic writing,assessment,validity},
number = {1},
pages = {59--74},
publisher = {Routledge},
title = {{Validity of comparative judgement to assess academic writing: examining implications of its holistic character and building on a shared consensus}},
url = {http://dx.doi.org/10.1080/0969594X.2016.1253542},
volume = {26},
year = {2019}
}
@manual{Wickham2019h,
annote = {R package version 0.2.2},
author = {Wickham, Hadley},
title = {{lazyeval: Lazy (Non-Standard) Evaluation}},
url = {https://cran.r-project.org/package=lazyeval},
year = {2019}
}
@manual{Csardi2016,
annote = {R package version 1.0.1},
author = {Csardi, Gabor},
title = {{rematch: Match Regular Expressions with a Nicer 'API'}},
url = {https://cran.r-project.org/package=rematch},
year = {2016}
}
@article{Gerber2015,
author = {Gerber, Florian and Furrer, Reinhard},
journal = {Journal of Statistical Software, Code Snippets},
number = {1},
pages = {1--32},
title = {{Pitfalls in the Implementation of {\{}B{\}}ayesian Hierarchical Modeling of Areal Count Data: An Illustration Using {\{}BYM{\}} and {\{}L{\}}eroux Models}},
url = {http://www.jstatsoft.org/v63/c01/},
volume = {63},
year = {2015}
}
@incollection{Robinson2001,
address = {Cambridge},
author = {Robinson, Peter},
booktitle = {Cognition and Second Language Instruction},
editor = {Robinson, Peter},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Robinson/Robinson{\_}2001{\_}Task complexity, cognitive resources and syllabus design a triadic framework for examining task influences on SLA.pdf:pdf},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
pages = {287--318},
publisher = {Cambridge University Press},
title = {{Task complexity, cognitive resources and syllabus design: a triadic framework for examining task influences on SLA}},
year = {2001}
}
@book{Genz2009,
address = {Heidelberg},
author = {Genz, Alan and Bretz, Frank},
isbn = {978-3-642-01688-2},
publisher = {Springer-Verlag},
series = {Lecture Notes in Statistics},
title = {{Computation of Multivariate Normal and t Probabilities}},
year = {2009}
}
@phdthesis{DeClercq2016,
address = {Brussels},
author = {{De Clercq}, Bastien},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/De Clercq/De Clercq{\_}2016{\_}The development of linguistic complexity.pdf:pdf},
school = {(Unpublished doctoral dissertation). Vrije Universiteit Brussel},
title = {{The development of linguistic complexity}},
year = {2016}
}
@manual{Warnes2017,
annote = {R package version 2.18.0},
author = {Warnes, Gregory R and Bolker, Ben and Gorjanc, Gregor and Grothendieck, Gabor and Korosec, Ales and Lumley, Thomas and MacQueen, Don and Magnusson, Arni and Rogers, Jim and Others},
title = {{gdata: Various R Programming Tools for Data Manipulation}},
url = {https://cran.r-project.org/package=gdata},
year = {2017}
}
@article{Pollitt2012,
author = {Pollitt, Alastair},
doi = {10.1080/0969594X.2012.665354},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Pollitt/Pollitt{\_}2012{\_}The method of Adaptive Comparative Judgement.pdf:pdf},
journal = {Assessment in Education: Principles, Policy {\&} Practice},
number = {3},
pages = {281--300},
title = {{The method of Adaptive Comparative Judgement}},
volume = {19},
year = {2012}
}
@book{Hanks2013,
address = {Cambridge MA},
author = {Hanks, Patrick},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hanks/Hanks{\_}2013{\_}Lexical Analysis.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hanks/Hanks{\_}2013{\_}Lexical Analysis(2).pdf:pdf},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
publisher = {The MIT Press},
title = {{Lexical Analysis}},
year = {2013}
}
@manual{Tuszynski2019,
annote = {R package version 1.17.1.2},
author = {Tuszynski, Jarek},
title = {{caTools: Tools: moving window statistics, GIF, Base64, ROC AUC, etc.}},
url = {https://cran.r-project.org/package=caTools},
year = {2019}
}
@article{Wood2004,
author = {Wood, S N},
journal = {Journal of the American Statistical Association},
number = {467},
pages = {673--686},
title = {{Stable and efficient multiple smoothing parameter estimation for generalized additive models}},
volume = {99},
year = {2004}
}
@manual{Ooms2019,
annote = {R package version 4.0},
author = {Ooms, Jeroen},
title = {{curl: A Modern and Flexible Web Client for R}},
url = {https://cran.r-project.org/package=curl},
year = {2019}
}
@article{Biber2004,
abstract = {This paper investigates the use of multi-word sequences in two important$\backslash$nuniversity registers: classroom teaching and textbooks. Following$\backslash$nBiber et al. (1999), we take a frequency-driven approach to the identification$\backslash$nof multi-word sequences, referred to as lexical bundles'. We compare$\backslash$nthe lexical bundles in classroom teaching and textbooks to those$\backslash$nfound in our previous research on conversation and academic prose.$\backslash$nStructural patterns are described first, and then we present a functional$\backslash$ntaxonomy, including stance expressions, discourse organizers, and$\backslash$nreferential expressions. The use of lexical bundles in classroom$\backslash$nteaching turns out to be especially surprising, both in frequency$\backslash$nand in function. Classroom teaching uses more stance and discourse$\backslash$norganizing bundles than conversation does, but at the same time,$\backslash$nclassroom teaching uses more referential bundles than academic prose.$\backslash$nThe analysis indicates that lexical bundles--the most frequent sequences$\backslash$nof words in a register--are a unique linguistic construct. Lexical$\backslash$nbundles are usually not complete grammatical structures nor are they$\backslash$nidiomatic, but they function as basic building blocks of discourse.$\backslash$nIn the conclusion, we discuss the implications of our study for the$\backslash$ntheoretical status of lexical bundles.},
author = {Biber, Douglas and Conrad, Susan and Cortes, Viviana},
doi = {10.1093/applin/25.3.371},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Biber, Conrad, Cortes/Biber, Conrad, Cortes{\_}2004{\_}If you look at ... Lexical bundles in university teaching and textbooks(2).pdf:pdf},
isbn = {0142-6001},
issn = {01426001},
journal = {Applied Linguistics},
number = {3},
pages = {371--405},
pmid = {15363903},
title = {{If you look at ...: Lexical bundles in university teaching and textbooks}},
volume = {25},
year = {2004}
}
@techreport{Candito2009,
author = {Candito, Marie and Beno{\^{i}}t, Crabb{\'{e}} and Falco, Mathieu},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Candito, Beno{\^{i}}t, Falco/Candito, Beno{\^{i}}t, Falco{\_}2009{\_}D{\'{e}}pendances syntaxiques de surface pour le fran{\c{c}}ais Sch{\'{e}}ma d'annotation pour un corpus en d{\'{e}}pendances.pdf:pdf},
institution = {Universit{\'{e}} Paris 7},
title = {{D{\'{e}}pendances syntaxiques de surface pour le fran{\c{c}}ais: Sch{\'{e}}ma d'annotation pour un corpus en d{\'{e}}pendances obtenu par conversion du FrenchTreebank}},
url = {http://alpage.inria.fr/statgram/frdep/Publications/FTB-GuideDepSurface.pdf},
year = {2009}
}
@incollection{Ellis2005,
address = {Amsterdam},
author = {Ellis, Rod and Yuan, Fangyuan},
booktitle = {Planning and Task Performance in a Second Language},
editor = {Ellis, Rod},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, Yuan/Ellis, Yuan{\_}2005{\_}The effects of careful within-task planning on oral and written task performance.pdf:pdf},
pages = {167--192},
publisher = {John Benjamins},
title = {{The effects of careful within-task planning on oral and written task performance}},
year = {2005}
}
@manual{Dragulescu2014,
annote = {R package version 0.6.1},
author = {Dragulescu, Adrian A},
title = {{xlsxjars: Package required POI jars for the xlsx package}},
url = {https://cran.r-project.org/package=xlsxjars},
year = {2014}
}
@article{Hothorn2008a,
author = {Hothorn, Torsten and Hornik, Kurt and van de Wiel, Mark A and Zeileis, Achim},
doi = {10.18637/jss.v028.i08},
journal = {Journal of Statistical Software},
number = {8},
pages = {1--23},
title = {{Implementing a class of permutation tests: The {\{}coin{\}} package}},
volume = {28},
year = {2008}
}
@manual{Tremblay2013,
annote = {R package version 2.0},
author = {Tremblay, Antoine and of Psychology, Department and University, Dalhousie},
title = {{LCFdata: Data sets for package ``LMERConvenienceFunctions''}},
url = {https://cran.r-project.org/package=LCFdata},
year = {2013}
}
@phdthesis{Vanderbauwhede2012,
author = {Vanderbauwhede, Gudrun},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Vanderbauwhede/Vanderbauwhede{\_}2012{\_}Le déterminant démonstratif en français et en néerlandais à travers les corpus Théorie, description, ac.pdf:pdf},
keywords = {LCF},
mendeley-tags = {LCF},
school = {(Unpublished Doctoral Dissertation). Katholieke Universiteit Leuven and Université Paris Ouest Nanterre La Défense},
title = {{Le déterminant démonstratif en français et en néerlandais à travers les corpus : Théorie, description, acquisition [The demonstrative determiner in French and Dutch corpora: Theory, description and acquisition]}},
year = {2012}
}
@manual{Xie2019d,
annote = {R package version 0.15},
author = {Xie, Yihui},
title = {{tinytex: Helper Functions to Install and Maintain 'TeX Live', and Compile 'LaTeX' Documents}},
url = {https://cran.r-project.org/package=tinytex},
year = {2019}
}
@manual{Ushey2020,
annote = {R package version 1.16},
author = {Ushey, Kevin and Allaire, J J and Tang, Yuan},
title = {{reticulate: Interface to 'Python'}},
url = {https://cran.r-project.org/package=reticulate},
year = {2020}
}
@manual{Kuhn2018,
annote = {R package version 0.0.2},
author = {Kuhn, Max and Wickham, Hadley and Vaughan, Davis},
title = {{generics: Common S3 Generics not Provided by Base R Methods Related to Model Fitting}},
url = {https://cran.r-project.org/package=generics},
year = {2018}
}
@article{Marti2019,
author = {Mart{\'{i}}, Maria Ant{\`{o}}nia and Taul{\'{e}}, Mariona and Kovatchev, Venelin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mart{\'{i}}, Taul{\'{e}}, Kovatchev/Mart{\'{i}}, Taul{\'{e}}, Kovatchev{\_}2019{\_}DISCOver DIStributional approach based on syntactic dependencies for discovering preprint.pdf:pdf},
journal = {Corpus Linguistics and Linguistic Theory},
keywords = {amarti,barcelona,constructions,corresponding author,distributional semantic models,e-mail,edu,filologia catalana i ling{\"{u}}{\'{i}}stica,general,linguistics,maria ant{\`{o}}nia mart{\'{i}},mariona taul{\'{e}},mtaule,semantics,spain,ub,universitat de barcelona,university of barcelona},
pages = {1--33},
title = {{DISCOver : DIStributional approach based on syntactic dependencies for discovering [preprint]}},
year = {2019}
}
@techreport{Martin1988,
author = {Martin, {\'{E}}velyne},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Martin/Martin{\_}1988{\_}Frantext La base de donn{\'{e}}es textuelles du fran{\c{c}}ais de l'INaLF.pdf:pdf},
institution = {EPN},
keywords = {frantext},
mendeley-tags = {frantext},
title = {{Frantext: La base de donn{\'{e}}es textuelles du fran{\c{c}}ais de l'INaLF}},
year = {1988}
}
@manual{Loden2018,
annote = {R package version 1.3.0},
author = {Loden, Jay and Daeschler, Dave and Rodola', Giampaolo and Cs{\'{a}}rdi, G{\'{a}}bor},
title = {{ps: List, Query, Manipulate System Processes}},
url = {https://cran.r-project.org/package=ps},
year = {2018}
}
@manual{Ushey2019,
annote = {R package version 0.10},
author = {Ushey, Kevin and Allaire, J J and Wickham, Hadley and Ritchie, Gary},
title = {{rstudioapi: Safely Access the RStudio API}},
url = {https://cran.r-project.org/package=rstudioapi},
year = {2019}
}
@manual{Dowle2019,
annote = {R package version 1.12.2},
author = {Dowle, Matt and Srinivasan, Arun},
title = {{data.table: Extension of `data.frame`}},
url = {https://cran.r-project.org/package=data.table},
year = {2019}
}
@article{Furrer2010,
author = {Furrer, Reinhard and Sain, Stephan R},
journal = {Journal of Statistical Software},
number = {10},
pages = {1--25},
title = {{{\{}spam{\}}: A Sparse Matrix {\{}R{\}} Package with Emphasis on {\{}MCMC{\}} Methods for {\{}G{\}}aussian {\{}M{\}}arkov Random Fields}},
url = {http://www.jstatsoft.org/v36/i10/},
volume = {36},
year = {2010}
}
@article{Halekoh2014,
author = {Halekoh, Ulrich and H{\o}jsgaard, S{\o}ren},
journal = {Journal of Statistical Software},
number = {9},
pages = {1--30},
title = {{A Kenward-Roger Approximation and Parametric Bootstrap Methods for Tests in Linear Mixed Models -- The {\{}R{\}} Package {\{}pbkrtest{\}}}},
url = {http://www.jstatsoft.org/v59/i09/},
volume = {59},
year = {2014}
}
@article{Gries2018,
abstract = {This paper critically discusses how corpus linguistics in general, but learner corpus research in particular, has been dealing with all sorts of frequency data in general, but over-and underuse frequencies in particular. I demonstrate on the basis of learner corpus data the pitfalls of using aggregate data and lacking statistical control that much work is unfortunately characterized by. In fact, I will demonstrate that monofactorial methods have very little to offer at all to research on observational data. While this paper is admittedly very didactic and methodological, I think the discussion of the empirical data offered here-a reanalysis of previously published work-shows how misleading many studies potentially and provides far-reaching implications for much of corpus linguistics and learner corpus research. Ideally/maxi-mally, this paper together with Paquot {\&} Plonsky (2017, Intntl. J. of Learner Corpus Research) would lead to a complete revision of how learner corpus linguists use quantitative methods and study over-/underuse; minimally, this paper would stimulate a much-needed discussion of currently lacking methodological sophistication.},
author = {Gries, Stefan Th.},
doi = {10.1075/jsls.00005.gri},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2018{\_}On over- and underuse in learner corpus research and multifactoriality in corpus linguistics more generally.pdf:pdf},
journal = {Journal of Second Language Studies},
keywords = {file variation,learner corpora,multifactorial analysis,speaker,stats},
mendeley-tags = {stats},
pages = {276--308},
title = {{On over- and underuse in learner corpus research and multifactoriality in corpus linguistics more generally}},
volume = {12},
year = {2018}
}
@incollection{Koch2001,
address = {T{\"{u}}bingen},
author = {Koch, P and Oesterreicher, W},
booktitle = {Lexikon der Romantischen Linguistk},
editor = {Holtus, G. and Metzeltin, M. and Schmitt, C.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Koch, Oesterreicher/Koch, Oesterreicher{\_}2001{\_}Langage parl{\'{e}} et langage {\'{e}}crit.pdf:pdf},
pages = {584--627},
publisher = {Niemeyer},
title = {{Langage parl{\'{e}} et langage {\'{e}}crit}},
year = {2001}
}
@article{Mitchell2019,
author = {Mitchell, Rosamond and Myles, Florence},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mitchell, Myles/Mitchell, Myles{\_}2019{\_}Learning French in the UK setting Policy, classroom engagement and attainable learning outcomes (in press).pdf:pdf},
journal = {Apples : Journal of Applied Language Studies},
number = {1},
title = {{Learning French in the UK setting : Policy, classroom engagement and attainable learning outcomes (in press)}},
volume = {13},
year = {2019}
}
@article{Blanche-benveniste2007,
annote = {subordination and weak verbs (from veronique 2017)},
author = {Blanche-Benveniste, Claire and Willems, Dominique},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Blanche-Benveniste, Willems/Blanche-Benveniste, Willems{\_}2007{\_}Un nouveau regard sur les verbes «faibles».pdf:pdf},
journal = {Bulletin de la Soci{\'{e}}t{\'{e}} de linguistique de Paris},
number = {1},
pages = {217--254},
title = {{Un nouveau regard sur les verbes «faibles»}},
volume = {102},
year = {2007}
}
@inproceedings{Candito2010,
abstract = {We first describe the automatic conversion of the French Treebank (Abeill{\{}{\'{e}}{\}} and Barrier, 2004), a constituency treebank, into typed projective dependency trees. In order to evaluate the overall quality of the resulting dependency treebank, and to quantify the cases where the projectivity constraint leads to wrong dependencies, we compare a subset of the converted treebank to manually validated dependency trees. We then compare the performance of two treebank-trained parsers that output typed dependency parses. The first parser is the MST parser (McDonald et al., 2006), which we directly train on dependency trees. The second parser is a combination of the Berkeley parser (Petrov et al., 2006) and a functional role labeler: trained on the original constituency treebank, the Berkeley parser first outputs constituency trees, which are then labeled with functional roles, and then converted into dependency trees. We found that used in combination with a high-accuracy French POS tagger, the MST parser performs a little better for unlabeled dependencies (UAS=90.3{\{}{\%}{\}} versus 89.6{\{}{\%}{\}}), and better for labeled dependencies (LAS=87.6{\{}{\%}{\}} versus 85.6{\{}{\%}{\}}).},
author = {Candito, Marie and Crabb{\'{e}}, Beno{\^{i}}t and Denis, Pascal},
booktitle = {Proceedings of the 7th International Conference on Language Resources and Evaluation, LREC'10},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Candito, Crabb{\'{e}}, Denis/Candito, Crabb{\'{e}}, Denis{\_}2010{\_}Statistical French dependency parsing treebank conversion and first results.pdf:pdf},
isbn = {2-9517408-6-7},
keywords = {dependency parsing,statistical parsing},
pages = {1840--1847},
title = {{Statistical French dependency parsing: treebank conversion and first results}},
url = {https://hal.inria.fr/hal-00495196/},
year = {2010}
}
@article{Pebesma2005,
author = {Pebesma, Edzer J and Bivand, Roger S},
journal = {R News},
month = {nov},
number = {2},
pages = {9--13},
title = {{Classes and methods for spatial data in {\{}R{\}}}},
url = {https://cran.r-project.org/doc/Rnews/},
volume = {5},
year = {2005}
}
@article{Norris2009,
abstract = {In this article, we examine current practices in the measurement of syntactic complexity to illustrate the need for more organic and sustainable practices in the measurement of complexity, accuracy, and fluency (CAF) in second language production. Through in-depth review of examples drawn from research on instructed second language acquisition, we identify and discuss challenges to the evidentiary logic that underlies current approaches. We also illuminate critical mismatches between the interpretations that researchers want to make and the complexity measures that they use to make them. Building from the case of complexity, we point to related concerns with impoverished operationalizations of multidimensional CAF constructs and the lack of attention to CAF as a dynamic and interrelated set of constantly changing subsystems. In conclusion, we offer suggestions for addressing these challenges, and we call for much closer articulation between theory and measurement as well as more central roles for multidimensionality and dynamicity in future CAF research.},
author = {Norris, John M. and Ortega, Lourdes},
doi = {10.1093/applin/amp044},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Norris, Ortega/Norris, Ortega{\_}2009{\_}Towards an organic approach to investigating CAF in instructed SLA The case of complexity.pdf:pdf},
isbn = {0142-6001},
issn = {01426001},
journal = {Applied Linguistics},
number = {4},
pages = {555--578},
title = {{Towards an organic approach to investigating CAF in instructed SLA: The case of complexity}},
volume = {30},
year = {2009}
}
@article{Conklin2012,
abstract = {It is generally accepted that we store representations of individual words in our mental lexicon. There is growing agreement that the lexicon also contains formulaic language (How are you? kick the bucket). In fact, there are compelling reasons to think that the brain represents formulaic sequences in long-term memory, bypassing the need to compose them online through word selection and grammatical sequencing in capacity-limited working memory. The research surveyed in this chapter strongly supports the position that there is an advantage in the way that native speakers process formulaic language compared to nonformulaic language. This advantage extends to the access and use of different types of formulaic language, including idioms, binomials, collocations, and lexical bundles. However, the evidence is mixed for nonnative speakers. While very proficient nonnatives sometimes exhibit processing advantages similar to natives, less proficient learners often have been shown to process formulaic language in a word-by-word manner similar to nonformulaic language. Furthermore, if the formulaic language is idiomatic (where the meaning cannot be understood from the component words), the figurative meanings can be much more difficult to process for nonnatives than nonidiomatic, nonformulaic language.},
author = {Conklin, Kathy and Schmitt, Norbert},
doi = {10.1017/S0267190512000074},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Conklin, Schmitt/Conklin, Schmitt{\_}2012{\_}The processing of formulaic language.pdf:pdf},
isbn = {0267-1905},
issn = {0267-1905},
journal = {Annual Review of Applied Linguistics},
keywords = {formulaic language},
mendeley-tags = {formulaic language},
pages = {45--61},
pmid = {17475768},
title = {{The processing of formulaic language}},
url = {http://www.journals.cambridge.org/abstract{\_}S0267190512000074},
volume = {32},
year = {2012}
}
@article{Hunt1970,
author = {Hunt, Kellogg},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hunt/Hunt{\_}1970{\_}Do sentences in the second language grow like those in the first.pdf:pdf},
journal = {TESOL Quarterly1},
number = {3},
pages = {195--202},
title = {{Do sentences in the second language grow like those in the first?}},
volume = {4},
year = {1970}
}
@manual{Couture-Beil2018,
annote = {R package version 0.2.20},
author = {Couture-Beil, Alex},
title = {{rjson: JSON for R}},
url = {https://cran.r-project.org/package=rjson},
year = {2018}
}
@inproceedings{Schafer2015,
address = {Mannheim},
author = {Sch{\"{a}}fer, Roland},
booktitle = {Proceedings of the 3rd Workshop on Challenges in the Management of Large Corpora (CMLC-3)},
editor = {Ba{\'{n}}ski, Piotr; and Biber, Hanno; and Breiteneder, Evelyn; and Kupietz, Marc; and L{\"{u}}ngen, Harald; and Witt, Andreas},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Sch{\"{a}}fer/Sch{\"{a}}fer{\_}2015{\_}Processing and querying large web corpora with the COW14 architecture.pdf:pdf},
pages = {28--34},
publisher = {Institute fur Deutsche Sprache},
title = {{Processing and querying large web corpora with the COW14 architecture}},
year = {2015}
}
@book{Heine2015a,
abstract = {After introducing central questions of modern valency theory (valency relations, valency carrier, valency and language structure, valency dynamics) and results of applied valency research, central questions of modern dependency grammar are addressed such as features of a pure dependency grammar, different notions of dependency, headedness, dependency and constituency. The chapter also comments on the metatheoretical issues of autonomy, adequacy and the optimal format of a syntactic theory.},
author = {Heine, Bernd and Narrog, Heiko and {\'{A}}gel, Vilmos and Fischer, Klaus},
booktitle = {The Oxford Handbook of Linguistic Analysis},
doi = {10.1093/oxfordhb/9780199677078.013.0010},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Heine et al/Heine et al.{\_}2015{\_}Dependency Grammar and Valency Theory.pdf:pdf},
isbn = {9780199677078},
keywords = {complement,dependency grammar,dependency relations,historical adequa,micro valency,principle of syntactic autonomy,typological adequacy,valency modification and alteration,valency relations,valency theory},
number = {April 2020},
pages = {1--35},
title = {{Dependency Grammar and Valency Theory}},
year = {2015}
}
@manual{Wickham2019j,
annote = {R package version 1.4.0},
author = {Wickham, Hadley},
title = {{stringr: Simple, Consistent Wrappers for Common String Operations}},
url = {https://cran.r-project.org/package=stringr},
year = {2019}
}
@manual{Qiu2019,
annote = {R package version 0.8},
author = {Qiu, Yixuan and Xie, Yihui},
title = {{highr: Syntax Highlighting for R Source Code}},
url = {https://cran.r-project.org/package=highr},
year = {2019}
}
@misc{ATILF-CNRS2020,
address = {Nancy},
author = {ATILF-CNRS and {Universit{\'{e}} de Lorraine}},
keywords = {frantext},
mendeley-tags = {frantext},
title = {{Base textuelle Frantext (En ligne)}},
url = {www.frantext.fr},
year = {2020}
}
@article{Lachaud2007,
abstract = {L'{\^{a}}ge d'acquisition et la familiarit{\'{e}} d'un mot sont des facteurs d{\'{e}}cisifs pour l'acc{\`{e}}s au lexique, en production comme en perception. Pour favoriser les recherches sur les m{\'{e}}canismes du traitement lexical en Fran{\c{c}}ais, une base de donn{\'{e}}es lexicales a {\'{e}}t{\'{e}} constitu{\'{e}}e pour un corpus de 1225 mots monosyllabiques et bisyllabiques du Fran{\c{c}}ais. Cet article d{\'{e}}crit la m{\'{e}}thode utilis{\'{e}}e pour le recueil des donn{\'{e}}es, l'information brute obtenue, la proc{\'{e}}dure pour traiter cette information brute, et le contenu de la base de donn{\'{e}}es CHACQFAM obtenu apr{\`{e}}s traitement de l'information brute, ainsi que les proc{\'{e}}dures de validation de ce contenu. CHACQFAM est disponible gratuitement sur le site Internet « http://psycholinguistique.unige.ch/ ». Mots-cl{\'{e}}},
author = {Lachaud, Christian Michel},
doi = {10.4074/s0003503307001030},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lachaud/Lachaud{\_}2007{\_}CHACQFAM une base de donn{\'{e}}es renseignant l'{\^{a}}ge d'acquisition estim{\'{e}} et la familiarit{\'{e}} pour 1225 mots monosyllabiq.pdf:pdf},
issn = {0003-5033},
journal = {L'Ann{\'{e}}e psychologique},
number = {01},
pages = {39},
title = {{CHACQFAM : une base de donn{\'{e}}es renseignant l'{\^{a}}ge d'acquisition estim{\'{e}} et la familiarit{\'{e}} pour 1225 mots monosyllabiques et bisyllabiques du Fran{\c{c}}ais}},
volume = {107},
year = {2007}
}
@article{Wickham2019a,
author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c{c}}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"{u}}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
doi = {10.21105/joss.01686},
journal = {Journal of Open Source Software},
number = {43},
pages = {1686},
title = {{Welcome to the tidyverse}},
volume = {4},
year = {2019}
}
@article{Verspoor2012,
abstract = {The goal of this study was to explore the contribution that a dynamic usage based (DUB) perspective can bring to the establishment of objective measures to assess L2 learners' written texts and at the same time to gain insight into the dynamic process of language development. Four hundred and thirty seven texts written by Dutch learners of English as an L2 with similar backgrounds were holistically coded for proficiency level, which ranged from beginner to intermediate (A1.1 to B1.2 according to the Common European Framework of Reference). Each text was hand coded for 64 variables as distilled from the literature at sentence, phrase, and word level. Statistical analyses showed that broad, frequently occurring, measures known to distinguish between proficiency levels of writing expertise did so in this corpus too: sentence length, the Guiraud index, all dependent clauses combined, all chunks combined, all errors combined, and the use of present and past tense. However, almost all specific constructions showed non-linear development, variation, and changing relationships among the variables as one would expect from a dynamic usage based perspective. Between levels 1 and 2 mainly lexical changes took place, between levels 2 and 3 mainly syntactic changes occurred, and between levels 3 and 4 both lexical and syntactic changes appeared. The transition between levels 4 and 5 was characterized by lexical changes only: particles, compounds, and fixed phrases. The study shows that even short writing samples can be useful in assessing general proficiency at the lower levels of L2 proficiency and that a cross-sectional study of samples at different proficiency levels can give worthwhile insights into dynamic L2 developmental patterns.},
author = {Verspoor, Marjolijn and Schmid, Monika S. and Xu, Xiaoyan},
doi = {10.1016/j.jslw.2012.03.007},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Verspoor, Schmid, Xu/Verspoor, Schmid, Xu{\_}2012{\_}A dynamic usage based perspective on L2 writing.pdf:pdf},
issn = {10603743},
journal = {Journal of Second Language Writing},
keywords = {Accuracy,Complexity,Developmental variables,Dynamic,L2 writing,Objective measures,Usage based},
month = {sep},
number = {3},
pages = {239--263},
title = {{A dynamic usage based perspective on L2 writing}},
url = {http://www.sciencedirect.com/science/article/pii/S1060374312000240},
volume = {21},
year = {2012}
}
@inproceedings{Schafer2013,
address = {Lancaster},
author = {Sch{\"{a}}fer, Roland and Barbaresi, Adrien and Bildhauer, Felix},
booktitle = {8th Web as Corpus Workshop},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Sch{\"{a}}fer, Barbaresi, Bildhauer/Sch{\"{a}}fer, Barbaresi, Bildhauer{\_}2013{\_}The Good , the Bad , and the Hazy Design Decisions in Web Corpus Construction(2).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Sch{\"{a}}fer, Barbaresi, Bildhauer/Sch{\"{a}}fer, Barbaresi, Bildhauer{\_}2013{\_}The Good , the Bad , and the Hazy Design Decisions in Web Corpus Construction.pdf:pdf},
month = {jul},
pages = {7--15},
publisher = {ACL SIGWAC},
title = {{The Good , the Bad , and the Hazy : Design Decisions in Web Corpus Construction}},
year = {2013}
}
@book{Biber1999,
address = {London},
author = {Biber, Douglas and Leech, G and Johansson, S and Conrad, S},
publisher = {Longman},
title = {{Longman grammar of spoken and written English}},
year = {1999}
}
@manual{Spector2016,
annote = {R package version 1.4.1},
author = {Spector, Phil and Friedman, Jerome and Tibshirani, Robert and Lumley, Thomas and Garbett, Shawn and Baron, Jonathan},
title = {{acepack: ACE and AVAS for Selecting Multiple Regression Transformations}},
url = {https://cran.r-project.org/package=acepack},
year = {2016}
}
@manual{Therneau2019,
annote = {R package version 4.1-15},
author = {Therneau, Terry and Atkinson, Beth},
title = {{rpart: Recursive Partitioning and Regression Trees}},
url = {https://cran.r-project.org/package=rpart},
year = {2019}
}
@article{Zalbidea2017,
abstract = {The present study explores the independent and interactive effects of task complexity and task modality on linguistic dimensions of second language (L2) performance and investigates how these effects are modulated by individual differences in working memory capacity. Thirty-two intermediate learners of L2 Spanish completed less and more complex versions of the same type of argumentative task in the speaking and writing modalities. Perceived complexity questionnaires were administered as measures of cognitive load to both L2 learners and native speakers to independently validate task complexity manipulations. Task performance was analyzed in terms of general (complexity and accuracy) as well as task-relevant (conjunctions) linguistic measures. Quantitative analyses revealed that task modality played a larger role than task complexity in inducing improved linguistic performance during task-based work: Speaking tasks brought about more syntactically complex output while writing tasks favored more lexically complex and more accurate language. In addition, relationships of working memory capacity with various linguistic measures were attested, but only when the cognitive complexity of tasks was enhanced.},
author = {Zalbidea, Janire},
doi = {10.1111/modl.12389},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Zalbidea/Zalbidea{\_}2017{\_}‘One Task Fits All' The roles of task complexity, modality, and working memory capacity in L2 performance.pdf:pdf},
issn = {15404781},
journal = {Modern Language Journal},
keywords = {modality,task complexity,working memory},
number = {2},
pages = {335--352},
title = {{‘One Task Fits All'? The roles of task complexity, modality, and working memory capacity in L2 performance}},
volume = {101},
year = {2017}
}
@article{Polio2003,
abstract = {Because a literature review revealed that the descriptions of measures of linguistic accuracy in research on second language writing are often inadequate and their reliabilities often not reported, I completed an empirical study comparing 3 measures. The study used a holistic scale, error-free T-units, and an error classification system on the essays of English as a second language (ESL) students. I present detailed discussion of how each measure was implemented, give intra- and interrater reliabilities and discuss why disagreements arose within a rater and between raters. The study will provide others doing research in the area of L2 writing with a comprehensive description that will help them select and use a measure of linguistic accuracy.},
author = {Polio, Charlene G.},
doi = {10.1111/0023-8333.31997003},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Polio/Polio{\_}2003{\_}Measures of Linguistic Accuracy in Second Language Writing Research.pdf:pdf},
journal = {Language Learning},
number = {1},
pages = {101--143},
title = {{Measures of Linguistic Accuracy in Second Language Writing Research}},
volume = {47},
year = {2003}
}
@article{Stefanowitsch2003,
abstract = {This paper introduces an extension of collocational analysis that takes into account grammatical structure and is specifically geared to investigating the interaction of lexemes and the grammatical constructions associated with them. The method is framed in a construction-based approach to language, i.e. it assumes that grammar consists of signs (form-meaning pairs) and is thus not fundamentally different from the lexicon. The method is applied to linguistic expressions at various levels of abstraction (words, semi-fixed phrases, argument structures, tense, aspect and mood). The method has two main applications: first, to increase the adequacy of grammatical description by providing an objective way of identifying the meaning of a grammatical construction and determining the degree to which particular slots in it prefer or are restricted to a particular set of lexemes; second, to provide data for linguistic theory-building.},
author = {Stefanowitsch, Anatol and Gries, Stefan Th.},
doi = {10.1075/ijcl.8.2.03ste},
issn = {1384-6655},
journal = {International Journal of Corpus Linguistics},
keywords = {collocation,construction,construction grammar,fisher exact,syntax-lexis interface,test},
number = {2},
pages = {209--243},
title = {{Collostructions: Investigating the interaction of words and constructions}},
volume = {8},
year = {2003}
}
@manual{Allaire2019,
annote = {R package version 1.1},
author = {Allaire, J J and Horner, Jeffrey and Xie, Yihui and Marti, Vicent and Porte, Natacha},
title = {{markdown: Render Markdown with the C Library 'Sundown'}},
url = {https://cran.r-project.org/package=markdown},
year = {2019}
}
@article{Csardi2006,
author = {Csardi, Gabor and Nepusz, Tamas},
journal = {InterJournal (Complex Systems)},
keywords = {igraph},
mendeley-tags = {igraph},
title = {{The igraph software package for complex network research}},
year = {2006}
}
@manual{survival-package,
annote = {version 2.38},
author = {Therneau, Terry M},
title = {{A Package for Survival Analysis in S}},
url = {https://cran.r-project.org/package=survival},
year = {2015}
}
@article{New2001,
author = {New, Boris and Pallier, C and Ferrand, L and Matos, R},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/New et al/New et al.{\_}2001{\_}Une base de donn{\'{e}}es lexicales du fran{\c{c}}ais contemporain sur internet LEXIQUE.pdf:pdf},
journal = {L'Ann{\'{e}}e Psychologique},
keywords = {lexique3},
mendeley-tags = {lexique3},
pages = {447--462},
title = {{Une base de donn{\'{e}}es lexicales du fran{\c{c}}ais contemporain sur internet: LEXIQUE}},
volume = {101},
year = {2001}
}
@incollection{Weissberg2005,
address = {New York},
author = {Weissberg, Bob},
booktitle = {Second Language Writing Research : Perspectives on the Process of Knowledge Construction},
editor = {Matsuda, Paul Kei and Silva, Tony},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Weissberg/Weissberg{\_}2005{\_}Talking about Writing Cross-Modality Research and Second Language SpeakingWriting Connections.pdf:pdf},
pages = {67--74},
publisher = {Routledge},
title = {{Talking about Writing: Cross-Modality Research and Second Language Speaking/Writing Connections}},
year = {2005}
}
@book{Gougenheim1964,
address = {Paris},
author = {Gougenheim, George and Mich{\'{e}}a, R and Rivenc, P and Sauvageot, A},
edition = {Nouvelle {\'{e}}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gougenheim et al/Gougenheim et al.{\_}1964{\_}L'{\'{e}}laboration du fran{\c{c}}ais fondamental, (1er degr{\'{e}}) {\'{e}}tude sur l'{\'{e}}tablissement d'un vocabulaire et d'une gram.pdf:pdf},
publisher = {Didier},
title = {{L'{\'{e}}laboration du fran{\c{c}}ais fondamental, (1er degr{\'{e}}) : {\'{e}}tude sur l'{\'{e}}tablissement d'un vocabulaire et d'une grammaire de base.}},
year = {1964}
}
@incollection{Klein2003,
address = {Cambridge MA},
author = {Klein, D. and Manning, C.},
booktitle = {Advances in Neural Information Processing Systems 15},
editor = {Becker, S. and Thrun, S. and Obermayer, K.},
keywords = {stanford parser},
mendeley-tags = {stanford parser},
pages = {3--10},
publisher = {MIT Press},
title = {{Fast exact inference with a factored model for natural language parsing}},
year = {2003}
}
@book{Cohen1988,
address = {New York},
author = {Cohen, Jacob},
booktitle = {Hillsdale, NJ: Laurence Erlbaum and Associates},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cohen/Cohen{\_}1988{\_}Statistical Power for the Behavioral Sciences (2nd Edition).pdf:pdf},
isbn = {0-8058-0283-5},
publisher = {Lawrence Erlbaum Associates},
title = {{Statistical Power for the Behavioral Sciences (2nd Edition)}},
year = {1988}
}
@manual{Henry2020c,
annote = {R package version 0.2.0},
author = {Henry, Lionel},
title = {{lifecycle: Manage the Life Cycle of your Package Functions}},
url = {https://cran.r-project.org/package=lifecycle},
year = {2020}
}
@manual{Lenth2018,
annote = {R package version 1.3},
author = {Lenth, Russell},
title = {{estimability: Tools for Assessing Estimability of Linear Predictions}},
url = {https://cran.r-project.org/package=estimability},
year = {2018}
}
@article{Way2000,
abstract = {This study investigated the effects of 3 different writing tasks (descriptive, narrative, and expository) and 3 different writing prompts (bare, vocabulary, and prose model) on 937 writing samples culled from 330 novice learners enrolled in 15 classes of Levels 1 and 2 high school French. In order to assess the quality, fluency, syntactic complexity, and accuracy of the writing samples, the researchers employed 4 evaluation methods: holistic scoring, length of product, mean length of T-units, and percentage of correct T-units. Results indicate that the descriptive task was the easiest and the expository task the most difficult. The prose model prompts produced the highest mean scores, and the bare prompts produced the lowest mean scores. Based on these findings, the researchers question whether the description of a novice writer in the ACTFL Proficiency Guidelines (1986) should be used as a blueprint for curriculum development and textbook construction for secondary novice foreign language learners. {\textcopyright}2000 The Modern Language Journal.},
author = {Way, Denise Paige and Joiner, Elizabeth G. and Seaman, Michael A.},
doi = {10.1111/0026-7902.00060},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Way, Joiner, Seaman/Way, Joiner, Seaman{\_}2000{\_}Writing in the secondary foreign language classroom The effects of prompts and tasks on novice learners of Fren.pdf:pdf},
issn = {15404781},
journal = {Modern Language Journal},
number = {2},
pages = {171--184},
title = {{Writing in the secondary foreign language classroom: The effects of prompts and tasks on novice learners of French}},
volume = {84},
year = {2000}
}
@misc{Bartning,
author = {Bartning, Inge and {Forsberg Lundell}, Fanny},
title = {{Transcription Principles in English}},
url = {http://spraakbanken.gu.se/lb/resurser/interfra/metadata/Transcription Principles In English.docx},
urldate = {2019-05-27}
}
@incollection{Kuiken2012,
address = {London},
author = {Kuiken, Folkert and Vedder, Ineke},
booktitle = {The Routledge Handbook of Second Language Acquisition},
editor = {Gass, Susan M. and Mackey, Alison},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiken, Vedder/Kuiken, Vedder{\_}2012{\_}Speaking and writing tasks and their effects on second language performance.pdf:pdf},
pages = {364--377},
publisher = {Routledge},
title = {{Speaking and writing tasks and their effects on second language performance}},
year = {2012}
}
@incollection{Degand2009,
address = {Helsinki},
author = {Degand, Liesbeth and Hadermann, Pascale},
booktitle = {La langue en contexte. Actes du colloque « Repr{\'{e}}sentations du sens linguistique IV »},
editor = {Havu, Eva and Harma, Juhani and Helkkula, Mervi and Larjavaara, Meri and Tuomarla, Ulla},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Degand, Hadermann/Degand, Hadermann{\_}2009{\_}Structure narrative et connecteurs temporels en fran{\c{c}}ais langue seconde.pdf:pdf},
isbn = {9789519040349},
pages = {19--34},
publisher = {Socit{\'{e}}t{\'{e}} N{\'{e}}ophilogique},
title = {{Structure narrative et connecteurs temporels en fran{\c{c}}ais langue seconde}},
year = {2009}
}
@article{Forsberg2010,
abstract = {By means of a phraseological identification method, this study provides a general description of the use of conventional sequences (CSs) in interviews at four different levels of spoken L2 French as well as in interviews with native speakers. Use of conventional sequences is studied with regard to overall quantity, category distribution and type frequencies. The most predictive measure is overall quantity, which yields significant differences between several learner levels. It is also found that Lexical CSs are the most difficult to acquire for second language speakers: only the most advanced group use them to the same extent as native speakers. No significant differences are found between the most advanced group of L2 speakers (LOR in France greater than 5 yrs) and native speakers, probably due to the measures and the task investigated. The results are then related to Ellis et al. (TESOL Quarterly 42: 375-396, 2008), suggesting that the sequences' frequencies of occurrence vs. their MI score in a larger corpus might influence their acquisition and use.},
author = {Forsberg, Fanny},
doi = {10.1515/iral.2010.002},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Forsberg/Forsberg{\_}2010{\_}Using conventional sequences in L2 French(2).pdf:pdf},
issn = {0019042X},
journal = {IRAL - International Review of Applied Linguistics in Language Teaching},
keywords = {L2 French,formulaic language,formulaic sequences},
mendeley-tags = {L2 French,formulaic language,formulaic sequences},
number = {1},
pages = {25--51},
title = {{Using conventional sequences in L2 French}},
volume = {48},
year = {2010}
}
@article{Lan2019,
author = {Lan, Ge and Lucas, Kyle and Sun, Yachao},
doi = {10.1016/j.system.2019.102116},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lan, Lucas, Sun/Lan, Lucas, Sun{\_}2019{\_}Does L2 writing proficiency influence noun phrase complexity A case analysis of argumentative essays written by Chi.pdf:pdf},
issn = {0346-251X},
journal = {System (TO APPEAR)},
publisher = {Elsevier Ltd},
title = {{Does L2 writing proficiency influence noun phrase complexity? A case analysis of argumentative essays written by Chinese students in a first-year composition course}},
url = {https://doi.org/10.1016/j.system.2019.102116},
year = {2019}
}
@manual{Warnes2018,
annote = {R package version 3.8.1},
author = {Warnes, Gregory R and Bolker, Ben and Lumley, Thomas},
title = {{gtools: Various R Programming Tools}},
url = {https://cran.r-project.org/package=gtools},
year = {2018}
}
@article{Bestgen2017,
abstract = {Formulaic competence, the native-like use of ready-made sequences of words, is a key aspect in the development of L2 writing proficiency. Becoming increasingly important in foreign language teaching, it is largely neglected when assessing learner writing. Recently, several (semi-)automatic methods have been proposed to analyse the formulaic sequences in learner texts. After describing these methods and discussing their strengths and limitations, this study aims at determining the usefulness for assessing L2 text quality of collgram, a technique that assigns to each pair of contiguous words in a learner text two association scores (mutual information and t-score) computed on the basis of a large native speaker reference corpus. Correlation and hierarchical regression analyses, conducted on two datasets of English-as-a-foreign-language texts, showed that formulaic measures were the best predictors of text quality and provided a much higher specific contribution to the prediction than single-word lexical measures of diversity and sophistication. This study also confirms the need, as is being increasingly emphasized in applied linguistics, to replicate analyses on several corpora. The conclusion addresses the limits of the study and points to some potential implications for the teaching and assessment of second language writing.},
author = {Bestgen, Yves},
doi = {10.1016/j.system.2017.08.004},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bestgen/Bestgen{\_}2017{\_}Beyond single-word measures L2 writing assessment, lexical richness and formulaic competence.pdf:pdf},
issn = {0346251X},
journal = {System},
keywords = {Association measure,Formulaic sequence,L2 writing assessment,Lexical diversity,Lexical sophistication,Mutual information,Replication study},
pages = {65--78},
publisher = {Elsevier Ltd},
title = {{Beyond single-word measures: L2 writing assessment, lexical richness and formulaic competence}},
url = {http://dx.doi.org/10.1016/j.system.2017.08.004},
volume = {69},
year = {2017}
}
@incollection{Verlinde2001,
abstract = {verlinde},
address = {Lancaster},
author = {Verlinde, Serge and Selva, Thierry},
booktitle = {Proceedings of the Corpus Linguistics 2001 Conference (Technical Papers Vol. 13 Special Issue)},
editor = {Rayson, P and Wilson, A and McEnery, Tony and Hardy, A and Khoja, S},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Verlinde, Selva/Verlinde, Selva{\_}2001{\_}Corpus-based versus intuition-based lexicography defining a word list for a French learners' dictionary(2).pdf:pdf},
pages = {594--598},
publisher = {Lancaster University},
title = {{Corpus-based versus intuition-based lexicography: defining a word list for a French learners' dictionary}},
year = {2001}
}
@techreport{Zeileis2019,
author = {Zeileis, Achim and Fisher, Jason C and Hornik, Kurt and Ihaka, Ross and McWhite, Claire D and Murrell, Paul and Stauffer, Reto and Wilke, Claus O},
institution = {arXiv.org E-Print Archive},
month = {mar},
number = {1903.06490},
title = {{{\{}colorspace{\}}: A Toolbox for Manipulating and Assessing Colors and Palettes}},
type = {arXiv},
url = {http://arxiv.org/abs/1903.06490},
year = {2019}
}
@manual{Genz2019,
annote = {R package version 1.0-11},
author = {Genz, Alan and Bretz, Frank and Miwa, Tetsuhisa and Mi, Xuefei and Leisch, Friedrich and Scheipl, Fabian and Hothorn, Torsten},
title = {{{\{}mvtnorm{\}}: Multivariate Normal and t Distributions}},
url = {https://cran.r-project.org/package=mvtnorm},
year = {2019}
}
@article{Lakens2018,
abstract = {Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects.},
author = {Lakens, Dani{\"{e}}l and Scheel, Anne M. and Isager, Peder M.},
doi = {10.1177/2515245918770963},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lakens, Scheel, Isager/Lakens, Scheel, Isager{\_}2018{\_}Equivalence Testing for Psychological Research A Tutorial.pdf:pdf},
issn = {2515-2459},
journal = {Advances in Methods and Practices in Psychological Science},
keywords = {equivalence testing,falsification,frequentist,null hypothesis,null-hypothesis significance test,open,power,tost},
number = {2},
pages = {259--269},
title = {{Equivalence Testing for Psychological Research: A Tutorial}},
volume = {1},
year = {2018}
}
@incollection{Byrnes2008,
author = {Byrnes, Heidi and Sinicrope, Castle},
booktitle = {Longitudinal Study of Advanced L2 Capacities Second Language Acquisition Research.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Byrnes, Sinicrope/Byrnes, Sinicrope{\_}2008{\_}Advancedness and the development of relativization in L2 German A curriculum-based longitudinal study.pdf:pdf},
pages = {109--138},
title = {{Advancedness and the development of relativization in L2 German: A curriculum-based longitudinal study}},
year = {2008}
}
@manual{Wilke2019,
annote = {R package version 1.0.0},
author = {Wilke, Claus O},
title = {{cowplot: Streamlined Plot Theme and Plot Annotations for 'ggplot2'}},
url = {https://cran.r-project.org/package=cowplot},
year = {2019}
}
@article{Addisu2014,
author = {Addisu, V{\'{e}}ronique Miguel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Addisu/Addisu{\_}2014{\_}Entre classe d'accueil et classe ordinaire comment « S ' Y Apprennent-Ils » Recherche Ethnographique {\`{A}} L ' {\'{E}}cole.pdf:pdf},
isbn = {9782252039359},
journal = {{\'{E}}tudes de linguistique appliqu{\'{e}}e},
number = {2},
pages = {175--185},
title = {{Entre classe d'accueil et classe ordinaire : comment « S ' Y Apprennent-Ils » ? Recherche Ethnographique {\`{A}} L ' {\'{E}}cole Primaire Entre Classe D ' Accueil Et Classe Ordinaire : Ethnographique {\`{A}} L ' {\'{E}}cole Primaire}},
volume = {174},
year = {2014}
}
@manual{CodebyRichardA.Becker2018,
annote = {R package version 3.3.0},
author = {{code by Richard A. Becker}, Original S and {version by Ray Brownrigg. Enhancements by Thomas P Minka}, Allan R Wilks. R and Deckmyn., Alex},
title = {{maps: Draw Geographical Maps}},
url = {https://cran.r-project.org/package=maps},
year = {2018}
}
@inproceedings{Kovacevic2018,
abstract = {This paper deals with the theory of two-phase laminar flow in a heated microchannels. The main objective of the work is to study the thermohydrodynamic characteristics of a two-phase capillary flow with phase change at the meniscus. A quasi-one- dimensional model is proposed for such a flow. It takes into account the principal characteristics of the phenomenon, namely, the effects of the inertia, pressure, gravity, friction forces and capillary pressure due to the curvature of the interface surface, as well as the thermal and dynamical interactions of the liquid and vapor phases. To describe the flow outside of the meniscus, in the domains of the pure liquid or vapor, the one-dimensional mass, momentum and energy equations are used. The possible states of the flow are considered, and the domains of steady and unsteady states are outlined. An equation for stationary two-phase flow regimes in heated microchannel is derived. This equation is applied to classify the operating parameters, corresponding to various types of flow. (C) 2002 Elsevier Science Ltd. All rights reserved.},
author = {Kova{\v{c}}evi{\'{c}}, Ervan},
booktitle = {Jezici i kulture u vremenu i prostoru},
editor = {Guduri{\'{c}}, Sne{\v{z}}ana and Radi{\'{c}}-Bojani{\'{c}}, Biljana},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kova{\v{c}}evi{\'{c}}/Kova{\v{c}}evi{\'{c}}{\_}2018{\_}The Relationship between Lexical and Syntactic Complexity Measures in a Learner Corpus.pdf:pdf},
number = {2},
pages = {469--479},
title = {{The Relationship between Lexical and Syntactic Complexity Measures in a Learner Corpus}},
volume = {2},
year = {2018}
}
@article{Crossley2019,
abstract = {A number of longitudinal studies of L2 production have reported frequency effects wherein learners' produce more frequent words as a function of time. The current study investigated the spoken output of English L2 learners over a four-month period of time using both native and non-native English speaker frequency norms for both word types and word tokens. The study also controlled for individual differences such as first language distance, English proficiency, gender, and age. Results demonstrated that lower level L2 learners produced more infrequent tokens at the beginning of the study and that high intermediate learners, when compared to advanced learners, produced more infrequent tokens at the beginning of the study and more frequent tokens toward the end of the study. Main effects were also reported for proficiency level, age, and language distance. These results provide further evidence that L2 production may not follow expected frequency trends (i.e., that more infrequent tokens are produced as a function of time).},
author = {Crossley, Scott A. and Skalicky, Stephen and Kyle, Kristopher and Monteiro, Katia},
doi = {10.1017/S0272263118000268},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crossley et al/Crossley et al.{\_}2019{\_}Absolute Frequency Effects in Second Language Lexical Acquisition.pdf:pdf},
isbn = {0272263118000},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
number = {4},
pages = {1--24},
title = {{Absolute Frequency Effects in Second Language Lexical Acquisition}},
volume = {41},
year = {2019}
}
@manual{Hester2018,
annote = {R package version 2.1.2},
author = {Hester, Jim and M{\"{u}}ller, Kirill and Ushey, Kevin and Wickham, Hadley and Chang, Winston},
title = {{withr: Run Code 'With' Temporarily Modified Global State}},
url = {https://cran.r-project.org/package=withr},
year = {2018}
}
@incollection{McCarthy2013,
address = {Amsterdam},
author = {McCarthy, Philip M and Jarvis, Scott},
booktitle = {Vocabulary knowledge: Human ratings and automated measures},
editor = {Jarvis, Scott and Daller, M},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/McCarthy, Jarvis/McCarthy, Jarvis{\_}2013{\_}From intrinsic to extrinsic issues of lexical diversity assessment An ecological validation study.pdf:pdf},
keywords = {complexity,diversity},
mendeley-tags = {complexity,diversity},
pages = {45--77},
publisher = {John Benjamins},
title = {{From intrinsic to extrinsic issues of lexical diversity assessment: An ecological validation study}},
year = {2013}
}
@article{Gerber2018,
author = {Gerber, Florian and Moesinger, Kaspar and Furrer, Reinhard},
doi = {10.1016/j.softx.2018.06.002},
issn = {2352-7110},
journal = {SoftwareX},
pages = {217--221},
title = {{{\{}dotCall64{\}}: An {\{}R{\}} package providing an efficient interface to compiled {\{}C{\}}, {\{}C++{\}}, and {\{}Fortran{\}} code supporting long vectors}},
volume = {7},
year = {2018}
}
@article{Bitchener2010,
abstract = {This article presents the findings of a study that investigated (1) the extent to which written corrective feedback (CF) can help advanced L2 learners, who already demonstrate a high level of accuracy in two functional uses of the English article system (the use of 'a' for first mention and 'the' for subsequent or anaphoric mentions), further increase that level of accuracy; and (2) the extent to which there may be a differential effect for different types of feedback on any observed improvement. Sixty-three advanced L2 learners at a university in the USA formed a control group and three treatment groups: (1) those who received written meta-linguistic explanation; (2) indirect circling of errors; and (3) written meta-linguistic feedback and oral form-focused instruction. On three occasions (pre-test, immediate post-test, delayed post-test) the participants were asked to describe what was happening in a picture of a different social setting. Significant differences were found in the level of accuracy on (1) the immediate post-test piece of writing between the control group and all three treatment groups; and (2) on the delayed post-test piece between the control and indirect groups and the two direct treatment groups. {\textcopyright} 2010 Elsevier Inc.},
author = {Bitchener, John and Knoch, Ute},
doi = {10.1016/j.jslw.2010.10.002},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bitchener, Knoch/Bitchener, Knoch{\_}2010{\_}Raising the linguistic accuracy level of advanced L2 writers with written corrective feedback.pdf:pdf},
issn = {10603743},
journal = {Journal of Second Language Writing},
keywords = {Corrective feedback,Direct and indirect feedback,Error correction,Written corrective feedback},
number = {4},
pages = {207--217},
publisher = {Elsevier Inc.},
title = {{Raising the linguistic accuracy level of advanced L2 writers with written corrective feedback}},
url = {http://dx.doi.org/10.1016/j.jslw.2010.10.002},
volume = {19},
year = {2010}
}
@article{Kuiken2008,
abstract = {This paper reports on a study on the relationship between cognitive task complexity and linguistic performance in L2 writing. In the study, two models proposed to explain the influence of cognitive task complexity on linguistic performance in L2 are tested and compared: Skehan and Foster's Limited Attentional Capacity Model (Skehan, 1998; Skehan {\&} Foster, 1999, 2001) and Robinson's Cognition Hypothesis (Robinson, 2001a, 2001b, 2005). In the experiment, 91 Dutch university students of Italian and 76 students of French performed two writing tasks with prompts of differing cognitive complexity. Linguistic performance was operationalized in terms of syntactic complexity, lexical variation, and accuracy. The study provides support for the Cognition Hypothesis insofar as the written products of the cognitively more demanding task turned out to be more accurate, with significantly lower error ratios per T-unit than those of the cognitively less demanding task. No effects on the written output could be observed on measures of syntactic complexity or lexical variation. The implications of the findings for both Skehan and Foster's model and Robinson's Cognition Hypothesis with regard to L2 writing pedagogy are discussed and suggestions are made for the direction in which further research on the influence of task complexity on text quality should be developed. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Kuiken, Folkert and Vedder, Ineke},
doi = {10.1016/j.jslw.2007.08.003},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiken, Vedder/Kuiken, Vedder{\_}2008{\_}Cognitive task complexity and written output in Italian and French as a foreign language.pdf:pdf},
issn = {10603743},
journal = {Journal of Second Language Writing},
keywords = {Accuracy,Attention,Cognition Hypothesis,Cognitive task complexity,Lexical variation,Limited Attentional Capacity Model,Multiple Attentional Resources Model,Proficiency level,Syntactic complexity,Writing performance},
number = {1},
pages = {48--60},
title = {{Cognitive task complexity and written output in Italian and French as a foreign language}},
volume = {17},
year = {2008}
}
@article{Zeileis2009,
author = {Zeileis, Achim and Hornik, Kurt and Murrell, Paul},
doi = {10.1016/j.csda.2008.11.033},
journal = {Computational Statistics {\&} Data Analysis},
number = {9},
pages = {3259--3270},
title = {{Escaping {\{}RGB{\}}land: Selecting Colors for Statistical Graphics}},
volume = {53},
year = {2009}
}
@book{Venables2002a,
address = {New York},
annote = {ISBN 0-387-95457-0},
author = {Venables, W N and Ripley, B D},
edition = {Fourth},
publisher = {Springer},
title = {{Modern Applied Statistics with S}},
url = {http://www.stats.ox.ac.uk/pub/MASS4},
year = {2002}
}
@manual{Wickham2019b,
annote = {R package version 0.2.0.1},
author = {Wickham, Hadley},
title = {{ellipsis: Tools for Working with ...}},
url = {https://cran.r-project.org/package=ellipsis},
year = {2019}
}
@article{Kassler2019,
author = {Kassler, Daniel and Nichols-Barrer, Ira and Finucane, Mariel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kassler, Nichols-Barrer, Finucane/Kassler, Nichols-Barrer, Finucane{\_}2019{\_}Beyond “Treatment Versus Control” How Bayesian Analysis Makes Factorial Experiments Feasible.pdf:pdf},
journal = {Evaluation Review},
number = {24},
title = {{Beyond “Treatment Versus Control”: How Bayesian Analysis Makes Factorial Experiments Feasible in Education Research}},
volume = {1},
year = {2019}
}
@article{Granger2015,
author = {Granger, Sylviane},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger/Granger{\_}2015{\_}Contrastive interlanguage analysis A reappraisal.pdf:pdf},
journal = {International Journal of Learner Corpus Research},
number = {1},
pages = {7--24},
title = {{Contrastive interlanguage analysis: A reappraisal}},
volume = {1},
year = {2015}
}
@article{Blanche-Benveniste1995,
author = {Blanche-Benveniste, Claire},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Blanche-Benveniste/Blanche-Benveniste{\_}1995{\_}De la raret{\'{e}} de certains ph{\'{e}}nom{\`{e}}nes syntaxiques en francais parl'ee.pdf:pdf},
journal = {French Language Studies},
pages = {17--29},
title = {{De la raret{\'{e}} de certains ph{\'{e}}nom{\`{e}}nes syntaxiques en francais parl'ee}},
volume = {5},
year = {1995}
}
@misc{Michalke2019,
author = {Michalke, Meik},
title = {{koRpus: An R Package for Text Analysis (Version 0.12-1)}},
year = {2019}
}
@misc{Garretson2011,
author = {Garretson, Gregory},
title = {{Dexter Coder}},
url = {http://www.dextercoder.org/},
year = {2011}
}
@manual{Gerds2018,
annote = {R package version 2018.04.18},
author = {Gerds, Thomas A},
title = {{prodlim: Product-Limit Estimation for Censored Event History Analysis}},
url = {https://cran.r-project.org/package=prodlim},
year = {2018}
}
@manual{Lumley2019,
annote = {R package version 2.4},
author = {Lumley, Thomas},
title = {{mitools: Tools for Multiple Imputation of Missing Data}},
url = {https://cran.r-project.org/package=mitools},
year = {2019}
}
@incollection{Herbst2009,
abstract = {This article discusses the role of valency as a lexico-grammatical phenomenon which can only be fully accounted for in terms of such concepts as Sinclair's idiom principle. It is argued that insights from corpus linguistics and foreign language linguistics can be accommodated in cognitive approaches such as Construction Grammar. The article outlines various levels of abstraction involved in a valency description and argues that although to a certain extent generalizations can be made, the idiosyncratic nature of valency should not be underestimated. Using largely data from the Valency Dictionary of English, it is shown that this is true of practically all levels of a valency description, ranging from correspondences of valency patterns and the meanings of the items to the lexical realization of particular complements.},
address = {Amsterdam},
author = {Herbst, Thomas},
booktitle = {Exploring the Lexis–Grammar Interface},
editor = {R{\"{o}}mer, Ute and Schulze, Rainer},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Herbst/Herbst{\_}2009{\_}Valency - item-specificity and idiom principle.pdf:pdf},
isbn = {978 90 272 2309 8},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
pages = {49--68},
publisher = {John Benjamins},
title = {{Valency - item-specificity and idiom principle}},
year = {2009}
}
@phdthesis{Urieli2013,
author = {Urieli, Assaf},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Urieli/Urieli{\_}2013{\_}Robust French syntax analysis reconciling statistical methods and linguistic knowledge in the Talismane toolkit.pdf:pdf},
school = {Universit{\'{e}} Toulouse 2 Le Mirai},
title = {{Robust French syntax analysis : reconciling statistical methods and linguistic knowledge in the Talismane toolkit}},
url = {https://tel.archives-ouvertes.fr/tel-01058143},
year = {2013}
}
@article{Egginton2014,
author = {Egginton, Emmanuelle},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Egginton/Egginton{\_}2014{\_}Les r{\'{e}}gionalismes dans l'enseignement du fran{\c{c}}ais langue seconde.pdf:pdf},
isbn = {9782252039359},
journal = {{\'{E}}tudes de linguistique appliqu{\'{e}}e},
number = {2},
pages = {211--220},
title = {{Les r{\'{e}}gionalismes dans l'enseignement du fran{\c{c}}ais langue seconde}},
volume = {174},
year = {2014}
}
@manual{Varadhan2017,
annote = {R package version 2017.10-1},
author = {Varadhan, Ravi},
title = {{SQUAREM: Squared Extrapolation Methods for Accelerating EM-Like Monotone Algorithms}},
url = {https://cran.r-project.org/package=SQUAREM},
year = {2017}
}
@manual{Revelle2018,
address = {Evanston, Illinois},
annote = {R package version 1.8.12},
author = {Revelle, William},
organization = {Northwestern University},
title = {{psych: Procedures for Psychological, Psychometric, and Personality Research}},
url = {https://cran.r-project.org/package=psych},
year = {2018}
}
@article{Ikehara1996,
author = {Ikehara, Satoru and Shirai, Satoshi and Uchino, Hajime},
doi = {10.3115/992628.992727},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ikehara, Shirai, Uchino/Ikehara, Shirai, Uchino{\_}1996{\_}A statistical method for extracting uninterrupted and interrupted collocations from very large corpora.pdf:pdf},
journal = {Proceedings of the 16th conference on Computational linguistics},
pages = {574--579},
title = {{A statistical method for extracting uninterrupted and interrupted collocations from very large corpora}},
url = {http://portal.acm.org/citation.cfm?doid=992628.992727},
year = {1996}
}
@inproceedings{Crabbe2008,
address = {Avignon},
author = {Crabb{\'{e}}, Beno{\^{i}}t and Candito, Marie},
booktitle = {15{\`{e}}me conf{\'{e}}rence sur le Traitement Automatique des Langues Naturelles - TALN'08},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crabb{\'{e}}, Candito/Crabb{\'{e}}, Candito{\_}2008{\_}Exp{\'{e}}riences d'analyse syntaxique statistique du fran{\c{c}}ais.pdf:pdf},
month = {jun},
pages = {44--54},
title = {{Exp{\'{e}}riences d'analyse syntaxique statistique du fran{\c{c}}ais}},
year = {2008}
}
@incollection{Ellis2015,
address = {London},
author = {Ellis, Nick C and Wulff, Stefanie},
booktitle = {Theories in Second Language Acquisition: An Introduction},
editor = {VanPatten, Bill and Williams, Jessica},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, Wulff/Ellis, Wulff{\_}2015{\_}Usage-Based Approaches to SLA.pdf:pdf},
publisher = {Routledge},
title = {{Usage-Based Approaches to SLA}},
year = {2015}
}
@article{Lu2010,
abstract = {We describe a computational system for automatic analysis of syntactic complexity in second language writing using fourteen different measures that have been explored or proposed in studies of second language development. The system takes a written language sample as input and produces fourteen indices of syntactic complexity of the sample based on these measures. The system is designed with advanced second language proficiency research in mind, and is therefore developed and evaluated using college-level second language writing data from the Written English Corpus of Chinese Learners (Wen et al. 2005). Experimental results show that the system achieves very high reliability on unseen test data from the corpus. We illustrate how the system is used in an example application to investigate whether and to what extent each of these measures significantly differentiate between different proficiency levels},
author = {Lu, Xiaofei},
doi = {10.1075/ijcl.15.4.02lu},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lu/Lu{\_}2010{\_}Automatic analysis of syntactic complexity in second language writing(3).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lu/Lu{\_}2010{\_}Automatic analysis of syntactic complexity in second language writing.pdf:pdf},
isbn = {1384-6655},
issn = {1384-6655},
journal = {International Journal of Corpus Linguistics},
keywords = {developmental index,learner corpus analysis,second language development,second language writing,syntactic complexity,taasc},
mendeley-tags = {taasc},
number = {4},
pages = {474--496},
pmid = {54858742},
title = {{Automatic analysis of syntactic complexity in second language writing}},
url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.15.4.02lu},
volume = {15},
year = {2010}
}
@article{Biber2016,
author = {Biber, Douglas and Gray, Bethany and Staples, Shelley},
doi = {10.1093/applin/amu059},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Biber, Gray, Staples/Biber, Gray, Staples{\_}2016{\_}Predicting Patterns of Grammatical Complexity Across Language Exam Task Types and Proficiency Levels.pdf:pdf},
journal = {Applied Linguistics},
number = {5},
pages = {639--668},
title = {{Predicting Patterns of Grammatical Complexity Across Language Exam Task Types and Proficiency Levels}},
volume = {37},
year = {2016}
}
@manual{Peters2019a,
annote = {R package version 0.9-9},
author = {Peters, Andrea and Hothorn, Torsten},
title = {{ipred: Improved Predictors}},
url = {https://cran.r-project.org/package=ipred},
year = {2019}
}
@article{Ravid2002,
abstract = {This is a position paper modelling the domain of linguistic literacy and its development through the life span. It aims to provide a framework for the analysis of language development in the school years, integrating sociolinguistic and psycholinguistic notions of variation, language awareness, and literacy in a comprehensive model. The paper focuses on those aspects of literacy competence that are expressed in language as well as aspects of linguistic knowledge that are affected by literacy competence, tracing the route that children take in appropriating linguistic literacy as part of their cognitive abilities and examining the effect of literacy on language across development. Our view of linguistic literacy consists of one defining feature: control over linguistic variation from both a user-dependent (‘lectal') and a context-dependent (modality, genre, and register) perspective; of one concomitant process: metalanguage and its role in language development; and of one condition: familiarity with writing and written language from two aspects: written language as discourse style – the recognition that the kind of language used for writing is essentially different from the one used for speech; and written language as a notational system – the perception and growing command of the representational system that is used in the written modality. Linguistic literacy is viewed as a constituent of language knowledge characterized by the availability of multiple linguistic resources and by the ability to consciously access one's own linguistic knowledge and to view language from various perspectives.},
author = {Ravid, Dorit and Tolchinsky, Liliana},
doi = {10.1017/s0305000902005111},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ravid, Tolchinsky/Ravid, Tolchinsky{\_}2002{\_}Developing linguistic literacy a comprehensive model.pdf:pdf},
issn = {0305-0009},
journal = {Journal of Child Language},
number = {2},
pages = {417--447},
publisher = {University of Groningen},
title = {{Developing linguistic literacy: a comprehensive model}},
volume = {29},
year = {2002}
}
@manual{OriginalbySteveDutkyinitialRport2013,
annote = {R package version 1.0-6},
author = {{original by Steve Dutky initial R port}, S and {extensions by Martin Maechler; revised} and {modified by Steve Dutky}},
title = {{bitops: Bitwise Operations}},
url = {https://cran.r-project.org/package=bitops},
year = {2013}
}
@manual{Love2020,
annote = {R package version 1.2.23},
author = {Love, Jonathon},
title = {{jmvcore: Dependencies for the 'jamovi' Framework}},
url = {https://cran.r-project.org/package=jmvcore},
year = {2020}
}
@manual{Hunt2018,
annote = {R package version 1.2.2},
author = {Hunt, Tyler},
title = {{ModelMetrics: Rapid Calculation of Model Metrics}},
url = {https://cran.r-project.org/package=ModelMetrics},
year = {2018}
}
@incollection{Granger1996,
address = {Lund},
author = {Granger, Sylviane},
booktitle = {Languages in contrast: Text-based linguistic studies},
editor = {Aijmer, K},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger/Granger{\_}1996{\_}From CA to CIA and back An integrated contrastive approach to bilingual and learner computerised corpora.pdf:pdf},
pages = {37--51},
publisher = {Lund University Press},
title = {{From CA to CIA and back: An integrated contrastive approach to bilingual and learner computerised corpora}},
year = {1996}
}
@manual{Robinson2019,
annote = {R package version 0.5.2},
author = {Robinson, David and Hayes, Alex},
title = {{broom: Convert Statistical Analysis Objects into Tidy Tibbles}},
url = {https://cran.r-project.org/package=broom},
year = {2019}
}
@article{Goldberg1992,
author = {Goldberg, Adele E},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Geeraerts/Geeraerts{\_}2006{\_}A rough guide to cognitive linguistics.pdf:pdf},
journal = {Cognitive Linguistics},
keywords = {theorySLA},
mendeley-tags = {theorySLA},
number = {1},
pages = {37--74},
title = {{The inherent semantics of argument structure: The case of the English ditransitive construction}},
volume = {3},
year = {1992}
}
@techreport{Clarin2018,
address = {Vilnius},
author = {Clarin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Clarin/Clarin{\_}2018{\_}Hacking the GDPR to Conduct Research with Language Resources in Digital Humanities and Social Sciences Final workshop report.pdf:pdf},
title = {{Hacking the GDPR to Conduct Research with Language Resources in Digital Humanities and Social Sciences: Final workshop report}},
year = {2018}
}
@incollection{Rosenthal1994,
address = {New York},
author = {Rosenthal, Robert},
booktitle = {The handbook of research synthesis},
editor = {Cooper, H. and Hedges, L. V.},
keywords = {effectsize},
mendeley-tags = {effectsize},
pages = {231--244},
publisher = {Russell Sage Foundation},
title = {{Parametric measures of effect size}},
year = {1994}
}
@manual{Wuertz2018,
annote = {R package version 3043.102},
author = {Wuertz, Diethelm and Setz, Tobias and Chalabi, Yohan and Maechler, Martin and Byers, Joe W},
title = {{timeDate: Rmetrics - Chronological and Calendar Objects}},
url = {https://cran.r-project.org/package=timeDate},
year = {2018}
}
@incollection{Hulstijn2010a,
author = {Hulstijn, I H and Alderson, Charles J. and Schoonen, Rob},
booktitle = {Communicative proficiency and linguistic development : Intersections between SLA and language testing},
editor = {Bartning, Inge and Martin, Maisa and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hulstijn, Alderson, Schoonen/Hulstijn, Alderson, Schoonen{\_}2010{\_}Developmental stages in second-language acquisition and levels of second-language proficiency Are ther.pdf:pdf},
pages = {11--20},
publisher = {European Second Language Association},
title = {{Developmental stages in second-language acquisition and levels of second-language proficiency: Are there links between them?}},
volume = {1},
year = {2010}
}
@article{Kyle2017,
abstract = {Over the past 45 years, the construct of syntactic sophistication has been assessed in L2 writing using what Bult{\'{e}} and Housen (2012) refer to as absolute complexity (Lu, 2011; Ortega, 2003; Wolfe-Quintero, Inagaki, {\&} Kim, 1998). However, it has been argued that making inferences about learners based on absolute complexity indices (e.g., mean length of t-unit and mean length of clause) may be difficult, both from practical and theoretical perspectives (Norris {\&} Ortega, 2009). Furthermore, indices of absolute complexity may not align with some prominent theories of language learning such as usage-based theories (e.g., Ellis, 2002a,b). This study introduces a corpus-based approach for measuring syntactic sophistication in L2 writing using a usage-based, frequency-driven perspective. Specifically, novel computational indices related to the frequency of verb argument constructions (VACs) and the strength of association between VACs and the verbs that fill them (i.e., verb–VAC combinations) are developed. These...},
author = {Kyle, Kristopher and Crossley, Scott A.},
doi = {10.1177/0265532217712554},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kyle, Crossley/Kyle, Crossley{\_}2017{\_}Assessing syntactic sophistication in L2 writing A usage-based approach.pdf:pdf},
issn = {14770946},
journal = {Language Testing},
keywords = {Automatic essay scoring,corpus-based,natural language processing,syntactic complexity,usage-based,writing assessment},
number = {4},
pages = {513--535},
title = {{Assessing syntactic sophistication in L2 writing: A usage-based approach}},
volume = {34},
year = {2017}
}
@manual{Gamer2019,
annote = {R package version 0.84.1},
author = {Gamer, Matthias and Lemon, Jim and {\textless}puspendra.pusp22@gmail.com{\textgreater}, Ian Fellows Puspendra Singh},
title = {{irr: Various Coefficients of Interrater Reliability and Agreement}},
url = {https://cran.r-project.org/package=irr},
year = {2019}
}
@article{Guillaume2017,
author = {Guillaume, Bruno and Perrier, Guy and Guillaume, Bruno and Perrier, Guy},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Guillaume et al/Guillaume et al.{\_}2017{\_}Reflexion sur l ' annotation de corpus ecrits du fran{\c{c}}ais en syntaxe et en semantique To cite this version HAL.pdf:pdf},
title = {{Reflexion sur l ' annotation de corpus ecrits du fran{\c{c}}ais en syntaxe et en semantique To cite this version : HAL Id : hal-01651753}},
year = {2017}
}
@manual{Wroteit2019,
annote = {R package version 0.1.0},
author = {Wrote it, Who},
title = {{uslides: What the Package Does (Title Case)}},
year = {2019}
}
@manual{Muller2018a,
annote = {R package version 1.3-2},
author = {M{\"{u}}ller, Kirill},
title = {{rprojroot: Finding Files in Project Subdirectories}},
url = {https://cran.r-project.org/package=rprojroot},
year = {2018}
}
@article{Granfeldt2014a,
author = {Granfeldt, Jonas and {\AA}gren, Malin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granfeldt, {\AA}gren/Granfeldt, {\AA}gren{\_}2014{\_}De l'acquisition des langues {\`{a}} l'{\'{e}}valuation en FLE- Le logiciel Direct Profil en application.pdf:pdf},
journal = {M{\'{e}}langes Crapel},
title = {{De l'acquisition des langues {\`{a}} l'{\'{e}}valuation en FLE- Le logiciel Direct Profil en application}},
volume = {35},
year = {2014}
}
@article{Plonsky2014,
abstract = {The calculation and use of effect sizes-such as d for mean differences and r for correlations-has increased dramatically in second language (L2) research in the last decade. Interpretations of these effects, however, have been rare and, when present, have largely defaulted to Cohen's levels of small (d = .2, r = .1), medium (.5, .3), and large (.8, .5), which were never intended as prescriptions but rather as a general guide. As Cohen himself and many others have argued, effect sizes are best understood when interpreted within a particular discipline or domain. This article seeks to promote more informed and field-specific interpretations of d and r by presenting a description of L2 effects from 346 primary studies and 91 meta-analyses (N {\textgreater} 604,000). Results reveal that Cohen's benchmarks generally underestimate the effects obtained in L2 research. Based on our analysis, we propose a field-specific scale for interpreting effect sizes, and we outline eight key considerations for gauging relative magnitude and practical significance in primary and secondary studies, such as theoretical maturity in the domain, the degree of experimental manipulation, and the presence of publication bias.},
author = {Plonsky, Luke and Oswald, Frederick L.},
doi = {10.1111/lang.12079},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Plonsky, Oswald/Plonsky, Oswald{\_}2014{\_}How big is big Interpreting effect sizes in L2 research.pdf:pdf},
issn = {14679922},
journal = {Language Learning},
keywords = {Effect sizes,Meta-analysis,Practical significance,Quantitative research methods,effectsize},
mendeley-tags = {effectsize},
number = {4},
pages = {878--912},
title = {{How big is "big"? Interpreting effect sizes in L2 research}},
volume = {64},
year = {2014}
}
@incollection{Treffers-Daller2009,
abstract = {International scholars and researchers present cutting edge contributions on the significance of vocabulary in current thinking on first and second language acquisition in the school and at home. By pursuing common themes across first and second language and bilingual contexts, the editors offer a collection that tackles the most important issues.},
address = {Houndmills Basingstoke},
author = {Treffers-Daller, Jeanine},
booktitle = {Vocabulary Studies in First and Second Language Acquisition: The Interface Between Theory and Applications},
doi = {10.1057/9780230242258},
editor = {Richards, B and {Michael Daller}, H and Malvern, D and Meara, P and Milton, J and Treffers-Daller, J},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Treffers-Daller/Treffers-Daller{\_}2009{\_}Language Dominance and Lexical Diversity How Bilinguals and L2 Learners Differ in their Knowledge and Use of French.pdf:pdf},
isbn = {9780230242258},
pages = {74--90},
publisher = {Palgrave Macmilan},
title = {{Language Dominance and Lexical Diversity: How Bilinguals and L2 Learners Differ in their Knowledge and Use of French Lexical and Functional Items}},
year = {2009}
}
@article{Gries2015,
abstract = {The advent of usage-/exemplar-based approaches has resulted in a major change in the theoretical landscape of linguistics, but also in the range of methodologies that are brought to bear on the study of language acquisition/learning, structure, and use. In particular, methods from corpus linguistics are now frequently used to study distributional characteristics of linguistics units and what they reveal about cognitive and psycholinguistic processes. This paper surveys a range of psycholinguistic notions that are becoming ever more important in theoretical and cognitive linguistics-for example, frequency, entrenchment, dispersion, contingency, surprisal, Zipfian distributions-and current corpus-linguistic approaches toward exploring these notions and their roles for linguistic cognition.},
author = {Gries, Stefan Th. and Ellis, Nick C},
doi = {10.1111/lang.12119},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries, Ellis/Gries, Ellis{\_}2015{\_}Statistical Measures for Usage-Based Linguistics(2).pdf:pdf},
issn = {14679922},
journal = {Language Learning},
keywords = {Associative learning,Contingency/association,Corpus data,Dispersion,Frequency,Psycholinguistics,Surprisal},
number = {Supplement 1},
pages = {1--28},
title = {{Statistical Measures for Usage-Based Linguistics}},
volume = {65},
year = {2015}
}
@manual{Walker2019,
annote = {R package version 4.1.0.1},
author = {Walker, Alexander},
title = {{openxlsx: Read, Write and Edit XLSX Files}},
url = {https://cran.r-project.org/package=openxlsx},
year = {2019}
}
@incollection{Bouwer2018,
abstract = {Tekst op achterflap: "Het onderwijs heeft als opdracht samen met iedere student op zoek te gaan naar zijn of haar unieke talenten in de domeinen van kennen, kunnen en voelen, en mogelijkheden te creëren om in optimale omstandigheden verder te kunnen werken aan deze talenten. Een klimaat waarin refl ectie en feedback hand in hand gaan, is hierbij cruciaal. Het helpt de horizon en de stip op die horizon helder te krijgen, de route te bepalen, wegomleidingen te kiezen wanneer nodig en de route aan te passen wanneer informatie erop wijst dat dit niet de meest effectieve weg is naar de beoogde plaats van bestemming. Deze visie op onderwijs, die steeds vaker doorklinkt in gesprekken binnen en over het hoger onderwijs, vraagt om een herkadering van het waarom, wat en hoe van de manier waarop wij studenten toetsen en beoordelen. In deze bundel wordt door middel van artikelen en interviews stilgestaan bij inspirerende, vooruitstrevende, en professionele toets- en feedbackpraktijken in het hoger onderwijs."},
address = {Culemborg, The Netherlands},
author = {Bouwer, Renske and Goossens, Maarten and Mortier, Anneleen Viona and Lesterhuis, Marije and {De Maeyer}, Sven},
booktitle = {Toetsrevolutie : naar een feedbackcultuur in het hoger onderwijs},
doi = {10.4149/gpb_2009_01_94},
editor = {Segers, Mien. and Sluijsmans, Dominique},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bouwer et al/Bouwer et al.{\_}2018{\_}Een comparatieve aanpak voor peer assessment leren door te vergelijken.pdf:pdf},
isbn = {9789490120283},
issn = {02315882},
pages = {92--109},
publisher = {Phronese},
title = {{Een comparatieve aanpak voor peer assessment: leren door te vergelijken}},
year = {2018}
}
@techreport{Lenth2007,
abstract = {Post hoc power is the retrospective power of an observed effect based on the sample size and parameter estimates derived from a given data set. Many scientists recommend using post hoc power as a follow-up analysis, especially if a finding is nonsignificant. This article presents tables of post hoc power for common t and F tests. These tables make it explicitly clear that for a given significance level, post hoc power depends only on the P value and the degrees of freedom. It is hoped that this article will lead to greater understanding of what post hoc power is—and is not. We also present a " grand unified formula " for post hoc power based on a reformulation of the problem, and a discussion of alternative views.},
author = {Lenth, Russell V},
booktitle = {Department of Statistics and Actuarial Science Technical Report No. 378},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lenth/Lenth{\_}2007{\_}Post Hoc Power Tables and Commentary.pdf:pdf},
institution = {The University of Iowa},
keywords = {grand unified formula,observed power,p value,post hoc power},
title = {{Post Hoc Power : Tables and Commentary}},
year = {2007}
}
@article{Hale2016,
abstract = {Information-theoretical complexity metrics are auxiliary hypotheses that link theories of parsing and grammar to potentially observable measurements such as reading times and neural signals. This review article considers two such metrics, Surprisal and Entropy Reduction, which are respectively built upon the two most natural notions of ‘information value' for an observed event (Blachman). This review sketches their conceptual background and touches on their relationship to other theories in cognitive science. It characterizes them as ‘lenses' through which theorists ‘see' the information-processing consequences of linguistic grammars. While these metrics are not themselves parsing algorithms, the review identifies candidate mechanisms that have been proposed for both of them.},
author = {Hale, John},
doi = {10.1111/lnc3.12196},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hale/Hale{\_}2016{\_}Information-theoretical Complexity Metrics.pdf:pdf},
issn = {1749818X},
journal = {Language and Linguistics Compass},
number = {9},
pages = {397--412},
title = {{Information-theoretical Complexity Metrics}},
volume = {10},
year = {2016}
}
@article{Edmonds2014,
author = {Edmonds, Amanda},
doi = {10.1017/S0272263113000557},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Edmonds/Edmonds{\_}2014{\_}Conventional Expressions.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Edmonds/Edmonds{\_}2014{\_}Conventional Expressions.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Edmonds/Edmonds{\_}2014{\_}Conventional Expressions.pdf:pdf},
isbn = {1470-1545},
issn = {0272-2631},
journal = {Studies in Second Language Acquisition},
keywords = {formulaic language},
mendeley-tags = {formulaic language},
number = {01},
pages = {69--99},
title = {{Conventional Expressions}},
url = {http://www.journals.cambridge.org/abstract{\_}S0272263113000557},
volume = {36},
year = {2014}
}
@inproceedings{Schluter2009,
address = {Odense},
author = {Schluter, Natalie and van Genabith, Josef},
booktitle = {NODALIDA 2009},
editor = {Jokinen, Kristiina and Bick, Eckhard},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Schluter, van Genabith/Schluter, van Genabith{\_}2009{\_}Dependency Parsing Resources for French Converting Acquired Lexical Functional Grammar F-Structure Annotati.pdf:pdf},
month = {may},
pages = {166--173},
title = {{Dependency Parsing Resources for French : Converting Acquired Lexical Functional Grammar F-Structure Annotations and Parsing F-Structures Directly}},
year = {2009}
}
@article{Gries2015c,
abstract = {Ever since the first studies introducing collostructional analysis in general and collexeme analysis in particular, these methods have been widely used for the analysis of constructions' semantic and functional characteristics. However, the more recent past has seen two publications, Bybee (2010) and Schmid and Kuchenhoff (2013), which criticized several aspects of these methods. This paper briefly recaps my response to Bybee (2010) (published as Gries 2012) as a prelude to its main contribution, viz a rebuttal of various claims and problems of Schmid and Kuchenhoff (2013).},
author = {Gries, Stefan Th.},
doi = {10.1515/cog-2014-0092},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2015{\_}More (old and new) misunderstandings of collostructional analysis On Schmid and Kuchenhoff (2013).pdf:pdf},
isbn = {0936-5907},
issn = {0936-5907},
journal = {Cognitive Linguistics},
keywords = {stats},
mendeley-tags = {stats},
number = {3},
pages = {505--536},
title = {{More (old and new) misunderstandings of collostructional analysis: On Schmid and Kuchenhoff (2013)}},
volume = {26},
year = {2015}
}
@article{Kim2018,
abstract = {{\textcopyright}2018 The Modern Language Journal This study conceptualizes lexical sophistication as a multidimensional phenomenon by reducing numerous lexical features of lexical sophistication into 12 aggregated components (i.e., dimensions) via a principal component analysis approach. These components were then used to predict second language (L2) writing proficiency levels, holistic lexical proficiency scores, and longitudinal lexical growth. The results from regression analyses indicated that 5 lexical components (i.e., bigram and trigram strength of directional association, content word properties, bigram mutual information, bigram and trigram proportions, and word specificity) explained 16.1{\%} and 31.0{\%} of the variance of L2 writing proficiency and lexical proficiency, respectively. Two additional components (i.e., word acquisition properties and content word frequency) explained an additional 8.5{\%} of the variance of L2 writing proficiency. Six lexical components (i.e., bigram and trigram proportions, word acquisition properties, content word frequency, bigram frequency and range, content word properties, and function word frequency and range) showed significant developmental trends in L2 beginning learners over a year-long period. These findings provide information about the multidimensional nature of lexical sophistication by expanding its scope beyond frequency and toward other primary dimensions that include various lexical and phrasal features such as concreteness, orthographic density, hypernymy, and n-gram frequency and association strength.},
author = {Kim, Minkyung and Crossley, Scott A. and Kyle, Kristopher},
doi = {10.1111/modl.12447},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kim, Crossley, Kyle/Kim, Crossley, Kyle{\_}2018{\_}Lexical Sophistication as a Multidimensional Phenomenon Relations to Second Language Lexical Proficiency, Devel.pdf:pdf},
issn = {15404781},
journal = {Modern Language Journal},
keywords = {corpus linguistics,lexical sophistication,proficiency,vocabulary},
number = {1},
pages = {120--141},
pmid = {6939},
title = {{Lexical Sophistication as a Multidimensional Phenomenon: Relations to Second Language Lexical Proficiency, Development, and Writing Quality}},
volume = {102},
year = {2018}
}
@article{Biber2014,
abstract = {Multi-Dimensional analyses have been conducted for many different discourse domains and many different languages. Using bottom-up statistical analyses, these studies have investigated specific patterns of register variation in several different discourse domains of English, as well as the more general patterns of register variation in many different languages. Each study identifies linguistic dimensions that are peculiar to that particular language/domain. However, the more theoretically interesting finding is that linguistically similar dimensions emerge in nearly all of these studies. Two of these dimensions are especially robust, making them strong candidates for universal dimensions of register variation: 1) a fundamental opposition between clausal/‘oral' discourse vs. phrasal/‘literate' discourse, and 2) the opposition between narrative vs . non-narrative discourse. The present paper introduces the methodology of Multi-Dimensional analysis and surveys the research studies carried out to date, with an emphasis on these potentially universal patterns of register variation.},
author = {Biber, Douglas},
doi = {10.1075/lic.14.1.02bib},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Biber/Biber{\_}2014{\_}Using multi-dimensional analysis to explore cross-linguistic universals of register variation.pdf:pdf},
issn = {1387-6759},
journal = {Languages in Contrast. International Journal for Contrastive Linguistics},
keywords = {cross-linguistic universals,discourse,literate,literate discourse,multi-dimensional analysis,oral discourse,register variation},
number = {1},
pages = {7--34},
title = {{Using multi-dimensional analysis to explore cross-linguistic universals of register variation}},
volume = {14},
year = {2014}
}
@incollection{Jarvis2013b,
address = {Amsterdam},
author = {Jarvis, Scott},
booktitle = {Vocabulary Knowledge: Human Ratings and Automated Measures},
editor = {Jarvis, S and Daller, M},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2013{\_}Defining and measuring lexical diversity.pdf:pdf},
keywords = {complexity,diversity},
mendeley-tags = {complexity,diversity},
pages = {13--43},
publisher = {John Benjamins},
title = {{Defining and measuring lexical diversity}},
year = {2013}
}
@article{Wrigley2019,
author = {Wrigley, Terry and McCuster, Sean},
doi = {10.1080/13803611.2019.1617992},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wrigley, McCuster/Wrigley, McCuster{\_}2019{\_}Evidence based teaching a simple view of science.pdf:pdf},
journal = {Educational Research and Evaluation},
title = {{Evidence based teaching: a simple view of science}},
year = {2019}
}
@inproceedings{Nagao1994,
author = {Nagao, Makoto and Mori, Shinsuke},
booktitle = {COLING 14},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Nagao, Mori/Nagao, Mori{\_}1994{\_}A New Method of N-gram Statistics for Large Number of n and Automatic Extraction of Words and Phrases from Large Text D.pdf:pdf},
title = {{A New Method of N-gram Statistics for Large Number of n and Automatic Extraction of Words and Phrases from Large Text Data of Japanese}},
year = {1994}
}
@article{Gyllstad2014,
abstract = {This study is a contribution to the empirical underpinning of the Common European Framework of Reference for Languages (CEFR), and it aims to identify linguistic correlates to the proficiency levels defined by the CEFR. The study was conducted in a Swedish school setting, focusing on English, French and Italian, and examined the relationship between CEFR levels (A1–C2) assigned by experienced raters to learners' written texts and three measures of syntactic complexity (based on length of t-unit, subclause ratio, and mean length of clause (cf. Norris {\&} Ortega, 2009)). Data were elicited through two written tasks (a short letter and a narrative) completed by pupils of L2 English (N = 54) in years four, nine and the final year of upper-secondary school, L3 French (N = 38) in year nine and the final year of upper-secondary school, and L4 Italian (N = 28) in the final year of upper-secondary school and first year of university. The results showed that, globally, there were weak to medium-strong correlations between assigned CEFR levels and the three measures of syntactic complexity in English, French and Italian. Furthermore, it was found that syntactic complexity was homogeneous across the three languages at CEFR level A, whereas syntactic complexity was different across languages at CEFR level B, especially in the data for English and French. Consequences for the empirical validity of the CEFR framework and the nature of the three measures of complexity are discussed.},
author = {Gyllstad, Henrik and Granfeldt, Jonas and Bernardini, Petra and K{\"{a}}llkvist, Marie},
doi = {10.1075/eurosla.14.01gyl},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gyllstad et al/Gyllstad et al.{\_}2014{\_}Linguistic correlates to communicative proficiency levels of the CEFR The case of syntactic complexity in writte(2).pdf:pdf},
issn = {1568-1491},
journal = {EUROSLA Yearbook},
pages = {1--30},
title = {{Linguistic correlates to communicative proficiency levels of the CEFR: The case of syntactic complexity in written L2 English, L3 French and L4 Italian}},
volume = {14},
year = {2014}
}
@manual{Wickham2020b,
annote = {R package version 2.3.1},
author = {Wickham, Hadley and Miller, Evan},
title = {{haven: Import and Export 'SPSS', 'Stata' and 'SAS' Files}},
url = {https://cran.r-project.org/package=haven},
year = {2020}
}
@article{Jarvis2000,
abstract = {Numerous conflicting claims exist concerning the nature of L1 influence. This article argues that much of the confusion could be eliminated if a unified framework were established for this area of inquiry. Such a framework would minimally require transfer studies to consider at least 3 potential effects of L1 influence: (a) intra-L1-group similarities, (b) inter-L1-group differences, and (c) L1-IL performance similarities. This study examines all three types of evidence in the English lexical reference of Finnish-speaking and Swedish-speaking Finns at multiple levels of age and L2 exposure in three different but related elicitation tasks. The results suggest a subtle yet demonstrable presence for L1 influence in this area of interlanguage performance.},
author = {Jarvis, Scott},
doi = {10.1111/0023-8333.00118},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2000{\_}Methodological rigor in the study of transfer Identifying L1 influence in the interlanguage lexicon.pdf:pdf},
issn = {00238333},
journal = {Language Learning},
number = {2},
pages = {245--309},
title = {{Methodological rigor in the study of transfer: Identifying L1 influence in the interlanguage lexicon}},
volume = {50},
year = {2000}
}
@article{Romer2009,
abstract = {{\textless}p{\textgreater} This paper focuses on the interface of lexis and grammar and provides corpus evidence for the inseparability of two areas that have traditionally been kept apart, both in language teaching and in linguistic analysis and description. The paper will first give an overview of a number of influential research strands and model-building attempts in this area (Pattern Grammar and Collostructional Analysis, among others) and then explore the use of a selected lexical-grammatical pattern, the introductory {\textless}italic{\textgreater}it{\textless}/italic{\textgreater} pattern (e.g. {\textless}italic{\textgreater}it is essential for EFL learners to come to grips with connotations{\textless}/italic{\textgreater} , attested example) in corpora of expert and apprentice academic writing. {\textless}/p{\textgreater}},
author = {R{\"{o}}mer, Ute},
doi = {10.1075/arcl.7.06rom},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/R{\"{o}}mer/R{\"{o}}mer{\_}2009{\_}The inseparability of lexis and grammar Corpus linguistic perspectives.pdf:pdf},
isbn = {1572-0268},
issn = {1572-0268},
journal = {Annual Review of Cognitive Linguistics},
keywords = {apprentice vs,corpus linguistics,expert academic writing,introductory it,lexis-grammar inseparability,patterns,proficiency development},
number = {2009},
pages = {140--162},
title = {{The inseparability of lexis and grammar: Corpus linguistic perspectives}},
url = {http://www.jbe-platform.com/content/journals/10.1075/arcl.7.06rom},
volume = {7},
year = {2009}
}
@manual{Wickham2019n,
annote = {R package version 1.3.1},
author = {Wickham, Hadley and Bryan, Jennifer},
title = {{readxl: Read Excel Files}},
url = {https://cran.r-project.org/package=readxl},
year = {2019}
}
@book{Forsberg2008,
address = {Bern},
author = {Forsberg, Fanny},
publisher = {Peter Lang},
title = {{Le langage pr{\'{e}}fabriq{\'{e}}: formes fonctions et fr{\'{e}}quences en fran{\c{c}}ais parl{\'{e}} L2 et L1}},
year = {2008}
}
@article{DeClercq2017,
abstract = {Syntactic and linguistic complexity have been studied extensively in applied linguistics as indicators of linguistic performance, development, and proficiency. Recent publications have equally highlighted the reductionist approach taken to syntactic complexity measurement, which often focuses on one or two measures representing complexity at the level of clause-linking or the sentence, but eschews complexity measurement at other syntactic levels, such as the phrase or the clause. Previous approaches have also rarely incorporated measures representing the diversity of syntactic structures in learner productions. Finally, complexity development has rarely been considered from a cross-linguistic perspective, so that many questions pertaining to the cross-linguistic validity of complexity measurement remain. This article reports on an empirical study on syntactic complexity development and introduces a range of syntactic diversity measures alongside frequently used measures of syntactic elaboration. The study analyzed 100 English and 100 French second language oral narratives from adolescent native speakers of Dutch, sit- uated at 4 proficiency levels (beginner–advanced), as well as native speaker benchmark data from each language. The results reveal a gradual process of syntactic elaboration and syntactic diversification in both learner groups, while, especially in French, considerable differences between learners and native speakers reside in the distribution of specific clause types. Keywords:},
author = {{De Clercq}, Bastien and Housen, Alex},
doi = {10.1111/modl.12396},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/De Clercq, Housen/De Clercq, Housen{\_}2017{\_}A cross-linguistic perspective on syntactic complexity in L2 development Syntactic elaboration and diversity.pdf:pdf},
isbn = {1540-4781},
issn = {15404781},
journal = {Modern Language Journal},
keywords = {L2 English,L2 French,complexity,cross-linguistic,syntax},
number = {2},
pages = {315--334},
title = {{A cross-linguistic perspective on syntactic complexity in L2 development: Syntactic elaboration and diversity}},
volume = {101},
year = {2017}
}
@article{Prescod2014,
author = {Prescod, Paula and Robert, Jean-michel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Prescod, Robert/Prescod, Robert{\_}2014{\_}La langue seconde {\`{a}} la crois{\'{e}}e des chemins.pdf:pdf},
isbn = {9782252039359},
issn = {0071190X},
journal = {{\'{E}}tudes de linguistique appliqu{\'{e}}e},
number = {2},
pages = {139--146},
title = {{La langue seconde {\`{a}} la crois{\'{e}}e des chemins}},
volume = {174},
year = {2014}
}
@article{Yu2010,
abstract = {In the rating scales of major international language tests, as well as in automated evaluation systems (e.g. e-rater), a positive relationship is often claimed between lexical diversity, holistic quality of written or spoken discourses, and language proficiency of candidates. This article reports a posteriori validation study that analysed a sample of the archived data of an international language test to examine empirically to what extent such relationships exist. It is also noted that previous studies on lexical diversity in the field of applied linguistics have focused exclusively on either written or spoken discourses, no study to date has compared lexical diversity of spoken and written discourses produced by the same participants. Therefore, the second aim of this article is to understand the differences in lexical diversity between writing and speaking task performances, and to what extent the topics of the writing prompts may affect lexical diversity of written discourses. Using D as a measure of lexical diversity (Malvern and Richards 1997, 2002; Malvern et al. 2004), it was found that D had a statistically significant and positive correlation with the overall quality ratings of both writing and speaking performances as well as the candidates' general language proficiency. Nevertheless, the significant relationships were not borne out across the subgroups of the sample in terms of gender, first language background, purpose of taking the test and topics of the writing prompts. The different writing topics also had significant effects on lexical diversity—especially the topics that candidates were highly familiar with—even after controlling for writing ability and overall language proficiency. The lexical diversity of candidates' writing and speaking performances were approximately at the same level; further, D was found to be a better predictor of speaking than writing performance. The implications of these findings are discussed with specific reference to the use of lexical diversity measures to inform language test validation and the development of lexical diversity parameters in automated evaluation systems.},
author = {Yu, Guoxing},
doi = {10.1093/applin/amp024},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Yu/Yu{\_}2010{\_}Lexical diversity in writing and speaking task performances.pdf:pdf},
isbn = {0142-6001$\backslash$r1477-450X},
issn = {01426001},
journal = {Applied Linguistics},
number = {2},
pages = {236--259},
title = {{Lexical diversity in writing and speaking task performances}},
volume = {31},
year = {2010}
}
@article{Foster2000,
abstract = {The analysis of spoken language requires a principled way of dividing transcribed data into units in order to assess features such as accuracy and complexity. If such analyses are to be comparable across different studies, there must be agreement on the nature of the unit, and it must be possible to apply this unit reliably to a range of different types of speech data. There are a number of different units in use, the various merits of which have been discussed by Crookes (1990). However, while these have been used to facilitate the analysis of spoken language data, there is presently no comprehensive, accessible definition of any of them, nor are detailed guides available on how to identify such units in data sets. Research reports tend to provide simplistic two-line definitions of units exemplified, if at all, by unproblematic written examples. These are inadequate when applied to transcriptions of complex oral data, which tend not to lend themselves easily to a clear division into units. This paper was motivated by the need each of the three authors felt for a reliable and comprehensively defined unit to assist with the analysis of a variety of recordings of native and non-native speakers of English. We first discuss in very general terms the criteria according to which such a unit might be selected. Next, we examine the main categories of unit which have been adopted previously and provide a justification for the particular type of unit that we have chosen. Focusing on this unit, we identify a number of problems which are associated with the definition and exemplification of units of this type, and give examples of the awkward cases found in actual data. Finally we offer a definition of our unit, the Analysis of Speech Unit (AS-unit), providing adequate detail to address the problematic data analyses we have illustrated.},
author = {Foster, Pauline and Tonkyn, Alan and Wigglesworth, Gillian},
doi = {10.1093/applin/21.3.354},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Foster, Tonkyn, Wigglesworth/Foster, Tonkyn, Wigglesworth{\_}2000{\_}Measuring spoken language A unit for all reasons.pdf:pdf},
isbn = {0142-6001},
issn = {01426001},
journal = {Applied Linguistics},
number = {3},
pages = {354--375},
pmid = {20710093},
title = {{Measuring spoken language: A unit for all reasons}},
volume = {21},
year = {2000}
}
@inproceedings{Petrov2007,
abstract = {We present an automatic approach to tree annota- tion in which basic nonterminal symbols are alter- nately split and merged to maximize the likelihood of a training treebank. Starting with a simple X- bar grammar, we learn a new grammar whose non- terminals are subsymbols of the original nontermi- nals. In contrast with previous work, we are able to split various terminals to different degrees, as ap- propriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more ac- curate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F1 of 90.2{\%} on the Penn Treebank, higher than fully lexicalized systems.},
annote = {Berkley Parser Citation},
author = {Petrov, Slav and Barrett, Leon and Thibaux, Romain and Klein, Dan},
booktitle = {ACL 2006},
doi = {10.3115/1220175.1220230},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Petrov et al/Petrov et al.{\_}2007{\_}Learning accurate, compact, and interpretable tree annotation.pdf:pdf},
title = {{Learning accurate, compact, and interpretable tree annotation}},
year = {2007}
}
@article{Carruthers2006,
author = {Carruthers, Janice},
doi = {10.1093/fs/knl033},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Carruthers/Carruthers{\_}2006{\_}The syntax of oral French.pdf:pdf},
issn = {00161128},
journal = {French Studies},
number = {2},
pages = {251--260},
title = {{The syntax of oral French}},
volume = {60},
year = {2006}
}
@incollection{Gries2008a,
abstract = {This chapter has three objectives. First, it argues in favor of more rigorous definitions of the term 'phraseologism' on the basis of six dimensions and excmplifico these dimensions for several different kinds ofphrascologism. Second, it reviews the ways in which phraseologisms as defined here have figured in three different linguistic approaches: generative linguistics, cognitive linguistics, and corpus linguistics. Finally, it discusses some shortcomings in the identification of phraseologisms and points to relevant work to overcome these shortcomings.},
author = {Gries, Stefan Th.},
booktitle = {Phraseology: An interdisciplinary perspective},
doi = {10.1075/z.139.06gri},
editor = {Granger, Sylviane and Meunier, Fanny},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gries/Gries{\_}2008{\_}Phraseology and linguistic theory A brief survey.pdf:pdf},
isbn = {0521378672},
issn = {10441549},
pages = {3--25},
pmid = {8679219},
publisher = {John Benjamins},
title = {{Phraseology and linguistic theory: A brief survey}},
url = {https://benjamins.com/catalog/z.139.06gri},
year = {2008}
}
@incollection{Jichoshvili2019,
address = {Cham},
author = {Jichoshvili, Gvantsa and Gutierrez-Mangado, M Juncal},
booktitle = {Cross-Linguistic Influence: From Empirical Evidence to Classroom Practice},
editor = {Gutierrez-Mangado, M. Juncal and Martínez-Adrián, María and Gallardo-del-Puerto, Francisco},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jichoshvili, Gutierrez-Mangado/Jichoshvili, Gutierrez-Mangado{\_}2019{\_}Cross-Linguistic Influence at the Level of Word Order in L3 English by L1 Georgian L2 Russian Speak.pdf:pdf},
isbn = {9783030220662},
keywords = {bilingual,cli,l1 russian and georgian,l3 english,word order},
pages = {86--100},
publisher = {Springer},
title = {{Cross-Linguistic Influence at the Level of Word Order in L3 English by L1 Georgian / L2 Russian Speakers}},
year = {2019}
}
@book{Cohen1988,
abstract = {Cohen, J. "Statistical power for the social sciences." Hillsdale, NJ: Laurence Erlbaum and Associates (1988).},
author = {Cohen, Jacob},
booktitle = {Hillsdale, NJ: Laurence Erlbaum and Associates},
isbn = {0-8058-0283-5},
title = {{Statistical Power for the Behavioral Sciences (2nd Edition)}},
year = {1988}
}
@manual{Xie2019a,
annote = {R package version 0.8},
author = {Xie, Yihui},
title = {{xfun: Miscellaneous Functions by 'Yihui Xie'}},
url = {https://cran.r-project.org/package=xfun},
year = {2019}
}
@manual{Michalke2019b,
annote = {(Version 0.1-3)},
author = {Michalke, Meik},
title = {{koRpus.lang.en: Language Support for 'koRpus' Package: English}},
url = {https://reaktanz.de/?c=hacking{\&}s=koRpus},
year = {2019}
}
@article{Panevova2014,
author = {Panevov{\'{a}}, Jarmila and {\v{S}}ev{\v{c}}{\'{i}}kov{\'{a}}, Magda},
doi = {10.1075/la.215.02pan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Panevov{\'{a}}, {\v{S}}ev{\v{c}}{\'{i}}kov{\'{a}}/Panevov{\'{a}}, {\v{S}}ev{\v{c}}{\'{i}}kov{\'{a}}{\_}2014{\_}Delimitation of information between grammatical rules and lexicon.pdf:pdf},
pages = {33--52},
title = {{Delimitation of information between grammatical rules and lexicon}},
year = {2014}
}
@article{Ellis2009a,
abstract = {This paper presents a psycholinguistic analysis of constructions and their acquisition. It investigates effects upon naturalistic second language acquisition of type/token distributions in the islands comprising the linguistic form of English verb-argument constructions (VACs: VL verb locative, VOL verb object locative, VOO ditransitive) in the ESF corpus (Perdue, 1993). Goldberg (2006) argued that Zipfian type/token frequency distribution of verbs in natural language might optimize construction learning by providing one very high frequency exemplar that is also prototypical in meaning. Ellis {\&} Ferreira-Junior (2009) confirmed that in the naturalistic L2A of English, VAC verb type/token distribution in the input is Zipfian and learners first acquire the most frequent, prototypical and generic exemplar (e.g. put in VOL, give in VOO, etc.). This paper further illustrates how acquisition is affected by the frequency and frequency distribution of exemplars within each island of the construction (e.g. [Subj V Obj Oblpath/loc]), by their prototypicality, and, using a variety of psychological and corpus linguistic association metrics, by their contingency of form-function mapping.},
author = {Ellis, Nick C and Ferreira-Junior, Fernando},
doi = {10.1075/arcl.7.08ell},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, Ferreira-Junior/Ellis, Ferreira-Junior{\_}2009{\_}Constructions and their acquisition Islands and the distinctiveness of their occupancy.pdf:pdf},
issn = {1572-0268},
journal = {Annual Review of Cognitive Linguistics},
title = {{Constructions and their acquisition: Islands and the distinctiveness of their occupancy}},
year = {2009}
}
@manual{Sarkar2016,
annote = {R package version 0.6-28},
author = {Sarkar, Deepayan and Andrews, Felix},
title = {{latticeExtra: Extra Graphical Utilities Based on Lattice}},
url = {https://cran.r-project.org/package=latticeExtra},
year = {2016}
}
@article{Gerber2017,
author = {Gerber, Florian and Moesinger, Kaspar and Furrer, Reinhard},
doi = {10.1016/j.cageo.2016.11.015},
issn = {0098-3004},
journal = {Computer {\&} Geoscience},
pages = {109--119},
title = {{Extending {\{}R{\}} packages to support 64-bit compiled code: An illustration with spam64 and {\{}GIMMS{\}} {\{}NDVI3g{\}} data}},
volume = {104},
year = {2017}
}
@article{Ellis1996,
abstract = {This paper provides an overview of sequencing in SLA. It contends that much of language acquisition is in fact sequence learning (for vocabulary, the phonological units of language and their phonotactic sequences: for discourse, the lexical units of language and their se- quences in clauses and collocations). It argues that the resultant long- term knowledge base of language sequences serves as the database for the acquisition of language grammar. It next demonstrates that SLA of lexis, idiom, collocation, and grammar are all determined by individual differences in learners' ability to remember simple verbal strings in order. It outlines how interactions between short-term and long-term phonological memory systems allow chunking and the tun- ing of language systems better to represent structural information for particular languages. It proposes mechanisms for the analysis of se- quence information that result in knowledge of underlying grammar. Finally, it considers the relations between this empiricist approach and that of generative grammar.},
author = {Ellis, Nick C},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis/Ellis{\_}1996{\_}Sequencing in SLA Phonological Memory, Chunking, and Points of Order.pdf:pdf},
journal = {Studies in Second Language Acquisition},
pages = {91--126},
title = {{Sequencing in SLA: Phonological Memory, Chunking, and Points of Order}},
volume = {18},
year = {1996}
}
@manual{Hester2019b,
annote = {R package version 1.3.1},
author = {Hester, Jim and Wickham, Hadley},
title = {{fs: Cross-Platform File System Operations Based on 'libuv'}},
url = {https://cran.r-project.org/package=fs},
year = {2019}
}
@book{Tutin2014,
address = {Rennes},
author = {Tutin, Agn{\`{e}}s and Grossman, F},
publisher = {Presses Universitaires de Rennes},
title = {{L'{\'{e}}crit scientifique : du lexique au discours. Autour de Scientext [Scientific writing: from lexis to discourse. Overview of Scientext]}},
year = {2014}
}
@manual{Csardi2019d,
annote = {R package version 1.2.2},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and FitzJohn, Rich},
title = {{progress: Terminal Progress Bars}},
url = {https://cran.r-project.org/package=progress},
year = {2019}
}
@manual{Cheng2016,
annote = {R package version 1.0.0},
author = {Cheng, Joe},
title = {{crosstalk: Inter-Widget Interactivity for HTML Widgets}},
url = {https://cran.r-project.org/package=crosstalk},
year = {2016}
}
@incollection{Kuiper2004,
abstract = {Formulaic sequences (FS) are now recognized as an essential element of language use. However, research on FS has generally been limited to a focus on description, or on the place of FS in L1 acquisition. This volume opens new directions in FS research, concentrating on how FS are acquired and processed by the mind, both in the L1 and L2. The ten original studies in the volume illustrate the L2 acquisition of FS, the relationship between L1 and L2 FS, the relationship between corpus recurrence of FS and their psycholinguistic reality, the processes involved in reading FS, and pedagogical issues in teaching FS. The studies use a wide range of methodologies, many of them innovative, and thus the volume serves as a model for future research in the area. The volume begins with three survey chapters offering a background on the characteristics and measurement of FS.},
address = {Amsterdam},
author = {Kuiper, Koenraad},
booktitle = {Formulaic Sequences : Acquisition, Processing and Use},
editor = {Schmitt, Norbert},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiper/Kuiper{\_}2004{\_}Formulaic performance in conventionalised varieties of speech(2).pdf:pdf},
isbn = {1588115003, 9781588115003},
issn = {0039-8322},
pages = {37--54},
publisher = {John Benjamins},
title = {{Formulaic performance in conventionalised varieties of speech}},
year = {2004}
}
@article{Lowie2018,
abstract = {Traditional research into individual differences (ID) in second language (L2) learning is based on group studies with the implicit assumption that findings can be generalized to the individual. In this article, we challenge this view. We argue that L2 learners do not form ergodic ensembles and that language learning data lack stability. The data from our experiment show that even highly similar learners in terms of ID show clearly different learning trajectories over time; however, we did find that those who showed the greatest degree of variability gained the most in proficiency. Such findings lead to the view that group studies and individual case studies are complementary. Group studies give us valuable information about the relative weight of individual factors that may play a role in L2 development, but longitudinal case studies are needed to understand the process of individual learners' development.},
author = {Lowie, Wander M. and Verspoor, Marjolijn H.},
doi = {10.1111/lang.12324},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Lowie, Verspoor/Lowie, Verspoor{\_}2018{\_}Individual Differences and the Ergodicity Problem.pdf:pdf},
issn = {14679922},
journal = {Language Learning},
keywords = {Complex Dynamic Systems Theory (CDST),ergodicity,individual differences,longitudinal data,second language,theorySLA},
mendeley-tags = {theorySLA},
pages = {1--23},
title = {{Individual Differences and the Ergodicity Problem}},
volume = {XXX EarlyV},
year = {2018}
}
@article{Ferrand2010,
abstract = {The French Lexicon Project involved the collection of lexical decision data for 38,840 French words and the same number of non words. It was directly inspired by the English Lexicon Project (Balota et al., 2007) and produced very comparable frequency and word length effects. The present article describes the methods used to collect the data, reports analyses on the word frequency and the word length effects, and describes the Excel files that make the data freely available for research purposes. The word and pseudo word data from this article may be downloaded from http://brm.psychonomic-journals.org/content/supplemental. {\textcopyright} 2010 The Psychonomic Society, Inc.},
author = {Ferrand, Ludovic and New, Boris and Brysbaert, Marc and Keuleers, Emmanuel and Bonin, Patrick and M{\'{e}}ot, Alain and Augustinova, Maria and Pallier, Christophe},
doi = {10.3758/BRM.42.2.488},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ferrand et al/Ferrand et al.{\_}2010{\_}The French lexicon project Lexical decision data for 38,840 French words and 38,840 pseudo words.pdf:pdf},
issn = {1554351X},
journal = {Behavior Research Methods},
number = {2},
pages = {488--496},
title = {{The French lexicon project: Lexical decision data for 38,840 French words and 38,840 pseudo words}},
volume = {42},
year = {2010}
}
@inproceedings{Futrell2019,
address = {Paris},
author = {Futrell, Richard and Qian, Peng and Gibson, Edward and Fedorenko, Evelina and {Asher Blank}, Idan},
booktitle = {SyntaxFest 2019},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Futrell et al/Futrell et al.{\_}2019{\_}Syntactic dependencies correspond to word pairs with high mutual information.pdf:pdf},
month = {jul},
title = {{Syntactic dependencies correspond to word pairs with high mutual information}},
year = {2019}
}
@book{Guiraud1954,
address = {Paris},
author = {Guiraud, P},
keywords = {lexdiv{\_}G},
mendeley-tags = {lexdiv{\_}G},
publisher = {Presses Universitaires de France},
title = {{Les charact{\`{e}}res statistiques du vocabulaire : Essai de m{\'{e}}thodologie [The statistical characteristics of vocabulary: Methodological test]}},
year = {1954}
}
@article{Fenclova2014,
author = {Fenclov{\'{a}}, Marie},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Fenclov{\'{a}}/Fenclov{\'{a}}{\_}2014{\_}Langue seconde, langue {\'{e}}trang{\`{e}}re et aspects cognitifs.pdf:pdf},
isbn = {9782252039359},
issn = {0071-190X},
journal = {{\'{E}}tudes de linguistique appliqu{\'{e}}e},
number = {2},
pages = {147--155},
title = {{Langue seconde, langue {\'{e}}trang{\`{e}}re et aspects cognitifs}},
url = {http://www.cairn.info.proxy.bibliotheques.uqam.ca:2048/resume.php?ID{\_}ARTICLE=ELA{\_}174{\_}0147},
volume = {174},
year = {2014}
}
@incollection{Tracy-Ventura2016,
address = {Amsterdam},
author = {Tracy-Ventura, Nicole and Mitchell, Rosamond and McManus, Kevin},
booktitle = {Spanish Learner Corpus Research : Current Trends and Future Perspectives.},
editor = {Alonso-Ramos, Margarita},
pages = {117--142},
publisher = {John Benjamins},
title = {{The LANGSNAP longitudinal learner corpus}},
year = {2016}
}
@article{Ballier2016,
author = {Ballier, Nicolas and Gaillat, Thomas},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ballier, Gaillat/Ballier, Gaillat{\_}2016{\_}Classification d'apprenants francophones de l'anglais sur la base des m{\'{e}}triques de complexit{\'{e}} lexicale et sy.pdf:pdf},
journal = {Axtes de la conf{\'{e}}rence conjointe JEP-TALN-RECITAL 2016},
pages = {1--14},
title = {{Classification d'apprenants francophones de l'anglais sur la base des m{\'{e}}triques de complexit{\'{e}} lexicale et syntaxique}},
volume = {9},
year = {2016}
}
@article{Dahl2009,
author = {Dahl, {\"{O}}sten},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dahl/Dahl{\_}2009{\_}Testing the assumption of complexity invariance the case of Elfdalian and Swedish.pdf:pdf},
journal = {Language complexity as an evolving variable},
pages = {50--63},
title = {{Testing the assumption of complexity invariance: the case of Elfdalian and Swedish}},
year = {2009}
}
@article{Hudson1993,
author = {Hudson, Thom},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hudson/Hudson{\_}1993{\_}Nothing Does Not Equal Zero Problems with applying developmental sequence findings to assessement and pedagogy.pdf:pdf},
isbn = {0272263100012},
journal = {Studies in second language acquisition},
pages = {461--493},
publisher = {Cambridge University Press},
title = {{Nothing Does Not Equal Zero: Problems with applying developmental sequence findings to assessement and pedagogy}},
volume = {15},
year = {1993}
}
@manual{Benoit2019,
annote = {R package version 0.75},
author = {Benoit, Kenneth and Obeng, Adam},
title = {{readtext: Import and Handling for Plain and Formatted Text Files}},
url = {https://cran.r-project.org/package=readtext},
year = {2019}
}
@incollection{Veronique1995,
address = {Paris},
author = {V{\'{e}}ronique, Georges Daniel},
booktitle = {Vers un outil d'evaluation des comp{\'{e}}tences linguistiques en fran{\c{c}}ais dans l'espace francophone},
editor = {Chaudenson, Robert},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/V{\'{e}}ronique/V{\'{e}}ronique{\_}1995{\_}Le d{\'{e}}veloppement des connaissances grammaticales en fran{\c{c}}ais langue 2 implications pour une {\'{e}}valuation.pdf:pdf},
publisher = {CIRELFA},
title = {{Le d{\'{e}}veloppement des connaissances grammaticales en fran{\c{c}}ais langue 2 : implications pour une {\'{e}}valuation}},
year = {1995}
}
@article{Vasylets2017,
abstract = {Taking a psycholinguistic orientation within task-based language teaching scholarship, this study investigated the effects of mode (oral vs. written) and task complexity on second language (L2) performance. The participants were 78 Catalan/Spanish learners of English as a foreign language. Half of the participants performed the simple and complex versions of an argumentative, instruction-giving task orally, the other half did it in writing. The comparison of the participants' oral and written performance revealed that speakers produced more idea units but that writers achieved higher scores for subordination, mean length of analysis-of-speech units, lexical diversity, extended idea units, and time on task. As for the effects of task complexity, the participants' written production showed more variation between the complex and the simple versions of the task. These findings are interpreted in light of task modality effects in L2 learning and discussed in relation to task complexity theory and research.},
author = {Vasylets, Olena and Gilabert, Roger and Manch{\'{o}}n, Rosa M.},
doi = {10.1111/lang.12228},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Vasylets, Gilabert, Manch{\'{o}}n/Vasylets, Gilabert, Manch{\'{o}}n{\_}2017{\_}The Effects of Mode and Task Complexity on Second Language Production.pdf:pdf},
issn = {14679922},
journal = {Language Learning},
keywords = {mode,propositional complexity,second language,speech,task complexity,writing},
number = {7},
pages = {394--430},
title = {{The Effects of Mode and Task Complexity on Second Language Production}},
volume = {67},
year = {2017}
}
@incollection{Campione2005,
address = {Amsterdam},
author = {Campione, Estelle and V{\'{e}}ronis, Jean and Deulofeu, Jos{\'{e}}},
booktitle = {C-ORAL-ROM: Integrated Reference Corpora for Spoken Romance Languages},
editor = {Cresti, E and Moneglia, M},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Campione, V{\'{e}}ronis, Deulofeu/Campione, V{\'{e}}ronis, Deulofeu{\_}2005{\_}The French Corpus.pdf:pdf},
keywords = {corpaix},
mendeley-tags = {corpaix},
pages = {111--133},
publisher = {John Benjamins},
title = {{The French Corpus}},
year = {2005}
}
@manual{Zhu2019,
annote = {R package version 1.1.0},
author = {Zhu, Hao},
title = {{kableExtra: Construct Complex Table with 'kable' and Pipe Syntax}},
url = {https://cran.r-project.org/package=kableExtra},
year = {2019}
}
@book{Goldberg2006,
address = {Oxford},
author = {Goldberg, Adele E},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Goldberg/Goldberg{\_}2006{\_}Constructions at work.PDF:PDF},
publisher = {Oxford University Press},
title = {{Constructions at work}},
year = {2006}
}
@manual{DeJonge2013,
annote = {R package version 0.3-2},
author = {de Jonge, Edwin},
title = {{whisker: {\{}{\{}mustache{\}}{\}} for R, logicless templating}},
url = {https://cran.r-project.org/package=whisker},
year = {2013}
}
@article{Eckerth2009,
abstract = {The present paper reports on an approximate replication of Foster's (1998) study on the negotiation of meaning. Foster investigated the interactional adjustments produced by L2 English learners working on different types of language learning tasks in a classroom setting. The replication study duplicates the methods of data collection and data analysis of the original study, but alters the target language (L2 German) and adds a stimulated recall methodology. The results of the replication study partially confirm Foster's results, and introduce some further differentiated findings. It is concluded that the original study's concern with the transferability of laboratory findings to classroom settings should be investigated in greater detail.},
author = {Eckerth, Johannes},
doi = {10.1017/s0261444808005442},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Eckerth/Eckerth{\_}2009{\_}Negotiated interaction in the L2 classroom.pdf:pdf},
isbn = {0261444808},
issn = {0261-4448},
journal = {Language Teaching},
number = {1},
pages = {109--130},
title = {{Negotiated interaction in the L2 classroom}},
volume = {42},
year = {2009}
}
@book{Xie2018,
address = {Boca Raton, Florida},
annote = {ISBN 9781138359338},
author = {Xie, Yihui and Allaire, J J and Grolemund, Garrett},
publisher = {Chapman and Hall/CRC},
title = {{R Markdown: The Definitive Guide}},
url = {https://bookdown.org/yihui/rmarkdown},
year = {2018}
}
@phdthesis{Kyle2016,
abstract = {Syntactic complexity has been an area of significant interest in L2 writing development},
author = {Kyle, Kristopher},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kyle/Kyle{\_}2016{\_}Measuring syntactic Development in L2 Writing Fine Grained Indices of Syntactic Complexity and Usage-Based Indices of Syntacti.pdf:pdf},
keywords = {Language assessment,Language use,Natural language processing,Second language acquisition,Syntactic complexity,Writing development,taasc},
mendeley-tags = {taasc},
school = {Georgia State University},
title = {{Measuring syntactic Development in L2 Writing: Fine Grained Indices of Syntactic Complexity and Usage-Based Indices of Syntactic Sophistication (doctoral dissertation)}},
type = {PhD Dissertation},
url = {https://scholarworks.gsu.edu/alesl{\_}diss/35},
year = {2016}
}
@manual{Wickham2020c,
annote = {R package version 1.1.0},
author = {Wickham, Hadley and Henry, Lionel},
title = {{tidyr: Tidy Messy Data}},
url = {https://cran.r-project.org/package=tidyr},
year = {2020}
}
@manual{RCoreTeam2018,
annote = {R package version 0.8-71},
author = {{R Core Team}},
title = {{foreign: Read Data Stored by 'Minitab', 'S', 'SAS', 'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ...}},
url = {https://cran.r-project.org/package=foreign},
year = {2018}
}
@inproceedings{Goossens2017,
author = {Goossens, Maarten and Maeyer, Sven De},
booktitle = {Technology Enhanced Assessment 2017},
doi = {10.1007/978-3-319-97807-9},
editor = {Ras, E and {Rold{\'{a}}n Guerrero}, A. E.},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Goossens, Maeyer/Goossens, Maeyer{\_}2017{\_}How to Obtain Efficient High Reliabilities in Assessing Texts Rubrics vs Comparative Judgement.pdf:pdf},
isbn = {978-3-319-97806-2},
keywords = {Comparative judgement,Efficiency,Reliability,Rubrics,ciency,judgement {\'{a}} ef fi,reliability,{\'{a}} rubrics {\'{a}} comparative},
pages = {13--25},
publisher = {Springer International Publishing},
title = {{How to Obtain Efficient High Reliabilities in Assessing Texts: Rubrics vs Comparative Judgement}},
url = {http://link.springer.com/10.1007/978-3-319-97807-9},
year = {2017}
}
@article{Hashimoto2019,
author = {Hashimoto, Brett J. and Egbert, Jesse},
doi = {10.1111/lang.12353},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Hashimoto, Egbert/Hashimoto, Egbert{\_}2019{\_}More Than Frequency Exploring Predictors of Word Difficulty for Second Language Learners.pdf:pdf},
issn = {14679922},
journal = {Language Learning},
keywords = {corpus frequency,lexical acquisition,recognition,second language,vocabulary,vocabulary size test,word difficulty},
number = {XXXX},
pages = {1--34},
title = {{More Than Frequency? Exploring Predictors of Word Difficulty for Second Language Learners}},
volume = {XXXX},
year = {2019}
}
@manual{Urbanek2020,
annote = {R package version 0.1-4},
author = {Urbanek, Simon and Ts'o, Theodore},
title = {{uuid: Tools for Generating and Handling of UUIDs}},
url = {https://cran.r-project.org/package=uuid},
year = {2020}
}
@inproceedings{Green2011,
abstract = {Dependency parsing has been a prime focus of NLP research of late due to its ability to help parse languages with a free word order. Dependency parsing has been shown to improve NLP systems in certain languages and in many cases is considered the state of the art in the field. The use of dependency parsing has mostly been limited to free word order languages, however the usefulness of dependency structures may yield improvements in many of the word's 6,000+ languages. I will give an overview of the field of dependency parsing while giving my aims for future research. Many NLP applications rely heavily on the quality of dependency parsing. For this reason, I will examine how different parsers and annotation schemes influence the overall NLP pipeline in regards to machine translation as well as the the baseline parsing accuracy.},
address = {Prague},
author = {Green, N},
booktitle = {WDS'11 Proceedings of Contributed Papers, Part I},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Green/Green{\_}2011{\_}Dependency Parsing.pdf:pdf},
isbn = {9788073781842},
title = {{Dependency Parsing}},
year = {2011}
}
@manual{HarrellJr2019a,
annote = {R package version 5.1-3.1},
author = {{Harrell Jr}, Frank E},
title = {{rms: Regression Modeling Strategies}},
url = {https://cran.r-project.org/package=rms},
year = {2019}
}
@techreport{Blanchard2013,
abstract = {This report presents work on the development of a new corpus of non-native English writing. It will be useful for the task of native language identification, as well as grammatical error detection and correction, and automatic essay scoring. In this report, the corpus is described in detail.},
author = {Blanchard, Daniel and Tetreault, Joel and Higgins, Derrick and Cahill, Aoife and Chodorow, Martin},
booktitle = {ETS Research Report Series (ETS RR-13-24)},
doi = {10.1002/j.2333-8504.2013.tb02331.x},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Blanchard et al/Blanchard et al.{\_}2013{\_}TOEFL11 A Corpus of Non-Native English.pdf:pdf},
institution = {Educational testing Service},
issn = {2330-8516},
title = {{TOEFL11: A Corpus of Non-Native English}},
year = {2013}
}
@manual{corrplot2017,
annote = {(Version 0.84)},
author = {Wei, Taiyun and Simko, Viliam},
title = {{R package "corrplot": Visualization of a Correlation Matrix}},
url = {https://github.com/taiyun/corrplot},
year = {2017}
}
@book{Polzin-Haumann2015,
doi = {10.1515/9783110450408-202},
editor = {Polzin-Haumann, Claudia and Schweickard, Wolfgang},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Unknown/Unknown{\_}2015{\_}Manuel de linguistique fran{\c{c}}aise.pdf:pdf},
isbn = {9783110302080},
publisher = {de Gruyter},
title = {{Manuel de linguistique fran{\c{c}}aise}},
year = {2015}
}
@manual{Gilbert2019,
annote = {R package version 2016.8-1.1},
author = {Gilbert, Paul and Varadhan, Ravi},
title = {{numDeriv: Accurate Numerical Derivatives}},
url = {https://cran.r-project.org/package=numDeriv},
year = {2019}
}
@article{Goldhahn2012,
abstract = {The Leipzig Corpora Collection offers free online access to 136 monolingual dictionaries enriched with statistical information. In this paper we describe current advances of the project in collecting and processing text data automatically for a large number of languages. Our main interest lies in languages of "low density", where only few text data exists online. The aim of this approach is to create monolingual dictionaries and statistical information for a high number of new languages and to expand the existing dictionaries, opening up new possibilities for linguistic typology and other research. Focus of this paper will be set on the infrastructure for the automatic acquisition of large amounts of monolingual text in many languages from various sources. Preliminary results of the collection of text data will be presented. The mainly language-independent framework for preprocessing, cleaning and creating the corpora and computing the necessary statistics will also be depicted.},
author = {Goldhahn, Dirk and Eckart, Thomas and Quasthoff, Uwe},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Goldhahn, Eckart, Quasthoff/Goldhahn, Eckart, Quasthoff{\_}2012{\_}Building large monolingual dictionaries at the leipzig corpora collection From 100 to 200 languages.pdf:pdf},
isbn = {9782951740877},
journal = {Proceedings of the 8th International Conference on Language Resources and Evaluation, LREC 2012},
keywords = {Corpus creation,Minority languages,Text acquisition,wordschatz},
mendeley-tags = {wordschatz},
pages = {759--765},
title = {{Building large monolingual dictionaries at the leipzig corpora collection: From 100 to 200 languages}},
year = {2012}
}
@article{Zeileis2005,
author = {Zeileis, Achim and Grothendieck, Gabor},
doi = {10.18637/jss.v014.i06},
journal = {Journal of Statistical Software},
number = {6},
pages = {1--27},
title = {{zoo: S3 Infrastructure for Regular and Irregular Time Series}},
volume = {14},
year = {2005}
}
@article{Clahsen1981,
abstract = {The few existing longitudinal studies on acquisition show that the frequency of a certain may go Molony (1977:279), for example, reports "a dramatic increase in errors from three and a half months (March) to five months, then a steady decline so that by October},
author = {Clahsen, Harald and Wuppertal, Manfred and Pienemann, Manfred},
doi = {10.1017/S0272263100004137},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Clahsen, Wuppertal, Pienemann/Clahsen, Wuppertal, Pienemann{\_}1981{\_}On Determining Developmental Stages in Natural Second Language Acquisition.pdf:pdf},
isbn = {doi:10.1017/S0272263100004137},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
number = {2},
pages = {109--135},
pmid = {22223540},
title = {{On Determining Developmental Stages in Natural Second Language Acquisition}},
volume = {3},
year = {1981}
}
@manual{ZAWAM2018,
annote = {R package version 0.10.0},
author = {ZAWAM, Jalal-Edine and Guillem, Francois},
title = {{manipulateWidget: Add Even More Interactivity to Interactive Charts}},
url = {https://cran.r-project.org/package=manipulateWidget},
year = {2018}
}
@article{Jarvis2017,
abstract = {The present study discusses the relevance of measures of lexical diversity (LD) to the assessment of learner corpora. It also argues that existing measures of LD, many of which have become specialized for use with language corpora, are fundamentally measures of lexical repetition, are based on an etic perspective of language, and lack construct validity. The proposed solution draws from Zipf's (1935) emic perspective of language, which views LD as a matter of perception, but which also assumes that competent speakers of a common language share similar perceptions. The present study tests whether this is true and specifically whether untrained human raters will show high levels of inter-rater reliability in their judgments of the levels of LD found in 60 texts extracted from a corpus of narratives written in English by a mix of language learners and native speakers. The results confirm Zipf's assertion, but also indicate that a relatively large number of motivated raters are needed to demonstrate this tendency. The remainder of the study discusses the implications these results have for the development of an automated measure of LD to be used with learner corpora. The proposed method begins with human judgments of a representative subsample of a corpus, proceeds to a statistical model of objective measures that accurately predicts the human judgments, and ends with a multidimensional, corpus-specific automated measure that outputs reliable estimates of how a reliable group of human judges would rate the levels of LD in the texts of that corpus. {\textcopyright} 2017, {\textcopyright} The Author(s) 2017.},
author = {Jarvis, Scott},
doi = {10.1177/0265532217710632},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jarvis/Jarvis{\_}2017{\_}Grounding lexical diversity in human judgments.pdf:pdf},
isbn = {0026-7902},
issn = {14770946},
journal = {Language Testing},
keywords = {Complexity,learner corpora,lexical diversity,lexical measures,lexical proficiency},
number = {4},
pages = {537--553},
title = {{Grounding lexical diversity in human judgments}},
volume = {34},
year = {2017}
}
@article{Crible,
author = {Crible, Ludivine and Degand, Liesbeth},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Crible, Degand/Crible, Degand{\_}Unknown{\_}Domains and functions A two-dimensional account of discourse markers.pdf:pdf},
title = {{Domains and functions: A two-dimensional account of discourse markers}}
}
@manual{TempleLang2020,
annote = {R package version 1.98-1.2},
author = {{Temple Lang}, Duncan},
title = {{RCurl: General Network (HTTP/FTP/...) Client Interface for R}},
url = {https://cran.r-project.org/package=RCurl},
year = {2020}
}
@book{MacWhinney2000,
address = {Mahwah, NJ},
author = {MacWhinney, B},
edition = {3rd Editio},
keywords = {clan},
mendeley-tags = {clan},
publisher = {Lawrence Erlbaum Associates.},
title = {{The CHILDES Project: Tools for Analyzing Talk.}},
year = {2000}
}
@manual{Firke2020,
annote = {R package version 1.2.1},
author = {Firke, Sam},
title = {{janitor: Simple Tools for Examining and Cleaning Dirty Data}},
url = {https://cran.r-project.org/package=janitor},
year = {2020}
}
@article{ForsbergLundell2014,
abstract = {The aim of this study is twofold: first, to find evidence for additional advanced stages in L2 French. The continuum of Bartning and Schlyter (2004)istaken as a point of departure. It is hypothesized that a number of linguistic criteria will account for high-level proficiency. It was earlier found that besides morpho- syntax, formulaic sequences and information structure are interesting phenomena for highly proficient learners (Bartning, Forsberg and Hancock, 2009). Three more measures are now added, i.e. perceived nativelikeness, lexical richness and fluency. The second aim of this study is to contribute to the debate on the possibility of nativelike attainment. The study shows that several measures are prone to characterise nativelike performance in highly proficient users among whom some attain nativelikeness.},
author = {{Forsberg Lundell}, Fanny and Bartning, Inge and Engel, Hugues and Gudmundson, Anna and Hancock, Victorine and Lindqvist, Christina},
doi = {10.1017/S0959269513000057},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Forsberg Lundell et al/Forsberg Lundell et al.{\_}2014{\_}Beyond advanced stages in high-level spoken L2 French.pdf:pdf},
isbn = {2009:206207},
issn = {14740079},
journal = {Journal of French Language Studies},
number = {2},
pages = {255--280},
title = {{Beyond advanced stages in high-level spoken L2 French}},
volume = {24},
year = {2014}
}
@manual{Slowikowski2020,
annote = {R package version 0.8.2},
author = {Slowikowski, Kamil},
title = {{ggrepel: Automatically Position Non-Overlapping Text Labels with 'ggplot2'}},
url = {https://cran.r-project.org/package=ggrepel},
year = {2020}
}
@article{Cooper1976,
abstract = {AbstractThe present study was designed to analyze by quantitative methods a corpus of writing produced by four levels of American college students and by one group of professional German writers. Analysis was undertaken to (a) determine whether or not significant quantitative differences in the use of selected syntactic structures exist between the five groups; and (b) test the validity of the Hunt method of measuring syntactic maturity when applied to the writing of second language learners and native Germans. Basically, the Hunt method measures syntactic acquisition by quantifying the rate of occurrence of sentence-embedding transformation in writing samples. The findings indicate that developmental stages in the acquisition of written German syntax did exist in this study and that these stages were most clearly definable between every other level. Hunt's method of measuring syntactic maturity was successfully applied to measuring second language acquisition. In addition, some comparisons were made between this study and other first language acquisition studies and suggestions for further research were given.},
author = {Cooper, Thomas C.},
doi = {10.1080/00220671.1976.10884868},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Cooper/Cooper{\_}1976{\_}Measuring written syntactic patterns of second language learners of German.pdf:pdf},
issn = {19400675},
journal = {Journal of Educational Research},
number = {5},
pages = {176--183},
title = {{Measuring written syntactic patterns of second language learners of German}},
volume = {69},
year = {1976}
}
@manual{Ushey2018,
annote = {R package version 0.1.7},
author = {Ushey, Kevin},
title = {{sourcetools: Tools for Reading, Tokenizing and Parsing R Code}},
url = {https://cran.r-project.org/package=sourcetools},
year = {2018}
}
@article{Biber2020,
author = {Biber, Douglas and Reppen, Randi and Staples, Shelley and Egbert, Jesse},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Biber et al/Biber et al.{\_}2020{\_}Exploring the longitudinal development of grammatical complexity in the disciplinary writing of L2-English university.doc:doc},
journal = {International Journal of Learner Corpus Research},
number = {1},
pages = {38--71},
title = {{Exploring the longitudinal development of grammatical complexity in the disciplinary writing of L2-English university students}},
volume = {6},
year = {2020}
}
@article{DeClercq2019,
author = {{De Clercq}, Bastien and Housen, Alex},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/De Clercq, Housen/De Clercq, Housen{\_}2019{\_}The development of morphological complexity A cross-linguistic study of L2 French and English.pdf:pdf},
journal = {Second Language Research},
number = {1},
pages = {71--97},
title = {{The development of morphological complexity: A cross-linguistic study of L2 French and English}},
volume = {35},
year = {2019}
}
@manual{Auguie2017a,
annote = {R package version 2.3},
author = {Auguie, Baptiste},
title = {{gridExtra: Miscellaneous Functions for "Grid" Graphics}},
url = {https://cran.r-project.org/package=gridExtra},
year = {2017}
}
@incollection{Novakova2019,
abstract = {In this contribution we take a keyword approach (Scott and Tribble in Textual Patterns: Key Words and Corpus Analysis in Language Education. Benjamins, Amsterdam, 2006) to exploring the part key “descriptive” adverbs play in the creation of literariness (литepaтypнocть, Jakobson 1921) in English novels compared with their functional equivalents in French novels. To our knowledge, little research has been done on the specific contribution made by key adverbs and adverbial phrases in fiction as well as on how they are translated (apart from a few stray remarks in translation textbooks). In this chapter we aim to (a) quantify the key adverbs used in English and French fiction, (b) investigate the ways in which selected adverbs contribute to conventional discursive patterns (“motifs”) found in fiction, and (c) analyze French functional equivalents of English key adverbs found in an English–French parallel corpus. We hypothesize also that adverbs of manner (*ly or *ment) tend to co-occur with certain semantic verb classes (speech, gesture, cognition, movement, and communication) and test this assumption by applying statistical methods to large English and French comparable corpora.},
address = {Cham},
author = {Novakova, Iva and Siepmann, Dirk and Gymnich, Marion},
booktitle = {Phraseology and style in subgenres of the novel: A synthesis of corpus and literary perspectives},
doi = {10.1007/978-3-030-23744-8_3},
editor = {Novakova, Iva and Siepmann, Dirk},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Novakova, Siepmann, Gymnich/Novakova, Siepmann, Gymnich{\_}2019{\_}Key adverbs and adverbial motifs in english fiction and their french functional equivalents(2).pdf:pdf},
isbn = {9783030237448},
keywords = {Key manner adverbs Adverbial motifs Natural equiva},
pages = {47--81},
publisher = {Palgrave Macmillan},
title = {{Key adverbs and adverbial motifs in english fiction and their french functional equivalents}},
year = {2019}
}
@misc{CouncilofEurope2009,
author = {{Council of Europe}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Council of Europe/Council of Europe{\_}2009{\_}Manual for relating language examinations to the Common European Framework of Reference for Languages.pdf:pdf},
title = {{Manual for relating language examinations to the Common European Framework of Reference for Languages}},
url = {https://www.coe.int/en/web/common-european-framework-reference-languages/relating-examinations-to-the-cefr},
year = {2009}
}
@manual{Csardi2015,
annote = {R package version 1.0.2},
author = {Csardi, Gabor},
title = {{prettyunits: Pretty, Human Readable Formatting of Quantities}},
url = {https://cran.r-project.org/package=prettyunits},
year = {2015}
}
@manual{Ooms2018,
annote = {R package version 1.7},
author = {Ooms, Jeroen},
title = {{commonmark: High Performance CommonMark and Github Markdown Rendering in R}},
url = {https://cran.r-project.org/package=commonmark},
year = {2018}
}
@inproceedings{Tack2016,
abstract = {This study examines two possibilities of using the FLELex graded lexicon for the automated assessment of text complexity in French as a foreign language learning. From the lexical frequency distributions described in FLELex, we derive a single level of difficulty for each word in a parallel corpus of original and simplified texts. We then use this data to automatically address the lexical complexity of texts in two ways. On the one hand, we evaluate the degree of lexical simplification in manually simplified texts with respect to their original version. Our results show a significant simplification effect, both in the case of French narratives simplified for non-native readers and in the case of simplified Wikipedia texts. On the other hand, we define a predictive model which identifies the number of words in a text that are expected to be known at a particular learning level. We assess the accuracy with which these predictions are able to capture actual word knowledge as reported by Dutch-speaking learners of French. Our study shows that although the predictions seem relatively accurate in general (87.4{\%} to 92.3{\%}), they do not yet seem to cover the learners{\{}'{\}} lack of knowledge very well.},
address = {Portoroz},
author = {Tack, Ana{\"{i}}s and Francois, Thomas and Ligozat, Anne-Laure and Fairon, C{\'{e}}drick},
booktitle = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Tack et al/Tack et al.{\_}2016{\_}Evaluating Lexical Simplification and Vocabulary Knowledge for Learners of {\{}F{\}}rench Possibilities of Using the {\{}FLEL{\}}ex.pdf:pdf},
keywords = {flelex,lexical simplification,vocabulary knowledge prediction},
month = {may},
pages = {230--236},
title = {{Evaluating Lexical Simplification and Vocabulary Knowledge for Learners of {\{}F{\}}rench: Possibilities of Using the {\{}FLEL{\}}ex Resource}},
url = {https://www.aclweb.org/anthology/L16-1035},
year = {2016}
}
@article{Lakens2017,
author = {Lakens, Daniel},
doi = {10.1177/1948550617697177},
journal = {Social Psychological and Personality Science},
pages = {1--8},
title = {{Equivalence tests: A practical primer for t-tests, correlations, and meta-analyses}},
volume = {1},
year = {2017}
}
@article{Granfeldt2014,
abstract = {Abstract One core area of research in Second Language Acquisition is the identification and definition of developmental stages in different L2s. For L2 French, Bartning and Schlyter (2004) presented a model of six morphosyntactic stages of development in the shape of grammatical profiles. The model formed the basis for the computer program Direkt Profil (Granfeldt et al., 2006), which carries out an automated analysis of the developmental stage of a learner text. The aim of the present study was to explore the relevance of Direkt Profil as a diagnostic assessment tool by comparing Direkt Profil's automated profile analysis with assessment by trained language teachers. Data for the present study come from the CEFLE corpus of written L2 French ({\AA}gren, 2008). The learner texts were first analysed for developmental stage by the computer program Direkt Profil. In a second step, seven experienced language teachers of French assessed the same texts. The results indicated relatively high degrees of correlation and showed that the analysis of developmental stage by Direkt Profil could explain 73{\%} of the variance in the teachers' mean assessments (r2 = 0.735). In addition, we concluded that the teachers were in agreement with each other and with the computer program when assessing texts at low and high proficiency levels respectively. The most important variation in the teachers' assessments was found in texts at intermediate levels, due to an inconsistent use of grammar and vocabulary. One of the advantages of using Direkt Profil as a diagnostic assessment tool is that it provides immediate and detailed feedback indicating how certain types of linguistic structures, correct or incorrect, are related to different stages of development.},
author = {Granfeldt, Jonas and {\AA}gren, Malin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granfeldt, {\AA}gren/Granfeldt, {\AA}gren{\_}2014{\_}SLA developmental stages and teachers' assessment of written French Exploring Direkt Profil as a diagnostic ass.pdf:pdf},
journal = {Language Testing},
number = {3},
pages = {285--305},
title = {{SLA developmental stages and teachers' assessment of written French: Exploring Direkt Profil as a diagnostic assessment tool}},
volume = {31},
year = {2014}
}
@manual{Koenker2017,
annote = {R package version 1.77},
author = {Koenker, Roger and Ng, Pin},
title = {{SparseM: Sparse Linear Algebra}},
url = {https://cran.r-project.org/package=SparseM},
year = {2017}
}
@inproceedings{Nivre2006,
annote = {Malt Parser citation},
author = {Nivre, Joakim and Hall, Johan and Nilsson, Jens},
booktitle = {LREC 2006},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Nivre, Hall, Nilsson/Nivre, Hall, Nilsson{\_}2006{\_}MaltParser A data-driven parser-generator for dependency parsing.pdf:pdf},
pages = {2216--2219},
title = {{MaltParser : A data-driven parser-generator for dependency parsing}},
year = {2006}
}
@phdthesis{Bolly2008,
author = {Bolly, Catherine},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bolly/Bolly{\_}2008{\_}Les unités phraséologiques un phénomène linguistique complexe Séquences (semi-) figées construites avec les ve.pdf:pdf},
school = {Universit{\'{e}} de Louvain},
title = {{Les unités phraséologiques : un phénomène linguistique complexe? Séquences (semi-) figées construites avec les verbes "prendre" et "donner" en français écrit L1 et L2 : Approche descriptive et acquisitionnelle.}},
type = {Doctoral Dissertation},
year = {2008}
}
@article{Horst2006,
abstract = {The study drew on an 80,000-word corpus consisting of narrative texts produced in response to picture prompts by 210 beginner-level francophone learners of English (11-12-year-olds). The unique feature of the corpus is its longitudinal character: The samples were collected at four 100hour intervals of intensive language instruction, during which time students made considerable progress in listening and speaking. However, analysis of these staged sub-corpora using Laufer and Nation's 1995 Lexical Frequency Profile did not identify the expected increase in use of less frequent words. Further analyses using three measures available at www.lextutor.ca (a Greco-Latin cognate index, a count of word families, and a types-per-family ratio) showed that although the learners continued to use large proportions of frequent words, their productive vocabulary featured fewer French cognates, a greater variety of frequent words, and more morphologically developed forms. Implications for frequency-based vocabulary acquisition research and vocabulary teaching are discussed. {\textcopyright} 2006 The Canadian Modern Language Review/La Revue canadienne des langues vivantes.},
author = {Horst, Marlise and Collins, Laura},
doi = {10.3138/cmlr.63.1.83},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Horst, Collins/Horst, Collins{\_}2006{\_}From faible to strong How does their vocabulary grow.pdf:pdf},
issn = {00084506},
journal = {Canadian Modern Language Review},
number = {1},
pages = {83--106},
title = {{From faible to strong: How does their vocabulary grow?}},
volume = {63},
year = {2006}
}
@manual{Dias2018,
annote = {R package version 0.3.1},
author = {Dias, David Valentim},
title = {{ini: Read and Write '.ini' Files}},
url = {https://cran.r-project.org/package=ini},
year = {2018}
}
@manual{Csardi2019c,
annote = {R package version 3.4.1},
author = {Cs{\'{a}}rdi, G{\'{a}}bor and Chang, Winston},
title = {{processx: Execute and Control System Processes}},
url = {https://cran.r-project.org/package=processx},
year = {2019}
}
@manual{Ooms2020,
annote = {R package version 0.5.0},
author = {Ooms, Jeroen},
title = {{av: Working with Audio and Video in R}},
url = {https://cran.r-project.org/package=av},
year = {2020}
}
@article{Hothorn2006a,
author = {Hothorn, Torsten and Hornik, Kurt and van de Wiel, Mark A and Zeileis, Achim},
doi = {10.1198/000313006X118430},
journal = {The American Statistician},
number = {3},
pages = {257--263},
title = {{A {\{}L{\}}ego system for conditional inference}},
volume = {60},
year = {2006}
}
@incollection{Wahl2020,
author = {Wahl, Alexander and Gries, Stefan Th.},
booktitle = {Computational Phraseology},
editor = {Pastor, Gloria Corpas and Colson, Jean-Pierre},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Wahl, Gries/Wahl, Gries{\_}2020{\_}Computational extraction of formulaic sequences from corpora.pdf:pdf},
keywords = {adjusted frequency list,child,collocation extraction,formulaic sequences,language,lexical association,merge},
pages = {84--110},
publisher = {John Benjamins},
title = {{Computational extraction of formulaic sequences from corpora}},
year = {2020}
}
@article{Stauffer2009,
author = {Stauffer, Reto and Mayr, Georg J and Dabernig, Markus and Zeileis, Achim},
doi = {10.1175/BAMS-D-13-00155.1},
journal = {Bulletin of the American Meteorological Society},
number = {2},
pages = {203--216},
title = {{Somewhere over the Rainbow: How to Make Effective Use of Colors in Meteorological Visualizations}},
volume = {96},
year = {2009}
}
@manual{Komsta2013,
annote = {R package version 0.1-2},
author = {Komsta, Lukasz},
title = {{dtt: Discrete Trigonometric Transforms}},
url = {https://cran.r-project.org/package=dtt},
year = {2013}
}
@article{Honaker2011,
author = {Honaker, James and King, Gary and Blackwell, Matthew},
journal = {Journal of Statistical Software},
number = {7},
pages = {1--47},
title = {{Amelia II: A Program for Missing Data}},
url = {http://www.jstatsoft.org/v45/i07/},
volume = {45},
year = {2011}
}
@article{Strobl2007,
author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
journal = {BMC Bioinformatics},
keywords = {cforest},
mendeley-tags = {cforest},
number = {25},
title = {{Bias in random forest variable importance measures: Illustrations, sources and a solution}},
volume = {8},
year = {2007}
}
@incollection{Paquot2013,
abstract = {Previous studies have shown that learner writing is often characterized by a more involved style than the writing of their native peers, as evidenced by a high number of writer/reader (W/R) visibility features such as first and second person pronouns, let's imperatives, epistemic modal adverbs (e.g. certainly, maybe) and questions (cf. e.g. Petch-Tyson 1998; Altenberg {\&} Tapper 1998). The aim of this study is to analyse French and Norwegian learners' use of W/R visibility features across genres to investigate whether learners are generally more overtly present within their academic writing or whether the features commonly attributed to EFL learners' involved style are prompted by the argumentative type of texts that has usually been analysed in learner corpus research. We compare argumentative texts from the International Corpus of Learner English (ICLE) and discipline-specific texts from the Varieties of English for Specific Purposes dAtabase (VESPA). Results show that, when compared to native speakers' writing within the same discipline, texts produced by French and Norwegian learners display an overuse of W/R visibility features. There are, however, generally fewer features of W/R visibility in the discipline-specific texts, thus suggesting that learners adapt to genre requirements to some extent.},
author = {Paquot, Magali and Hasselg{\aa}rd, Hilde and Ebeling, Signe Oksefjell},
booktitle = {Twenty Years of Learner Corpus Research: Looking back, Moving ahead. “Corpora and Language in Use”},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Paquot, Hasselg{\aa}rd, Ebeling/Paquot, Hasselg{\aa}rd, Ebeling{\_}2013{\_}Writerreader visibility in learner writing across genres. A comparison of the French and Norwegian com.pdf:pdf},
pages = {377--387},
publisher = {Presses Universitaires de Louvain},
title = {{Writer/reader visibility in learner writing across genres. A comparison of the French and Norwegian components of the ICLE and VESPA learner corpora}},
year = {2013}
}
@book{Dewaele2005,
address = {Clevedon},
author = {Dewaele, Jean-Marc},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dewaele/Dewaele{\_}2005{\_}Focus on French as a Foreign Language.pdf:pdf},
publisher = {Multilingual Matters},
title = {{Focus on French as a Foreign Language}},
year = {2005}
}
@article{Prodeau2012,
abstract = {This paper contributes to an assessment of the role of grammatical knowledge in the definition of the CEFR (Common European Framework of Reference) levels of reference and to a discussion of the relation of the knowledge of grammar in the definition of proficiency in French as a second language. The first part is a summary of the findings about the acquisition of French morphosyntax with special emphasis on nominal and verbal groups. The second part looks at possible correlation between these results and the CEFR. The rationale is that the six levels defined in the CEFR do not imply an even split in the acquisit ion process or the curriculum. Some levels will take longer and require more instruction for the learner to move beyond than others. We will also argue that the sum of pragmatic and linguistic skills needed to achieve communicative success at each level ma kes it difficult, if not impossible, to find lexical and grammatical means that would characterize only one level. Keywords: second language acquisition of French, Common European Framework, development of morphosyntax 1 Different scales: communicative, linguistic The Common European Framework of Reference (CEFR) for Languages was initially designed to provide common ground for professionals in Europe who designed language programs and assessments. To measure learners' acquisition, knowledge and skills are described according to six levels of proficiency. Each level is defined in terms of communicative skills in various activities (oral and written) that involve reception, interaction and production (Chapter 5 in the CEFR).},
author = {Prodeau, Mireille and Lopez, Sabine and V{\'{e}}ronique, Georges Daniel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Prodeau, Lopez, V{\'{e}}ronique/Prodeau, Lopez, V{\'{e}}ronique{\_}2012{\_}Acquisition of French as a Second Language Do developmental stages correlate with CEFR levels.pdf:pdf},
issn = {1457-9863},
journal = {Apples – Journal of Applied Language Studies},
keywords = {1 different scales,cefr,common european,communicative,development of morphosyntax,for languages was,framework,french,linguistic,of reference,second language acquisition of,the common european framework},
number = {1},
pages = {47--68},
title = {{Acquisition of French as a Second Language: Do developmental stages correlate with CEFR levels?}},
url = {http://apples.jyu.fi},
volume = {6},
year = {2012}
}
@incollection{Leclercq2014,
address = {Bristol},
author = {Leclercq, Pascale and Edmonds, Amanda},
booktitle = {Measuring L2 Proficiency: Perspectives from SLA},
doi = {10.21832/9781783092291-004},
editor = {Leclercq, Pascale and Edmonds, Amanda and Hilton, Heather},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Leclercq, Edmonds/Leclercq, Edmonds{\_}2014{\_}How to assess L2 Proficiency An overview of proficiency assessment research.pdf:pdf},
isbn = {9781783092291},
pages = {3--23},
publisher = {Multilingual Matters},
title = {{How to assess L2 Proficiency? An overview of proficiency assessment research}},
year = {2014}
}
@inproceedings{Candito2010a,
abstract = {We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French. The architectures are based on PCFGs with latent variables , graph-based dependency parsing and transition-based dependency parsing, respectively. We also study the inu-ence of three types of lexical information: lemmas, morphological features, and word clusters. The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88{\%}. All three parsers benet from the use of automatically derived lem-mas, while morphological features seem to be less important. Word clusters have a positive effect primarily on the latent variable parser.},
address = {Beijing},
author = {Candito, Marie and Nivre, Joakim and Denis, Pascal and Anguiano, Enrique Henestroza},
booktitle = {COLING 2010: Poster Volume},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Candito et al/Candito et al.{\_}2010{\_}Benchmarking of statistical dependency parsers for French.pdf:pdf},
pages = {108--116},
title = {{Benchmarking of statistical dependency parsers for French}},
year = {2010}
}
@article{Staples2016,
abstract = {Using the British Academic Written English corpus, this study focuses on the use of grammatical complexity features in university level texts written by first language (L1) English writers to demonstrate knowledge and perform other specialized tasks required of advanced academic writers. While the primary focus of the analysis is on writing development from first-year undergraduate to graduate students, we also consider interactions with discipline and genre. The study goes beyond most previous work on grammatical complexity in writing by investigating the use of phrasal as well as clausal features. The results show that as academic level increases, the use of phrasal complexity features in writing also increases. On the other hand, the use of clausal complexity features in student writing, particularly finite dependent clauses, decreases as academic level increases. Results further indicate that the extent of the differences across level is mediated by discipline and genre, reflecting patterns observed in research on disciplinary variation in professional academic writing.},
author = {Staples, Shelley and Egbert, Jesse and Biber, Douglas and Gray, Bethany},
doi = {10.1177/0741088316631527},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Staples et al/Staples et al.{\_}2016{\_}Academic writing development at the university level Phrasal and clausal complexity across level of study, disciplin.pdf:pdf},
issn = {15528472},
journal = {Written Communication},
keywords = {college writing development,corpus linguistics,disciplinary genres,discipline-specific writing,grammatical complexity,register analysis},
number = {2},
pages = {149--183},
title = {{Academic writing development at the university level: Phrasal and clausal complexity across level of study, discipline, and genre}},
volume = {33},
year = {2016}
}
@book{Richards2009,
abstract = {International scholars and researchers present cutting edge contributions on the significance of vocabulary in current thinking on first and second language acquisition in the school and at home. By pursuing common themes across first and second language and bilingual contexts, the editors offer a collection that tackles the most important issues.},
author = {Richards, Brian and Daller, Michael H. and Malvern, David D. and Meara, Paul and Milton, James and Treffers-Daller, Jeanine},
booktitle = {Vocabulary Studies in First and Second Language Acquisition: The Interface Between Theory and Application},
doi = {10.1057/9780230242258},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Richards et al/Richards et al.{\_}2009{\_}Vocabulary studies in first and second language acquisition The interface between theory and application.pdf:pdf},
isbn = {9780230242258},
number = {June 2009},
pages = {1--248},
title = {{Vocabulary studies in first and second language acquisition: The interface between theory and application}},
year = {2009}
}
@article{Pecina2010,
abstract = {We present an extensive empirical evaluation of collocation extraction methods based on lexical association measures and their combination. The exper- iments are performed on three sets of collocation candidates extracted from the Prague Dependency Treebank with manual morphosyntactic annotation and from the Czech National Corpus with automatically assigned lemmas and part-of-speech tags. The collocation candidates were manually labeled as collocational or non- collocational. The evaluation is based on measuring the quality of ranking the candidates according to their chance to form collocations. Performance of the methods is compared by precision-recall curves and mean average precision scores. The work is focused on two-word (bigram) collocations only. We experiment with bigrams extracted from sentence dependency structure as well as from surface word order. Further, we study the effect of corpus size on the performance of the indi- vidual methods and their combination.},
author = {Pecina, Pavel},
doi = {10.1007/s10579-009-9101-4},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Pecina/Pecina{\_}2010{\_}Lexical association measures and collocation extraction.pdf:pdf},
isbn = {1574-020X},
issn = {1574020X},
journal = {Language Resources and Evaluation},
keywords = {Collocations,Evaluation,Lexical association measures,Multiword expressions},
number = {1-2},
pages = {137--158},
title = {{Lexical association measures and collocation extraction}},
volume = {44},
year = {2010}
}
@manual{Meyer2019,
annote = {R package version 1.7-2},
author = {Meyer, David and Dimitriadou, Evgenia and Hornik, Kurt and Weingessel, Andreas and Leisch, Friedrich},
title = {{e1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien}},
url = {https://cran.r-project.org/package=e1071},
year = {2019}
}
@article{Bardovi-Harlig1989,
abstract = {The present study examines the relationship between syntactic development, or complexity, and overall accuracy evidenced in the written English of advanced adult foreign language learners. Similar acquisition profiles were found to exist for 30 learners across five language groups: Arabic, Chinese, Korean, Malay, and Spanish. Syntactic complexity, measured in number of clauses per T-unit, is found to be similar in all five groups. These advanced foreign language learners, who show similar patterns of error distribution, all show relative strength in syntax, what Newport, Gleitman, and Gleitman (1977) call a universal design feature of language, but relative weakness in morphology, which is always a language-specific system. {\textcopyright} 1989, Cambridge University Press. All rights reserved.},
author = {Bardovi-Harlig, Kathleen and Bofrnan, Theodora},
doi = {10.1017/S0272263100007816},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bardovi-Harlig, Bofrnan/Bardovi-Harlig, Bofrnan{\_}1989{\_}Attainment of syntactic and morphological accuracy by advanced language learners.pdf:pdf},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
number = {1},
pages = {17--34},
publisher = {University of Groningen},
title = {{Attainment of syntactic and morphological accuracy by advanced language learners}},
volume = {11},
year = {1989}
}
@book{survival-book,
address = {New York},
author = {{Terry M. Therneau} and {Patricia M. Grambsch}},
isbn = {0-387-98784-3},
publisher = {Springer},
title = {{Modeling Survival Data: Extending the {\{}C{\}}ox Model}},
year = {2000}
}
@manual{Bates2014,
annote = {R package version 1.2.4},
author = {Bates, Douglas and Mullen, Katharine M and Nash, John C and Varadhan, Ravi},
title = {{minqa: Derivative-free optimization algorithms by quadratic approximation}},
url = {https://cran.r-project.org/package=minqa},
year = {2014}
}
@book{Prevost2009,
address = {Amsterdam},
author = {Pr{\'{e}}vost, Phillipe},
publisher = {John Benjamins},
title = {{The Acquisition of French}},
year = {2009}
}
@phdthesis{Bulte2013,
abstract = {Bult{\'{e}}, B. (2013). The development of complexity in second language acquisition: A dynamic systems approach. (Unpublished PhD). University of Brussels,},
address = {Brussels},
author = {Bult{\'{e}}, Bram},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}}/Bult{\'{e}}{\_}2013{\_}The development of complexity in second language acquisition A dynamic systems approach.pdf:pdf},
school = {(Unpublished doctoral dissertation). Vrije Universiteit Brussel},
title = {{The development of complexity in second language acquisition: A dynamic systems approach}},
type = {Doctoral Dissertation},
year = {2013}
}
@article{Strobl2008,
author = {Strobl, Carolin and Boulesteix, Anne-Laure and Kneib, Thomas and Zeileis, Thomas and Achim, Augustin},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Strobl et al/Strobl et al.{\_}2008{\_}Conditional variable importance for random forests.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {cforest},
mendeley-tags = {cforest},
number = {307},
title = {{Conditional variable importance for random forests}},
volume = {9},
year = {2008}
}
@book{Jurafsky2018,
address = {Boulder},
author = {Jurafsky, Daniel and Martin, James H},
edition = {3rd},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Jurafsky, Martin/Jurafsky, Martin{\_}2018{\_}Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Spee.pdf:pdf},
publisher = {Prentice Hall},
title = {{Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft}},
year = {2018}
}
@incollection{Plonsky,
author = {Plonsky, Luke and Oswald, Frederick L},
booktitle = {???},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Plonsky, Oswald/Plonsky, Oswald{\_}Unknown{\_}Meta-analyzing second language research.pdf:pdf},
title = {{Meta-analyzing second language research}}
}
@book{Sarkar2008,
address = {New York},
annote = {ISBN 978-0-387-75968-5},
author = {Sarkar, Deepayan},
publisher = {Springer},
title = {{Lattice: Multivariate Data Visualization with R}},
url = {http://lmdvr.r-forge.r-project.org},
year = {2008}
}
@inproceedings{Dias1999,
address = {Venice},
author = {Dias, Ga{\"{e}}l and {Gabriel Pereira Lopes}, Jos{\'{e}} and Guillor{\'{e}}, Sylvie},
booktitle = {VEXTALL'99},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Dias, Gabriel Pereira Lopes, Guillor{\'{e}}/Dias, Gabriel Pereira Lopes, Guillor{\'{e}}{\_}1999{\_}Mutual Expectation A Measure for Multiword Lexical Unit Extraction.pdf:pdf},
month = {nov},
title = {{Mutual Expectation : A Measure for Multiword Lexical Unit Extraction}},
year = {1999}
}
@article{DeClercq2015,
abstract = {The development of lexical complexity in second language acquisition has received a considerable amount of attention in applied linguistics research. Many studies have examined the role of lexical diversity, sophistication and density as indicators of L2 proficiency. Few studies, though, have considered the development of lexical complexity from an explicitly cross-linguistic perspective. This article reports on an explorative, cross-linguistic study on the development of lexical diversity, sophistication and density in L2 French and English at four levels of linguistic proficiency. Additionally, the study proposes a number of alternative measures tapping into collocational knowledge and lexical sophistication. The analyses were carried out on a cross-sectional, multilingual corpus of L2 French and English consisting of oral narrative data. The results show a similar development of lexical diversity in L2 French and English, but considerably different developmental tendencies in terms of sophistication and density. The concluding sections discuss possible explanations for these differences and consequences for the measurement of linguistic proficiency.},
author = {{De Clercq}, Bastien},
doi = {10.1075/eurosla.15.03dec},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/De Clercq/De Clercq{\_}2015{\_}The development of lexical complexity in second language acquisition A cross-linguistic study of L2 French and English.pdf:pdf},
issn = {1568-1491},
journal = {EUROSLA Yearbook},
pages = {69--94},
title = {{The development of lexical complexity in second language acquisition: A cross-linguistic study of L2 French and English}},
volume = {15},
year = {2015}
}
@manual{Henry2020,
annote = {R package version 1.1.0},
author = {Henry, Lionel and Wickham, Hadley},
title = {{tidyselect: Select from a Set of Strings}},
url = {https://cran.r-project.org/package=tidyselect},
year = {2020}
}
@article{Zeileis2010,
author = {Zeileis, Achim and Croissant, Yves},
doi = {10.18637/jss.v034.i01},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--13},
title = {{Extended Model Formulas in {\{}R{\}}: Multiple Parts and Multiple Responses}},
volume = {34},
year = {2010}
}
@manual{Wickham2018,
annote = {R package version 6.1.1},
author = {Wickham, Hadley and Danenberg, Peter and Eugster, Manuel},
title = {{roxygen2: In-Line Documentation for R}},
url = {https://cran.r-project.org/package=roxygen2},
year = {2018}
}
@manual{Csardi2017,
annote = {R package version 1.3.4},
author = {Cs{\'{a}}rdi, G{\'{a}}bor},
title = {{crayon: Colored Terminal Output}},
url = {https://cran.r-project.org/package=crayon},
year = {2017}
}
@manual{Wickham2018d,
annote = {R package version 1.3.1},
author = {Wickham, Hadley and Hester, Jim and Francois, Romain},
title = {{readr: Read Rectangular Text Data}},
url = {https://cran.r-project.org/package=readr},
year = {2018}
}
@manual{Ooms2019d,
annote = {R package version 1.4.1},
author = {Ooms, Jeroen},
title = {{openssl: Toolkit for Encryption, Signatures and Certificates Based on OpenSSL}},
url = {https://cran.r-project.org/package=openssl},
year = {2019}
}
@manual{Horner2011,
annote = {R package version 1.0-6},
author = {Horner, Jeffrey},
title = {{brew: Templating Framework for Report Generation}},
url = {https://cran.r-project.org/package=brew},
year = {2011}
}
@article{Andre2010,
abstract = {Cet article pr{\'{e}}sente le projet TCOF $\backslash$(Traitement de Corpus Oraux en Fran{\c{c}}ais$\backslash$) du laboratoire ATILF $\backslash$(Analyse et Traitement Informatique de la Langue Fran{\c{c}}aise$\backslash$), UMR 7118, CNRS et Nancy Universit{\'{e}}. Ce projet a {\'{e}}t{\'{e}} initi{\'{e}} en 2005 afin de collecter un grand corpus de donn{\'{e}}es orales et d'{\'{e}}tudier les productions langagi{\`{e}}res et les pratiques interactionnelles $\backslash$(des enfants et des adultes$\backslash$) en fran{\c{c}}ais parl{\'{e}}. La mise en place du projet TCOF comporte plusieurs aspects : importante collecte de donn{\'{e}}es, transcription align{\'{e}}e texte-son, mise en conformit{\'{e}} juridique, traitement informatique de ces donn{\'{e}}es, diffusion internationale libre et gratuite sur le site du CNRTL $\backslash$(Centre National de Ressources Textuelles et Lexicales$\backslash$), {\`{a}} l'adresse suivante : http:$\backslash$/$\backslash$/www.cnrtl.fr$\backslash$/corpus$\backslash$/tcof$\backslash$/. L'article pr{\'{e}}sente les r{\'{e}}flexions, les contraintes et les travaux en cours pour la r{\'{e}}alisation de ces diff{\'{e}}rents aspects.},
author = {Andr{\'{e}}, Virginie and Canut, Emmanuelle},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Andr{\'{e}}, Canut/Andr{\'{e}}, Canut{\_}2010{\_}Mise {\`{a}} disposition de corpus oraux interactifs le projet TCOF ( Traitement de Corpus Oraux en Fran{\c{c}}ais ).pdf:pdf},
journal = {Pratiques},
keywords = {base de donn{\'{e}}es,cnrtl,corpus oraux,m{\'{e}}tadonn{\'{e}}es,traitement de donn{\'{e}}es orales,transcription},
pages = {35--51},
title = {{Mise {\`{a}} disposition de corpus oraux interactifs : le projet TCOF ( Traitement de Corpus Oraux en Fran{\c{c}}ais )}},
year = {2010}
}
@article{Benazzo2007,
abstract = {Cet article se focalise sur la transition entre l'expression lexicale et l'expression grammaticale des relations temporelles, en discutant les r{\'{e}}sultats de recherches r{\'{e}}centes bas{\'{e}}es sur une partie des donn{\'{e}}es ESF, notamment en fran{\c{c}}ais et en n{\'{e}}erlandais L2. Les donn{\'{e}}es prises en compte r{\'{e}}v{\`{e}}lent deux parcours acquisitionnels {\`{a}} premi{\`{e}}re vue tr{\`{e}}s diff{\'{e}}rents : en n{\'{e}}erlandais L2 $\backslash$(apprenants turcs et marocains$\backslash$) l'{\'{e}}mergence d'une morphologie verbale fonctionnelle conduit {\`{a}} une {\'{e}}tape interm{\'{e}}diaire caract{\'{e}}ris{\'{e}}e par la combinaison de deux morph{\`{e}}mes libres qui encodent s{\'{e}}par{\'{e}}ment les valeurs de temps$\backslash$/aspect ; en fran{\c{c}}ais L2 $\backslash$(apprenants hispanophones$\backslash$), les premi{\`{e}}res formes d'auxiliaire semblent avoir une valeur temporelle, alors que certaines distinctions aspectuelles sont exprim{\'{e}}es par l'adverbe de contraste temporel d{\'{e}}j{\`{a}}. Nous sugg{\'{e}}rons que les deux parcours refl{\`{e}}tent une tendance d{\'{e}}velop­pementale commune, sp{\'{e}}cifique {\`{a}} l'apprenant, {\`{a}} traiter s{\'{e}}par{\'{e}}ment les valeurs complexes de la flexion verbale : les composantes temporelle et aspectuelle seraient encod{\'{e}}es d'abord de mani{\`{e}}re analytique — soit par deux morph{\`{e}}mes libres, soit par une forme verbale associ{\'{e}}e {\`{a}} un marqueur lexical sp{\'{e}}cialis{\'{e}} — avant de pouvoir fusionner dans la morphologie verbale.This article focuses on the transition between lexical and grammatical expression of temporal relations, by discussing the results of recent research based on some of the ESF project, namely French and Dutch L2.Learner production reveals two acquisitional paths which are apparently very different : in Dutch L2 $\backslash$(Turkish and Moroccan Arabic learners$\backslash$) the emergence of a functional verb morphology leads to an intermediary stage where a combination of two free morphemes encodes separately tense and aspect oppositions ; in French L2 $\backslash$(Spanish-speaking learners$\backslash$), the first auxiliaries seem to have a temporal value, whereas some aspectual distinctions are expressed by the adverb of temporal contrast d{\'{e}}j{\`{a}}.We suggest that both acquisitional paths can be accounted for by a learner-specific common tendency to deal separately with the complex values of verb inflection : the temporal and aspectual components would be encoded first in an analytic way – either by two free morphemes or by a verb form combined with a specialized lexical marker — before being packaged into one verbal form.},
author = {Benazzo, Sandra and Starren, Marianne},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Benazzo, Starren/Benazzo, Starren{\_}2007{\_}L'{\'{e}}mergence de moyens grammaticaux pour exprimer les relations temporelles en L2.pdf:pdf},
issn = {1778-7432},
journal = {Acquisition et interaction en langue {\'{e}}trang{\`{e}}re},
keywords = {Acquisition,Expression,Fran{\c{c}}ais,Langage,Linguistique,Marocains,Morph{\`{e}}mes,N{\'{e}}erlandais,Os temporal,Premi{\`{e}}res,Prises,Production,Relations,Richesse,Temps,Turcs,Valeur,Valeurs (philosophie),Valeurs mobili{\`{e}}res,Vision,auxiliaire,fran{\c{c}}ais (langue),pouvoir,transition,vue},
number = {25},
pages = {129--157},
title = {{L'{\'{e}}mergence de moyens grammaticaux pour exprimer les relations temporelles en L2}},
year = {2007}
}
@article{Kuiken2007,
abstract = {In a study on L2 proficiency in writing, conducted among 84 Dutch university students of Italian and 75 students of French, manipulation of task complexity led in the complex task to a significant decrease of errors, while at the same time a trend for a lexically more varied text was observed (Kuiken and Vedder 2005, 2007, in press). Based on this first analysis in which some global performance measures were used, a more specific analysis was carried out. In the latter analysis, which is reported in this article, accuracy was investigated in more detail according to the type of errors in the L2 texts, while lexical variation was analysed further by distinguishing frequent words from infrequent ones. Results showed that the effect of task complexity could mainly be attributed to lower ratios of lexical errors in the more complex task. With respect to the use of frequent versus infrequent words mixed results were found. On the basis of these findings a number of implications with regard to the operationalisation of task complexity and linguistic performance are discussed. {\textcopyright} Walter de Gruyter 2007.},
author = {Kuiken, Folkert and Vedder, Ineke},
doi = {10.1515/iral.2007.012},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiken, Vedder/Kuiken, Vedder{\_}2007{\_}Task complexity and measures of linguistic performance in L2 writing.pdf:pdf},
issn = {0019042X},
journal = {International Review of Applied Linguistics in Language Teaching},
number = {3},
pages = {261--284},
title = {{Task complexity and measures of linguistic performance in L2 writing}},
volume = {45},
year = {2007}
}
@inproceedings{Mcdonald2006,
abstract = {In this paper we extend the maximum spanning tree (MST) dependency parsing framework of McDonald et al. (2005c) to incorporate higher-order feature representations and allow dependency structures with multiple parents per word.},
annote = {MST Parser Citation},
author = {Mcdonald, Ryan and Pereira, Fernando},
booktitle = {EACL 2006},
doi = {10.1.1.60.8013},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mcdonald, Pereira/Mcdonald, Pereira{\_}2006{\_}Online Learning of Approximate Dependency Parsing Algorithms.pdf:pdf},
isbn = {1932432590},
pages = {81--88},
title = {{Online Learning of Approximate Dependency Parsing Algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.8013},
year = {2006}
}
@manual{Schutten2018,
annote = {R package version 1.6.7},
author = {Schutten, Gerrit-Jan and Chan, Chung-hong and Leeper, Thomas J and Other contributors},
title = {{readODS: Read and Write ODS Files}},
url = {https://cran.r-project.org/package=readODS},
year = {2018}
}
@article{Garner2018b,
abstract = {Current quantitative methods in second language (L2) acquisition have proven useful in examining how phraseological unit production changes over time. However, these methods are limited in that they do not allow for the analysis of individual differences in those changes. This study demonstrates the po- tential for Latent Curve Modeling, a type of Structural Equation Modeling, to address questions about productive phraseological knowledge development. It examines growth in multiple indices of bigram and trigram use (frequency, association strength, proportion) in the spoken output of L2 speakers over the course of a 4-month study. Results for unconditional latent curve models indicate that spoken bi- gram and trigram proportions increased for the entire group over the study period. Conditional latent curve models showed that growth in bigram frequency and bigram proportion was predicted by profi- ciency, with less proficient writers experiencing greater growth. These models also demonstrated that conversation dyad predicted growth in spoken bigram frequency in that L2 speakers with L2 conversa- tion partners, as compared to first language (L1) partners, produced more high-frequency bigrams over time. These results have implications for research on L2 productive phraseological knowledge develop- ment specifically and longitudinal L2 research in general. Keywords:},
author = {Garner, James and Crossley, Scott A.},
doi = {10.1111/modl.12494},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Garner, Crossley/Garner, Crossley{\_}2018{\_}A Latent Curve Model Approach To Studying L2 N-Gram Development.pdf:pdf},
isbn = {0895-3309},
issn = {15404781},
journal = {Modern Language Journal},
keywords = {latent curve modeling,longitudinal development,n-gram analysis},
number = {3},
pages = {494--511},
pmid = {17746758},
title = {{A Latent Curve Model Approach To Studying L2 N-Gram Development}},
volume = {102},
year = {2018}
}
@book{Davison1997,
address = {Cambridge},
annote = {ISBN 0-521-57391-2},
author = {Davison, A C and Hinkley, D V},
publisher = {Cambridge University Press},
title = {{Bootstrap Methods and Their Applications}},
url = {http://statwww.epfl.ch/davison/BMA/},
year = {1997}
}
@manual{Xiao2018,
annote = {R package version 2.9},
author = {Xiao, Nan},
title = {{ggsci: Scientific Journal and Sci-Fi Themed Color Palettes for 'ggplot2'}},
url = {https://cran.r-project.org/package=ggsci},
year = {2018}
}
@article{Ishwaran2008,
author = {Ishwaran, H and Kogalur, U B and Blackstone, E H and Lauer, M S},
journal = {Ann. Appl. Statist.},
number = {3},
pages = {841--860},
title = {{Random survival forests}},
url = {http://arxiv.org/abs/0811.1645v1},
volume = {2},
year = {2008}
}
@manual{Xie2019b,
annote = {R package version 0.7},
author = {Xie, Yihui},
title = {{mime: Map Filenames to MIME Types}},
url = {https://cran.r-project.org/package=mime},
year = {2019}
}
@manual{Wickham2016a,
annote = {R package version 0.1.1},
author = {Wickham, Hadley and Hofmann, Heike},
title = {{productplots: Product Plots for R}},
url = {https://cran.r-project.org/package=productplots},
year = {2016}
}
@book{Pecina2009,
author = {Pecina, Pavel},
editor = {Haji{\v{c}}, Jan},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Pecina/Pecina{\_}2009{\_}Lexical Association Measures Collocation Extraction.pdf:pdf},
isbn = {9788090417557},
publisher = {Institute of Formal and Applied Linguistics},
title = {{Lexical Association Measures : Collocation Extraction}},
year = {2009}
}
@manual{Wickham2019i,
annote = {R package version 0.3.0},
author = {Wickham, Hadley and Pedersen, Thomas Lin},
title = {{gtable: Arrange 'Grobs' in Tables}},
url = {https://cran.r-project.org/package=gtable},
year = {2019}
}
@incollection{Ellis2019,
address = {Cambridge},
author = {Ellis, Nick C and Wulff, Stefanie},
booktitle = {The Cambridge Handbook of Language Learning},
doi = {10.1017/9781108333603.003},
editor = {Schwieter, John W and Benati, Alessandro G},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ellis, Wulff/Ellis, Wulff{\_}2019{\_}Cognitive Approaches to Second Language Acquisition.pdf:pdf},
isbn = {9781108333603},
pages = {41--61},
publisher = {Cambridge University Press},
title = {{Cognitive Approaches to Second Language Acquisition}},
year = {2019}
}
@article{Durrant2009,
abstract = {Usage-based models claim that first language learning is based on the frequency-based analysis of memorised phrases. It is not clear though, whether adult second language learning works in the same way. It has been claimed that non-native language lacks idiomatic formulas, suggesting that learners neglect phrases, focusing instead on orthographic words. While a number of studies challenge the claim that non-native language lacks formulaicity, these studies have two important shortcomings: they fail to take account of appropriate frequency information and they pool the writing of different learners in ways that may mask individual differences. Using methodologies which avoid these problems, this study found that non-native writers rely heavily on high-frequency collocations, but that they underuse less frequent, strongly associated collocations (items which are probably highly salient for native speakers). These findings are consistent with usage-based models of acquisition while accounting for the impression that non-native writing lacks idiomatic phraseology.},
author = {Durrant, Philip and Schmitt, Norbert},
doi = {10.1515/iral.2009.007},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Durrant, Schmitt/Durrant, Schmitt{\_}2009{\_}To what extent do native and non-native writers make use of collocations.pdf:pdf},
isbn = {0019-042X$\backslash$r1613-4141},
issn = {0019042X},
journal = {International Review of Applied Linguistics in Language Teaching},
keywords = {stats},
mendeley-tags = {stats},
pages = {157--177},
pmid = {346179272},
title = {{To what extent do native and non-native writers make use of collocations?}},
volume = {47},
year = {2009}
}
@incollection{Kuiken2012a,
abstract = {The research project reported in this chapter consists of three studies in which syntactic complexity, lexical variation and fluency appear as dependent variables. The independent variables are task complexity and proficiency level, as the three studies investigate the effect of task complexity on the written and oral performance of L2 learners of different levels of linguistic proficiency. Task complexity was defined according to Robinsons Triadic Componential Framework in terms of the number of elements to be dealt with (Robinson 2001a, b, 2003, 2005, 2007). Linguistic performance was assessed by means of both general and specific measures of syntactic complexity, lexical variation and accuracy. In the final section of the paper, the results of the three studies, which seem to contradict Robinson's predictions, are compared and discussed, both with respect to the Triadic Componential Framework and the proficiency measures used. 1 . I n t r o d u c t i o n In their overview of research on CAF, Housen and Kuiken (2009) point out that the concepts of complexity, accuracy and fluency (hence CAF) in second language acquisition (SLA) research have figured not only as dependent but also as inde pendent variables of investigation. The research project which is reported in this chapter comprises three studies in which syntactic complexity, lexical variation and fluency appear as dependent variables. The independent variables are task complex ity and proficiency level, as the three studies investigate the effect of task complexity on the written and oral performance of L2 learners of different levels of linguistic proficiency. Linguistic performance was assessed by means of both general and spe cific measures of syntactic complexity, lexical variation and accuracy, whereas task complexity was defined according to Robinsons Triadic Componential Framework 144 Folkert Kuiken {\&} Ineke Vedder (Robinson 2001a, b, 2003,2005,2007). The effect of task complexity on the fluency of the writing process was not included in the studies. In Section 2, an overview of general and specific performance measures is given, with a focus on the areas of investigation, i.e. syntactic complexity, lexi cal variation and accuracy in L2 production. In Section 3, the two most influential models of task complexity are discussed, the Limited Attentional Capacity Model (or Trade-off Hypothesis) developed by Skehan and Foster (Skehan 1998, 2001, 2003; Skehan {\&} Foster 1999, 2001) and the Triadic Componential Framework developed by Robinson (2001a, b, 2003,2005,2007), also known as the Cognition Hypothesis. In Section 4 the design of the research and the methods for coding and analyzing the data are described. The core data concern written texts of university students of Italian L2 and French L2, with Dutch as their mother tongue. These data were analyzed along different lines: in study 1, all data were submitted to an analysis of general performance measures (Kuiken {\&} Vedder 2008a); in study 2, an in-depth analysis of lexical variation and accuracy was carried out (Kuiken {\&} Vedder 2007b); and in study 3, the effect of mode (oral versus written proficiency) was investigated, by focusing on the students of Italian L2. For this purpose new data were collected from a second, different group of students of Italian L2. These students were asked to perform in the oral mode the same tasks that were per formed earlier by the students of study 1 in the written mode (Kuiken {\&} Vedder). This chapter presents an overview of the results of the studies, which appear to be in contrast with Robinsons Cognition Hypothesis. As will be shown in Section 5, in study 1, although a significant effect on accuracy was found, no influence of task complexity on syntactic complexity and lexical variation was detected. In study 2, the predictions of the Cognition Hypothesis were confirmed for one of the two target languages (French), but not for the other one (Italian). Study 3 demonstrated that both in the written and in the oral mode, in spite of a significant influence on accuracy, the findings for syn tactic complexity and lexical variation clearly contradicted Robinson's predictions. In Section 6, the outcomes of the three studies are compared and discussed, not only with respect to the proficiency measures which were used in the studies, but also concerning the Triadic Componential Framework and the hypotheses which can be derived from it.},
address = {Amsterdam},
author = {Kuiken, Folkert and Vedder, Ineke},
booktitle = {Dimensions of L2 performance and proficiency: Complexity, accuracy and fluency in SLA},
doi = {10.1075/lllt.32.07kui},
editor = {Housen, Alex and Kuiken, Folkert and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Kuiken, Vedder/Kuiken, Vedder{\_}2012{\_}Syntactic complexity, lexical variation and accuracy as a function of task complexity and proficiency level in L2 wr.pdf:pdf},
number = {2012},
pages = {143--170},
publisher = {John Benjamins},
title = {{Syntactic complexity, lexical variation and accuracy as a function of task complexity and proficiency level in L2 writing and speaking}},
year = {2012}
}
@techreport{DFGReviewBoardonLinguistics2017,
author = {{DFG Review Board on Linguistics}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/DFG Review Board on Linguistics/DFG Review Board on Linguistics{\_}2017{\_}Guidelines for Building Language Corpora Under German Law.pdf:pdf},
title = {{Guidelines for Building Language Corpora Under German Law}},
year = {2017}
}
@article{Bulte2008,
abstract = {This article aims (a) to explore the operationalisation and definition of lexical L2 proficiency and related constructs with a view to identifying a set of measures that can adequately capture the dynamics of lexical L2 proficiency development over time, and (b) to shed more light on the development of lexical proficiency in French Foreign Language classes. After a discussion of theoretical, terminological and methodological issues in L2 vocabulary research, we present a longitudinal quantitative study of the lexical development of Dutch-speaking adolescents learning FFL in Dutch-medium schools in Brussels over a three-year period and compare these learners' lexical proficiency in French to native speaker benchmarks.},
author = {Bult{\'{e}}, Bram and Housen, Alex and Pierrard, Michel and {Van Daele}, Siska},
doi = {10.1017/S0959269508003451},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bult{\'{e}} et al/Bult{\'{e}} et al.{\_}2008{\_}Investigating lexical proficiency development over time - The case of Dutch-speaking learners of French in Brussels.pdf:pdf},
isbn = {0959269508003},
issn = {09592695},
journal = {Journal of French Language Studies},
keywords = {complexity,stats},
mendeley-tags = {complexity,stats},
pages = {277--298},
title = {{Investigating lexical proficiency development over time - The case of Dutch-speaking learners of French in Brussels}},
volume = {18},
year = {2008}
}
@manual{Hope2013,
annote = {R package version 1.5},
author = {Hope, Ryan M},
title = {{Rmisc: Rmisc: Ryan Miscellaneous}},
url = {https://cran.r-project.org/package=Rmisc},
year = {2013}
}
@manual{Canty2019,
annote = {R package version 1.3-22},
author = {Canty, Angelo and Ripley, B D},
title = {{boot: Bootstrap R (S-Plus) Functions}},
year = {2019}
}
@article{Ferhani2014,
author = {Ferhani, F Fatiha},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Ferhani/Ferhani{\_}2014{\_}Statut du Fran{\c{c}}ais {\`{a}} l'{\'{e}}cole sup{\'{e}}rieure de banque d'Alger FLE, FOS ou FLS.pdf:pdf},
isbn = {9782252039359},
journal = {{\'{E}}tudes de linguistique appliqu{\'{e}}e},
number = {2},
pages = {221--229},
title = {{Statut du Fran{\c{c}}ais {\`{a}} l'{\'{e}}cole sup{\'{e}}rieure de banque d'Alger: FLE, FOS ou FLS?}},
volume = {174},
year = {2014}
}
@article{Stefanowitsch2003a,
abstract = {This paper introduces an extension of collocational analysis that takes into account grammatical structure and is specifically geared to investigating the interaction of lexemes and the grammatical constructions associated with them. The method is framed in a construction-based approach to language, i.e. it assumes that grammar consists of signs (form-meaning pairs) and is thus not fundamentally different from the lexicon. The method is applied to linguistic expressions at various levels of abstraction (words, semi-fixed phrases, argument structures, tense, aspect and mood). The method has two main applications: first, to increase the adequacy of grammatical description by providing an objective way of identifying the meaning of a grammatical construction and determining the degree to which particular slots in it prefer or are restricted to a particular set of lexemes; second, to provide data for linguistic theory-building.},
author = {Stefanowitsch, Anatol and Gries, Stefan Th.},
doi = {10.1075/ijcl.8.2.03ste},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Stefanowitsch, Gries/Stefanowitsch, Gries{\_}2003{\_}Collostructions Investigating the interaction of words and constructions.pdf:pdf},
isbn = {1384-6655},
issn = {1384-6655},
journal = {International Journal of Corpus Linguistics},
keywords = {stats},
mendeley-tags = {stats},
number = {2},
pages = {209--243},
title = {{Collostructions: Investigating the interaction of words and constructions}},
volume = {8},
year = {2003}
}
@article{Foster1996,
abstract = {This study focuses on the impact of different variables on the nature of language performance in the context of task-based instruction. Characteristics of tasks are discussed, and then a framework is offered that can organize the nature of task-based instruction and relevant research. The framework is used to generate predictions regarding the effects of three different tasks (Personal Information Exchange, Narrative, and Decision-Making) and three different implementation conditions for each task (unplanned, planned but without detail, detailed planning) on the variables of fluency, complexity, and accuracy. The study reports strong effects of planning on fluency and clear effects also on complexity, with a linear relationship between degree of planning and degree of complexity. However, a more complex relationship was discovered between planning and accuracy, with the most accurate performance produced by the less detailed planners. In addition, interactions were found between task type and planning conditions, such that the effects of planning were greater with the Narrative and Decision-Making tasks than with the Personal Information Exchange task. The results are discussed in terms of an attentional model of learning and performance and highlight the importance of tradeoff effects between the goals of complexity and accuracy in the context of the use of limited capacity attentional resources. The study contributes to the development of cognitive models of second language performance and addresses a number of pedagogic issues. {\textcopyright} 1996 Cambridge University Press.},
author = {Foster, Pauline and Skehan, Peter},
doi = {10.1017/S0272263100015047},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Foster, Skehan/Foster, Skehan{\_}1996{\_}The influence of planning and task type on second language performance.pdf:pdf},
issn = {14701545},
journal = {Studies in Second Language Acquisition},
number = {3},
pages = {299--323},
publisher = {University of Groningen},
title = {{The influence of planning and task type on second language performance}},
volume = {18},
year = {1996}
}
@book{CouncilofEurope2001,
abstract = {This book contains descriptor scales which describe the linguistic skills needed by language learners to become competent speakers of another language.},
address = {Cambridge},
author = {{Council of Europe}},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Council of Europe/Council of Europe{\_}2001{\_}The Common European Framework of Reference for Languages Learning, teaching, assessment.pdf:pdf},
institution = {Council of Europe},
isbn = {0521005310},
publisher = {Cambridge University Press},
title = {{The Common European Framework of Reference for Languages : Learning, teaching, assessment}},
year = {2001}
}
@article{Bartning2003,
abstract = {Le but de cette {\'{e}}tude est de d{\'{e}}crire le d{\'{e}}veloppement de la comp{\'{e}}tence textuelle chez des apprenants su{\'{e}}dophones {\`{a}} diff{\'{e}}rents stades. Au pr{\'{e}}alable, nous pr{\'{e}}sentons un continuum de stades acquisitionnels r{\'{e}}cemment propos{\'{e}} pour les traits d{\'{e}}veloppementaux morphosyntaxiques, que nous compl{\'{e}}tons ensuite dans cette {\'{e}}tude par les traits de la comp{\'{e}}tence textuelle.},
author = {Bartning, Inge and Kirchmeyer, Nathalie},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bartning, Kirchmeyer/Bartning, Kirchmeyer{\_}2003{\_}Le d{\'{e}}veloppement de la comp{\'{e}}tence textuelle {\`{a}} travers les stades acquisitionnels en fran{\c{c}}ais L2.pdf:pdf},
issn = {1778-7432},
journal = {Acquisition et interaction en langue {\'{e}}trang{\`{e}}re},
keywords = {Acquisition,Analyse,Analyse de r{\'{e}}seau (planification),Bastions,Dimensions,Dynamique,D{\'{e}}veloppement,Fran{\c{c}}ais,Langage,Linguistique,Litt{\'{e}}ratie,Planification,Projet,Propositions relatives,Recherche,Sein,Stades,Stages,Su{\'{e}}dois,comp{\'{e}}tence textuelle,faisceaux,fran{\c{c}}ais (langue),perspective,travail},
number = {19},
pages = {9--39},
title = {{Le d{\'{e}}veloppement de la comp{\'{e}}tence textuelle {\`{a}} travers les stades acquisitionnels en fran{\c{c}}ais L2}},
year = {2003}
}
@book{Granger2015,
abstract = {In recent years, the application of learner corpora to the educational domain has developed into a rapidly growing research field. Multiple research venues are now devoted to it, including the International Speech Communication Association (ISCA) Special Interest Group on Speech and Language Technology in Education (SLaTE) and the North American Chapter of the Association for Computational Linguistics (NAACL) Workshop on Innovative Use of Natural Language Processing for Building Educational Applications. Special issues of major journals (Language Testing, Natural Language Engineering and Speech Communication) have been devoted to the use of natural language processing (NLP) and speech processing to support educational applications, as well. A number of factors have contributed to this recent interest. One is the increase in large-scale testing for tracking students' mastery of skills and content knowledge, especially in the United States. There has been a trend toward incorporating more open-ended items in these tests (such as essay-writing tasks), because traditional multiple-choice items are thought to provide a less authentic measure of students' true abilities (Linn et al. 1991) and therefore to represent the test construct (the knowledge, skills and abilities to be measured) less directly and faithfully. However, the large-scale scoring of open-ended test items presents a significant operational challenge. A second factor is the increasing ubiquity of computers and other electronic devices in educational settings, which makes computerised support of learning feasible in an increasing number of scenarios. Finally, the development of educational applications has been accelerated by the availability of corpus resources that can be used to calibrate automated scoring engines and other educational systems. Corpora that reflect the writing and speech of language learners play an especially important role here, as in many testing applications language learners constitute the population of interest, in whole or in part. This chapter focuses on NLP and speech applications that support scoring of open-ended responses, broadly speaking, although there are many other educational applications of NLP and speech processing that are intended for more formative contexts (those that support the learning process, rather than solely the assessment of knowledge or skills).},
address = {Cambridge},
author = {Granger, Sylviane and Gilquin, Ga{\"{e}}tanelle and Meunier, Fanny},
booktitle = {The Cambridge Handbook of Learner Corpus Research},
doi = {10.1017/CBO9781139649414},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research.pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(2).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(3).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(4).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(5).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(6).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(7).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(8).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(9).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(10).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(11).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(12).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(13).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(14).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(15).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(16).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(17).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(18).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(19).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(20).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(21).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(22).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(23).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(24).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(25).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(26).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(27).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(28).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(29).pdf:pdf;:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Granger, Gilquin, Meunier/Granger, Gilquin, Meunier{\_}2015{\_}The Cambridge handbook of learner corpus research(30).pdf:pdf},
isbn = {9781139649414},
publisher = {Cambridge University Press},
title = {{The Cambridge handbook of learner corpus research}},
year = {2015}
}
@incollection{Saied2017,
address = {Berlin},
author = {Saied, Hazem Al and Candito, Marie and Constant, Matthieu},
booktitle = {Multiword expressions at length and in depth: Extended papers from the MWE 2017 workshop},
doi = {10.5281/zenodo.1469561},
editor = {Markantonatou, Stella and Ramisch, Carlos and Savary, Agata and Vincze, Veronika},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Saied, Candito, Constant/Saied, Candito, Constant{\_}2017{\_}A transition-based verbal multiword expression analyzer.pdf:pdf},
pages = {209--226},
publisher = {Language Science Press},
title = {{A transition-based verbal multiword expression analyzer}},
year = {2017}
}
@article{Gimenes2016,
abstract = {Lexical frequency is one of the strongest predictors of word processing time. The frequencies are often calculated from book-based corpora, or more recently from subtitle-based corpora. We present new frequencies based on Twitter, blog posts, or newspapers for 66 languages. We show that these frequencies predict lexical decision reaction times similar to the already existing frequencies, or even better than them. These new frequencies are freely available and may be downloaded from http://worldlex.lexique.org.},
author = {Gimenes, Manuel and New, Boris},
doi = {10.3758/s13428-015-0621-0},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Gimenes, New/Gimenes, New{\_}2016{\_}Worldlex Twitter and blog word frequencies for 66 languages.pdf:pdf},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Blogs,Cross-language frequency,Twitter,Word frequency,wordlex},
mendeley-tags = {wordlex},
number = {3},
pages = {963--972},
title = {{Worldlex: Twitter and blog word frequencies for 66 languages}},
volume = {48},
year = {2016}
}
@incollection{Bestgen2018,
address = {Leiden},
author = {Bestgen, Yves and Granger, Sylviane},
booktitle = {Corpora and lexis},
editor = {Hoffmann, Sebastian and Sand, Andrea and Arndt-Lappe, Sabine and Dillmann, Lisa Marie},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Bestgen, Granger/Bestgen, Granger{\_}2018{\_}Tracking L2 writers' phraseological development using collgrams Evidence from a longitudinal EFL corpus.pdf:pdf},
publisher = {Brill Rodopi},
title = {{Tracking L2 writers' phraseological development using collgrams: Evidence from a longitudinal EFL corpus}},
year = {2018}
}
@article{Melcuk2014,
author = {Mel'{\v{c}}uk, Igor},
doi = {10.1075/la.215.01mel},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Mel'{\v{c}}uk/Mel'{\v{c}}uk{\_}2014{\_}Dependency in Language.pdf:pdf},
number = {ii},
pages = {1--32},
title = {{Dependency in Language}},
year = {2014}
}
@incollection{Forsberg391851,
author = {Forsberg, Fanny and Bartning, Inge},
booktitle = {Communicative proficiency and linguistic development : Intersections between SLA and language testing},
editor = {Bartning, Inge and Martin, Maisa and Vedder, Ineke},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Forsberg, Bartning/Forsberg, Bartning{\_}2010{\_}Can linguistic features discriminate between the communicative CEFR-levels A pilot study of written L2 French.pdf:pdf},
keywords = {CEFR scale,second language acquisition},
organization = {Stockholm University, Department of French, Italian and Classical Languages},
pages = {133--157},
publisher = {European Second Language Association},
series = {Eurosla Monographs series},
title = {{Can linguistic features discriminate between the communicative CEFR-levels? : A pilot study of written L2 French}},
year = {2010}
}
@article{Rammell2017,
author = {Rammell, C. Sophia and {Van Lanker Sidtis}, Diana and Pisoni, David B.},
doi = {10.1075/ml.16019.ram},
file = {:Users/nvandew/OneDrive - UCL/Mendeley Desktop/Rammell, Van Lanker Sidtis, Pisoni/Rammell, Van Lanker Sidtis, Pisoni{\_}2017{\_}Perception of formulaic and novel expressions under acoustic degradation.pdf:pdf},
journal = {The Mental Lexicon},
number = {2},
pages = {234--262},
title = {{Perception of formulaic and novel expressions under acoustic degradation}},
volume = {12},
year = {2017}
}
